\chapter{Elementarne struktury danych}

\subchapter{Stosy i~kolejki}

\exercise %10.1-1
Ciąg operacji na stosie $S$ został przedstawiony na rys.~\ref{fig:10.1-1}.
\begin{figure}[ht]
    \begin{center}
		\includegraphics{fig10.1}
	\end{center}
	\caption{Operacje wstawiania i~usuwania elementów na stosie $S$. {\sffamily\bfseries(a)} Pusty stos $S$ reprezentowany jako tablica $S[1\twodots6]$. {\sffamily\bfseries\twodashes{(b)}{(d)}} Stos $S$ po wykonaniu na nim kolejnych operacji \proc{Push}. {\sffamily\bfseries(e)} Po usunięciu elementu ze stosu $S$ zmieniana jest jedynie pozycja atrybutu $\id{top}[S]$, natomiast sam element pozostaje w~tablicy. {\sffamily\bfseries(f)} Wstawienie nowego elementu na stos $S$ nadpisuje stary element, który został usunięty w~poprzednim kroku. {\sffamily\bfseries(g)} Stos $S$ po wykonaniu ostatniej operacji \proc{Pop}.} \label{fig:10.1-1}
\end{figure}

\exercise %10.1-2
Z~tablicą $A$ związujemy atrybuty $\id{top_1}[A]$ i~$\id{top}_2[A]$, które będą wskazywać na pozycje wierzchołków, odpowiednio, pierwszego i~drugiego stosu. Pierwszy będzie składał się z~elementów $A[1\twodots\id{top}_1[A]]$, a~drugi -- z~elementów $A[\id{top}_2[A]\twodots n]$. Początkowo $\id{top}_1[A]=0$ i~$\id{top}_2[A]=n+1$. Dodawanie i~usuwanie elementów w~pierwszym stosie działa identycznie jak dla pojedynczego stosu znajdującego się w~tablicy $A$, którego wierzchołek zajmuje pozycję $\id{top}_1[A]$. Drugi stos zachowuje się symetrycznie do pierwszego -- podczas dodawania do niego nowego elementu atrybut $\id{top}_2[A]$ będzie inkrementowany, a~podczas usuwania -- dekrementowany. Operacje dodawania i~usuwania elementów działają oczywiście w~czasie stałym. Jeśli $\id{top}_1[A]=0$, to pierwszy stos jest pusty, a~jeśli $\id{top}_2[A]=n+1$, to drugi stos jest pusty. Przepełnienie ma miejsce tylko wtedy, gdy $\id{top}_1[A]=\id{top}_2[A]-1$ i~usiłujemy dodać nowy element do któregokolwiek stosu, czyli wówczas, gdy łączna liczba elementów na obu stosach wynosi $n$.

\exercise %10.1-3
Ciąg operacji na kolejce $Q$ ilustruje rys.~\ref{fig:10.1-3}.

\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig10.2}
	\end{center}
	\caption{Operacje wstawiania i~usuwania elementów na kolejce $Q$. {\sffamily\bfseries(a)} Pusta kolejka $Q$ reprezentowana jako tablica $Q[1\twodots6]$. {\sffamily\bfseries\twodashes{(b)}{(d)}} Kolejka $Q$ po wykonaniu na niej kolejnych operacji \proc{Enqueue}. {\sffamily\bfseries(e)} Po usunięciu elementu z~kolejki $Q$ zmieniana jest jedynie pozycja atrybutu $\id{head}[Q]$, natomiast sam element pozostaje w~tablicy. {\sffamily\bfseries(f)} Wstawienie nowego elementu do kolejki $Q$ nadpisuje stary element, który został usunięty w~poprzednim kroku. {\sffamily\bfseries(g)} Kolejka $Q$ po wykonaniu ostatniej operacji \proc{Dequeue}.} \label{fig:10.1-3}
\end{figure}

\exercise %10.1-4
Poniżej znajduje się pseudokod operacji analogicznej do \proc{Stack-Empty}, ale testującej pustość kolejki. Wykorzystujemy ją podczas wykrywania błędów niedomiaru.

\begin{codebox}
\Procname{$\proc{Queue-Empty}(Q)$}
\li	\If $\id{head}[Q]=\id{tail}[Q]$
\li		\Then \Return \const{true}
\li		\Else \Return \const{false}
\End
\end{codebox}

Następujące wiersze należy dodać na początek procedury \proc{Enqueue}:
\begin{codebox}
\zi	\If $\id{head}[Q]=\id{tail}[Q]+1$
\zi		\Then \Error ,,nadmiar''
		\End
\zi	\If $\id{head}[Q]=1$ i~$\id{tail}[Q]=\id{length}[Q]$
\zi		\Then \Error ,,nadmiar''
		\End
\end{codebox}
Z~kolei poniższy fragment kodu umieszczamy na początku procedury \proc{Dequeue}:
\begin{codebox}
\zi	\If $\proc{Queue-Empty}(Q)$
\zi		\Then \Error ,,niedomiar''
		\End
\end{codebox}

\exercise %10.1-5
Kolejkę dwustronną implementujemy przy użyciu tablicy $D[1\twodots n]$. Podobnie jak w~zwykłej kolejce atrybut $\id{head}[D]$ wskazuje na początek kolejki, natomiast~atrybut $\id{tail}[D]$ wyznacza następną wolną pozycję, na którą można wstawić nowy element. Procedury \proc{Head-Enqueue} oraz \proc{Head-Dequeue} mają na celu, odpowiednio, dodanie nowego elementu na początek kolejki i~usunięcie elementu z~początku kolejki. Z~kolei procedury \proc{Tail-Enqueue} oraz \proc{Tail-Dequeue} implementują dodawanie i~usuwanie elementów na końcu kolejki. Dla skrócenia zapisu pominięto sprawdzanie błędów niedomiaru i~przepełnienia.

\begin{codebox}
\Procname{$\proc{Head-Enqueue}(D,x)$}
\li	\If $\id{head}[D]=1$
\li		\Then $\id{head}[D]\gets\id{length}[D]$
\li		\Else $\id{head}[D]\gets\id{head}[D]-1$
		\End
\li	$D[\id{head}[D]]\gets x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Head-Dequeue}(D)$}
\li	$x\gets D[\id{head[D]}]$
\li	\If $\id{head}[D]=\id{length}[D]$
\li		\Then $\id{head}[D]\gets1$
\li		\Else $\id{head}[D]\gets\id{head}[D]+1$
		\End
\li	\Return $x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Tail-Enqueue}(D,x)$}
\li	$D[\id{tail[D]}]\gets x$
\li	\If $\id{tail}[D]=\id{length}[D]$
\li		\Then $\id{tail}[D]\gets1$
\li		\Else $\id{tail}[D]\gets\id{tail}[D]+1$
		\End
\end{codebox}

\begin{codebox}
\Procname{$\proc{Tail-Dequeue}(D,x)$}
\li	\If $\id{tail}[D]=1$
\li		\Then $\id{tail}[D]\gets\id{length}[D]$
\li		\Else $\id{tail}[D]\gets\id{tail}[D]-1$
		\End
\li	\Return $D[\id{tail[D]}]$
\end{codebox}

Wszystkie powyższe operacje działają w~czasie $\Theta(1)$.

\exercise %10.1-6
Wszystkie elementy kolejki będą trzymane na jednym stosie -- drugi stos będzie pełnił funkcję pomocniczą. Dodawanie nowego elementu do kolejki oraz sprawdzanie czy kolejka jest pusta, nie różnią się od analogicznych operacji wykonywanych na pierwszym stosie. Usuwanie elementu z~kolejki jest już operacją nieco bardziej skomplikowaną, gdyż należy pobrać element znajdujący się najgłębiej na tym stosie. Ściągamy wpierw z~niego wszystkie elementy za pomocą operacji \proc{Pop} i~umieszczamy kolejno na drugim stosie, wywołując ciąg operacji \proc{Push}. W~rezultacie drugi stos będzie zawierał wszystkie elementy kolejki w~odwrotnej kolejności. Teraz pobieramy i zapamiętujemy element ze szczytu drugiego stosu, gdyż za chwilę zwrócimy go jako wynik procedury. Wcześniej trzeba bowiem przenieść pozostałą zawartość drugiego stosu z~powrotem do pierwszego, co przy okazji przywróci początkową kolejność elementów.

Łatwo sprawdzić, że testowanie pustości kolejki oraz dodawanie do niej nowego elementu, są wykonywane w~czasie stałym, natomiast usuwanie wymaga czasu proporcjonalnego do liczby elementów kolejki.

\exercise %10.1-7
Rozwiązanie jest analogiczne do rozwiązania poprzedniego zadania. Sprawdzanie czy stos jest pusty, jak również dodawanie nowego elementu, to identyczne operacje wywoływane na pierwszej kolejce. Usuwanie elementu ze stosu odbywa się poprzez pobranie wszystkich elementów z~wyjątkiem ostatniego z~pierwszej kolejki i~dodanie tych elementów do drugiej. Ostatni z~nich także usuwamy z~kolejki, zapamiętawszy go w~celu późniejszego zwrócenia jako wyniku operacji. Ostatnim krokiem jest przeniesienie reszty elementów z~powrotem do pierwszej kolejki.

Podobnie jak w~poprzednim zadaniu operacja odpowiedzialna za sprawdzenie czy stos jest pusty oraz dodawanie elementu działają w~czasie stałym, a~operacja usuwania -- w~czasie liniowym względem liczby elementów na stosie.

\subchapter{Listy}

\exercise %10.2-1
Operację \proc{Insert}, dodającą nowy element $x$ na początek listy jednokierunkowej $L$, można zaimplementować w~czasie stałym -- wystarczy ustawić pole $\id{next}[x]$ na głowę listy $L$ (albo na \const{nil}, jeśli lista $L$ jest pusta) i~uaktualnić wskaźnik $\id{head}[L]$. Operacja \proc{Delete}, czyli usuwanie z~listy jednokierunkowej elementu wskazywanego przez $x$, wymaga jednak czasu wyższego niż stały. Jest tak dlatego, że jedynym sposobem na dotarcie do elementu poprzedzającego $x$ na liście $L$ w~celu aktualizacji jego pola \id{next}, jest przejście tej listy od głowy aż do tegoż elementu. Czynność ta w~najgorszym przypadku zajmuje czas proporcjonalny do liczby elementów listy $L$.

Poniżej zamieszczamy implementacje obu tych operacji -- będziemy z~nich korzystać w~późniejszych zadaniach.
\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Insert}(L,x)$}
\li	$\id{next}[x]\gets\id{head}[L]$
\li	$\id{head}[L]\gets x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Delete}(L,x)$}
\li	\If $x=\id{head}[L]$
\li		\Then $\id{head}[L]\gets\id{next}[\id{head}[L]]$
\li		\Else
			$y\gets\id{head}[L]$
\li			\While $\id{next}[y]\ne x$
\li				\Do $y\gets\id{next}[y]$
				\End
\li			$\id{next}[y]\gets\id{next}[x]$
		\End
\end{codebox}

\exercise %10.2-2
Wszystkie elementy implementowanego stosu będziemy trzymać na liście jednokierunkowej $L$ w~kolejności od szczytu w~głowie listy do dna stosu w~ogonie. Dzięki takiemu rozwiązaniu operacje dodawania i~usuwania elementów będą działać w~czasie $\Theta(1)$. Sprawdzenie pustości stosu sprowadza się do sprawdzenia pustości listy $L$. Pseudokody operacji \proc{Push} i~\proc{Pop} prezentujemy poniżej.
\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Push}(L,k)$}
\li	$\id{key}[x]\gets k$
\li $\proc{Singly-Linked-List-Insert}(L,x)$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Pop}(L)$}
\li	\If $\id{head}[L]=\const{nil}$
\li		\Then \Error ,,niedomiar''
		\End
\li	$x\gets\id{head}[L]$
\li	$\id{head}[L]\gets\id{next}[x]$
\li	\Return $\id{key}[x]$
\end{codebox}

\exercise %10.2-3
Elementy kolejki będziemy przechowywać na liście jednokierunkowej $L$ w~kolejności od głowy kolejki do jej ogona. Aby jednak operacja dodawania była wykonalna w~czasie $\Theta(1)$, wymagane jest związanie z~listą $L$ dodatkowego atrybutu $\id{tail}[L]$, który będzie wskazywał na ogon listy $L$ albo na \const{nil}, jeżeli lista $L$ jest pusta. Oczywiście testowanie pustości kolejki polega na sprawdzeniu, czy pusta jest lista $L$. Implementacje operacji \proc{Enqueue} i~\proc{Dequeue} znajdują się poniżej.
\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Enqueue}(L,k)$}
\li	$\id{next}[x]\gets\const{nil}$
\li	$\id{key}[x]\gets k$
\li	\If $\id{tail}[L]\ne\const{nil}$
\li		\Then $\id{next}[\id{tail}[L]]\gets x$
\li		\Else $\id{head}[L]\gets x$
		\End
\li	$\id{tail}[L]\gets x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Dequeue}(L)$}
\li	\If $\id{head}[L]=\const{nil}$
\li		\Then \Error ,,niedomiar''
		\End
\li	$x\gets\id{head}[L]$
\li	$\id{head}[L]\gets\id{next}[x]$
\li	\If $\id{tail}[L]=x$
\li		\Then $\id{tail}[L]\gets\const{nil}$
		\End
\li	\Return $\id{key}[x]$
\end{codebox}

\exercise %10.2-4
Zauważmy, że pole $\id{key}[\id{nil}[L]]$ jest niewykorzystywane w~implementacji listy z~wartownikami. Możemy zatem na początku działania procedury \proc{List-Search}$'$ przypisać mu wartość $k$. Jeśli na liście $L$ nie będzie elementu o~wartości $k$, to pętla tej procedury zatrzyma się na elemencie $\id{nil}[L]$, po czym zostanie on zwrócony.

\exercise %10.2-5
Operacja wstawiania nowego elementu na jednokierunkową listę cykliczną $L$ umieszcza go jako następnik głowy listy $L$. Podczas operacji usuwania znajdowany jest poprzednik $y$ usuwanego elementu $x$, po czym $\id{next}[y]$ zostaje uaktualnione. Jeśli $x$ jest głową listy, to atrybut $\id{head}[L]$ zostaje ustawiony na następnik $x$ albo na \const{nil}, w~przypadku gdy $x$ stanowi jedyny element listy~$L$. Wreszcie operacja wyszukiwania przechodzi całą listę $L$, począwszy od jej głowy, zatrzymując się w~momencie odnalezienia elementu o~szukanym kluczu bądź w~chwili ponownego dotarcia do głowy listy $L$.

Poniższe procedury stanowią implementacje tych trzech operacji słownikowych.
\begin{codebox}
\Procname{$\proc{Cyclic-List-Insert}(L,x)$}
\li	\If $\id{head}[L]=\const{nil}$
\li		\Then $\id{head}[L]\gets\id{next}[x]\gets x$
\li		\Else
			$\id{next}[x]\gets\id{next}[\id{head}[L]]$
\li			$\id{next}[\id{head}[L]]\gets x$
		\End
\end{codebox}

\begin{codebox}
\Procname{$\proc{Cyclic-List-Delete}(L,x)$}
\li	$y\gets\id{head}[L]$
\li	\While $\id{next}[y]\ne x$
\li		\Do $y\gets\id{next}[y]$
		\End
\li	$\id{next}[y]\gets\id{next}[x]$
\li	\If $\id{head}[L]=x$
\li		\Then
			\If $\id{next}[x]=x$
\li				\Then $\id{head}[L]\gets\const{nil}$
\li				\Else $\id{head}[L]\gets\id{next}[x]$
				\End
		\End
\end{codebox}

\begin{codebox}
\Procname{$\proc{Cyclic-List-Search}(L,k)$}
\li	\If $\id{head}[L]=\const{nil}$
\li		\Then \Return \const{nil}
		\End
\li	\If $\id{key}[\id{head}[L]]=k$
\li		\Then \Return $\id{head}[L]$
		\End
\li	$x\gets\id{next}[\id{head}[L]]$
\li	\While $x\ne\id{head}[L]$
\li		\Do
			\If $\id{key}[x]=k$
\li				\Then \Return $x$
				\End
\li			$x\gets\id{next}[x]$
		\End
\li	\Return \const{nil}
\end{codebox}

Łatwo sprawdzić, że procedura implementująca operację \proc{Insert} działa w~czasie stałym, natomiast pozostałe dwie procedury dla listy o~$n$ elementach w~pesymistycznym przypadku potrzebują czasu $\Theta(n)$.

\exercise %10.2-6
Zbiory można zaimplementować jako jednokierunkowe listy cykliczne. Zbiory $S_1$ i~$S_2$ są rozłączne, więc w~reprezentacji sumy $S_1\cup S_2$ nie pojawią się powtarzające się elementy. Operacja \proc{Union} może więc tylko ,,sklejać'' listy reprezentujące zbiory $S_1$ i~$S_2$. Podczas działania tej operacji następnikiem głowy pierwszej listy staje się następnik głowy drugiej listy, a~następnikiem głowy drugiej staje się początkowy następnik głowy pierwszej. Oczywiście działania te są wykonywane tylko wtedy, gdy obie listy są niepuste. Wykonując stałą liczbę kroków, otrzymujemy w~wyniku tej operacji jednokierunkową listę cykliczną (której głową może być dowolny jej element) reprezentującą zbiór $S_1\cup S_2$.

\exercise %10.2-7
W~algorytmie wykorzystamy pomocniczą listę jednokierunkową $L'$, na którą będziemy umieszczać kolejno usuwane elementy z~głowy listy $L$. Łatwo zauważyć, że pod koniec operacji przeniesione elementy będą znajdować się w~$L'$ w~porządku odwrotnym względem początkowego ustawienia na liście $L$. Nadanie atrybutowi $\id{head}[L]$ wartości $\id{head}[L']$ wystarczy, aby przenieść całą zawartość listy $L'$ do listy $L$.
\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Reverse}(L)$}
\li	$\id{head}[L']\gets\const{nil}$
\li	\While $\id{head}[L]\ne\const{nil}$
\li		\Do
			$x\gets\id{head[L]}$
\li			$\proc{Singly-Linked-List-Delete}(L,\id{head[L]})$
\li			$\proc{Singly-Linked-List-Insert}(L',x)$
		\End
\li	$\id{head}[L]\gets\id{head}[L']$
\end{codebox}

Procedury \proc{Singly-Linked-List-Insert} i~\proc{Singly-Linked-List-Delete} zostały przedstawione w~\refExercise{10.2-1}. Ich wywołania w~powyższym algorytmie zajmują czas stały. Stąd czasem działania algorytmu jest $\Theta(n)$.

\exercise %10.2-8
Zgodnie z~opisem w~treści zadania przyjmijmy, że każdy element listy zamiast wskaźników na poprzednik i~następnik posiada atrybut \id{np}, będący alternatywą wykluczającą tych dwóch wskaźników. Załóżmy, że znamy adres elementu $x$ listy $L$ i~elementu $y$ będącego poprzednikiem $x$ na liście $L$. Niech $z$ będzie następnikiem $x$ na tej liście. Wówczas $\id{np}[x]=z\func{xor}y$, zatem na podstawie własności operacji \func{xor}, aby dostać się do $z$, wystarczy obliczyć wartość
\[
    z = z\func{xor}0 = z\func{xor}(y\func{xor}y) = (z\func{xor}y)\func{xor}y = \id{np}[x]\func{xor}y.
\]
Podobnie ma się rzecz podczas wyznaczania $y$ na podstawie $x$ i~$z$ -- wówczas $y=\id{np}[x]\func{xor}z$. Zauważmy, że jeśli element $x$ jest ogonem listy, to $\id{np}[x]=\const{nil}\func{xor}y=0\func{xor}y=y$, skąd mamy $z=\id{np}[x]\func{xor}y=0=\const{nil}$ i~analogicznie dla głowy listy, z~faktu, że $\id{np}[x]=z\func{xor}0=z$ wynika $y=\const{nil}$. Podobnie jak w~zwykłych listach przyjmujemy, że atrybut $\id{head}[L]$ przechowuje wskaźnik do głowy listy~$L$. Ponadto z~listą związujemy atrybut $\id{tail}[L]$, który będzie wskazywał na jej ogon -- jest on konieczny do tego, aby operacja odwracania kolejności elementów na liście działała w~czasie stałym.

Poniżej przedstawiono procedury implementujące operacje \proc{Search}, \proc{Insert} i~\proc{Delete} dla takiej listy.
\begin{codebox}
\Procname{$\proc{Xor-List-Search}(L,k)$}
\li	$x\gets\id{head}[L]$
\li	$y\gets\const{nil}$
\li	\While $x\ne\const{nil}$ i~$\id{key}[x]\ne k$
\li		\Do
			$z\gets\id{np}[x]\func{xor}y$
\li			$y\gets x$
\li			$x\gets z$
		\End
\li	\Return $x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Xor-List-Insert}(L,x)$}
\li	$\id{np}[x]\gets\id{head}[L]$
\li	\If $\id{head}[L]\ne\const{nil}$
\li		\Then $\id{np}[\id{head}[L]]\gets\id{np}[\id{head}[L]]\func{xor}x$
		\End
\li	$\id{head}[L]\gets x$
\li	\If $\id{tail}[L]=\const{nil}$
\li		\Then $\id{tail}[L]\gets x$
		\End
\end{codebox}

\begin{codebox}
\Procname{$\proc{Xor-List-Delete}(L,x)$}
\li	$x'\gets\id{head}[L]$
\li	$y\gets\const{nil}$
\li	\While $x'\ne x$
\li		\Do
			$z\gets\id{np}[x']\func{xor}y$
\li			$y\gets x'$
\li			$x'\gets z$
		\End
\li	$z\gets\id{np}[x]\func{xor}y$
\li	\If $y\ne\const{nil}$
\li		\Then $\id{np}[y]\gets\id{np}[y]\func{xor}x\func{xor}z$
		\End
\li	\If $z\ne\const{nil}$
\li		\Then $\id{np}[z]\gets\id{np}[z]\func{xor}x\func{xor}y$
		\End
\li	\If $x=\id{head}[L]$
\li		\Then $\id{head}[L]\gets z$
		\End
\li	\If $x=\id{tail}[L]$
\li		\Then $\id{tail}[L]\gets y$
		\End
\end{codebox}

Procedury \proc{Xor-List-Search} i~\proc{Xor-List-Insert} są analogiczne do swoich odpowiedników dla zwykłej listy dwukierunkowej i~pesymistyczny czas ich działania wynosi odpowiednio $\Theta(n)$ oraz $\Theta(1)$. W~procedurze \proc{Xor-List-Delete} należy odszukać na liście poprzednika i~następnika elementu $x$, aby uaktualnić ich pola \id{np}, co w~pesymistycznym przypadku zajmuje czas $\Theta(n)$. Odwracanie kolejności elementów -- zarówno w~zwykłej liście dwukierunkowej, jak i~w~tak zmodyfikowanej liście -- jest możliwe w~czasie $\Theta(1)$. W~tym celu wystarczy zamienić ze sobą wartości atrybutów $\id{head}[L]$ i~$\id{tail}[L]$. 

\subchapter{Reprezentowanie struktur wskaźnikowych za pomocą tablic}

\exercise %10.3-1
Rys.~\ref{fig:10.3-1} przedstawia przykładowe rozmieszczenie elementów ciągu w~reprezentacji wielotablicowej listy dwukierunkowej i~jednokierunkowej.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig10.3}
	\end{center}
	\caption{Reprezentacja wielotablicowa ciągu $\langle13,4,8,19,5,11\rangle$. {\sffamily\bfseries(a)} Ciąg przechowywany w~tablicach \id{key}, \id{next} oraz \id{prev} jako lista dwukierunkowa. {\sffamily\bfseries(b)} To samo rozmieszczenie elementów ciągu, ale bez wykorzystania tablicy \id{prev}, czyli w~postaci listy jednokierunkowej.} \label{fig:10.3-1}
\end{figure}

\exercise %10.3-2
Załóżmy, że właściwa lista oraz lista wolnych pozycji znajdują się w~pojedynczej tablicy $A$. Poniższe procedury są adaptacjami operacji przydzielania i~zwalniania pamięci dla list dwukierunkowych w~reprezentacji jednotablicowej. Wykorzystujemy tutaj fakt, że polu \id{next} odpowiada przesunięcie~1 względem początku fragmentu tablicy $A$ przechowującego dany element listy.
\begin{codebox}
\Procname{$\proc{Single-Array-Allocate-Object}(A)$}
\li	\If $\id{free}=\const{nil}$
\li		\Then \Error ,,brak pamięci''
		\End
\li	$i\gets\id{free}$
\li	$\id{free}\gets A[i+1]$
\li	\Return $i$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Single-Array-Free-Object}(A,i)$}
\li	$A[i+1]\gets\id{free}$
\li	$\id{free}\gets i$
\end{codebox}

\exercise %10.3-3
Lista wolnych pozycji jest listą jednokierunkową -- nie są więc wykorzystywane w~niej pola \id{prev}.

\exercise %10.3-4
Korzystając ze wskazówki z~treści zadania, zaimplementujemy listę wolnych pozycji jako stos. Będzie on zajmował wszystkie pozycje na prawo od tej wskazywanej przez \id{free} -- jego wierzchołka. Stos jest pusty wtedy i~tylko wtedy, gdy $\id{free}=\const{nil}$. Przydzielanie pamięci polega na wywołaniu na stosie wolnych pozycji operacji \proc{Pop}, a~więc nie różni się od oryginalnej wersji. Z~kolei zwalnianie pamięci to wywołanie na tym stosie operacji \proc{Push}. Wcześniej jednak należy zamienić zwalniany element z~tym, który znajduje się bezpośrednio na lewo od wierzchołka stosu.
\begin{codebox}
\Procname{$\proc{Compact-List-Free-Object}(x)$}
\li	\If $\id{free}=\const{nil}$
\li		\Then $y\gets n$
\li		\Else $y\gets\id{free}-\,1$
		\End
\li	skopiuj wartości pól \id{key}, \id{next} i~\id{prev} elementu $y$ do pól elementu $x$
\li	\If $\id{next}[y]\ne\const{nil}$
\li		\Then $\id{prev}[\id{next}[y]]\gets x$
		\End
\li	\If $\id{prev}[y]\ne\const{nil}$
\li		\Then $\id{next}[\id{prev}[y]]\gets x$
		\End
\li	\If $L=y$
\li		\Then $L\gets x$
		\End
\li	$\proc{Free-Object}(y)$
\end{codebox}

\exercise %10.3-5
Ogólny zarys procedury \proc{Compactify-List} jest następujący. Podczas przechodzenia listy $L$ wyznaczane są te elementy, które zajmują pozycje na prawo od $m$. Wszystkie one muszą być zamienione z~elementami listy $F$ znajdującymi się na pozycjach do $m$ włącznie. Aby zachować czas $\Theta(m)$, procedura nie może przechodzić po liście $F$, która składa się z~$n-m$ elementów. Zamiast tego będzie ona przeszukiwać liniowo tablice implementujące listy i~wyznaczać rekordy należące do listy wolnych pozycji. Jednym ze sposobów rozróżniania elementów list $L$ i~$F$ jest wykorzystanie wskaźników \id{prev}. Na początku działania procedury do pól \id{prev} wszystkich elementów listy $L$ zostanie wpisana pewna specjalna wartość, np.\ $n+1$. Przechodząc później przez listę $L$, wskaźnikom \id{prev} zostaną nadane właściwe wartości, ale wpierw pola te posłużą do identyfikacji elementów listy.
\begin{codebox}
\Procname{$\proc{Compactify-List}(L,F)$}
\li	$n\gets\id{length}[\id{key}]$
\li	wpisz $n+1$ do pól \id{prev} elementów listy $L$ i~wyznacz liczbę jej elementów $m$ \label{li:compactify-list-preprocess}
\li $x\gets L$
\li	$x'\gets\const{nil}$
\li	$y\gets1$
\li	\While $x\ne\const{nil}$ \label{li:compactify-list-while-begin}
\li		\Do
			\If $x\le m$
\li				\Then
					$x'\gets x$
\li					$x\gets\id{next}[x]$
\li				\Else
					\While $\id{prev}[y]=n+1$ \label{li:compactify-list-while2-begin}
\li						\Do $y\gets y+1$
						\End \label{li:compactify-list-while2-end}
\li					zamień wartości pól \id{key}, \id{next} i~\id{prev} elementu $x$ z~polami elementu $y$ \label{li:compactify-list-swap}
\li					\If $\id{next}[x]\ne\const{nil}$ \label{li:compactify-list-fix-neighbors-begin}
\li						\Then $\id{prev}[\id{next}[x]]\gets x$
						\End
\li					\If $\id{prev}[x]\ne\const{nil}$
\li						\Then $\id{next}[\id{prev}[x]]\gets x$
						\End \label{li:compactify-list-fix-neighbors-end}
\li					\If $x'\ne\const{nil}$ \label{li:compactify-list-fix-predecessor-begin}
\li						\Then $\id{next}[x']\gets y$
						\End \label{li:compactify-list-fix-predecessor-end}
\li					\If $L=x$ \label{li:compactify-list-fix-heads-begin}
\li						\Then $L\gets y$
						\End
\li					\If $F=y$
\li						\Then $F\gets x$
						\End \label{li:compactify-list-fix-heads-end}
\li					$x'\gets y$
\li					$x\gets\id{next}[y]$
				\End
		\End \label{li:compactify-list-while-end}
\li	przywróć poprawne wartości w~polach \id{prev} elementów listy $L$ \label{li:compactify-list-postprocess}
\end{codebox}

Procedura przechodzi listę $L$ trzy razy. Najpierw w~wierszu~\ref{li:compactify-list-preprocess} tablice przechowujące listy $L$ i~$F$ są przygotowywane do właściwego przetwarzania poprzez ustawienie pól \id{prev} wszystkich elementów listy $L$ na wartość $n+1$. W~tym samym kroku można przy okazji wyznaczyć $m$ -- rozmiar listy $L$.

Kolejne przejście po liście to właściwe kompaktowanie. Jeśli dany element $x$ listy $L$ zajmuje w~tablicach pozycję wyższą niż $m$, to zostaje zamieniony z~elementem $y$ listy $F$ znajdującym się najbardziej na lewo. Pętla \kw{while} w~wierszach \twodashes{\ref{li:compactify-list-while2-begin}}{\ref{li:compactify-list-while2-end}} wyznacza $y$ poprzez liniowe przeglądanie tablicy \id{prev}, po czym w~wierszu~\ref{li:compactify-list-swap} elementy $x$ i~$y$ zamieniają swoje pozycje. Należy jeszcze uaktualnić wartości pól \id{prev} i~\id{next} elementów sąsiednich na liście $F$ (wiersze \twodashes{\ref{li:compactify-list-fix-neighbors-begin}}{\ref{li:compactify-list-fix-neighbors-end}}), wartość pola \id{next} poprzednika $x$ na liście $L$ (wiersze \twodashes{\ref{li:compactify-list-fix-predecessor-begin}}{\ref{li:compactify-list-fix-predecessor-end}}), jak również wartości wskaźników $L$ i~$F$, w~przypadku gdy wśród zamienianych elementów była głowa którejś z~list (wiersze \twodashes{\ref{li:compactify-list-fix-heads-begin}}{\ref{li:compactify-list-fix-heads-end}}).

Ostatnim krokiem procedury jest ponowne przejście przez listę $L$ w~wierszu~\ref{li:compactify-list-postprocess} i~przywrócenie odpowiednich wartości w~polach \id{prev} wszystkich jej elementów.

\subchapter{Reprezentowanie drzew (ukorzenionych)}

\exercise %10.4-1
Drzewo binarne, którego reprezentacją są podane tablice, przedstawiono na rys.~\ref{fig:10.4-1}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig10.4}
	\end{center}
	\caption{Drzewo binarne o~korzeniu o~indeksie~6 reprezentowane przez tablice \id{key}, \id{left} i~\id{right}.} \label{fig:10.4-1}
\end{figure}

\exercise %10.4-2
Szukany algorytm został opisany w~Podręczniku w~podrozdziale~12.1 jako procedura \proc{Inorder-Tree-Walk}. Czas działania tego algorytmu dla drzewa o~$n$ węzłach wynosi $\Theta(n)$ -- mówi o~tym tw.~12.1 z~Podręcznika.

\exercise %10.4-3
Przedstawiona poniżej procedura stanowi nierekurencyjną implementację algorytmu przechodzenia drzewa metodą preorder (patrz podrozdział~12.1). Do emulowania rekursji wykorzystywany jest stos. Każdy węzeł drzewa jest dokładnie raz wstawiany na stos i~dokładnie raz z~niego usuwany, stąd czas działania tej procedury dla drzewa o~$n$ węzłach wynosi $\Theta(n)$.
\begin{codebox}
\Procname{$\proc{Iterative-Preorder-Tree-Walk}(T)$}
\li	\If $\id{root}[T]=\const{nil}$
\li		\Then \Return
		\End
\li	$\proc{Push}(S,\id{root}[T])$
\li	\While $\proc{Stack-Empty}(S)=\const{false}$
\li		\Do
			$x\gets\proc{Pop}(S)$
\li			wypisz $\id{key}[x]$
\li			\If $\id{right}[x]\ne\const{nil}$
\li				\Then $\proc{Push}(S,\id{right}[x])$
				\End
\li			\If $\id{left}[x]\ne\const{nil}$
\li				\Then $\proc{Push}(S,\id{left}[x])$
				\End
		\End
\end{codebox}

\exercise %10.4-4
Nasza procedura będzie przyjmować węzeł $x$ drzewa w~reprezentacji ,,na lewo syn, na prawo brat'' i~wypisywać wszystkie klucze z~poddrzewa o~korzeniu w~$x$. Najpierw zostanie wypisany klucz węzła $x$, a~następnie procedura zostanie wywołana rekurencyjnie kolejno dla każdego syna węzła $x$.
\begin{codebox}
\Procname{$\proc{Rooted-Tree-Walk}(x)$}
\li	\If $x=\const{nil}$
\li		\Then \Return
		\End
\li	wypisz $\id{key}[x]$
\li	$y\gets\id{left-child}[x]$
\li	\While $y\ne\const{nil}$
\li		\Do
			$\proc{Rooted-Tree-Walk}(y)$
\li			$y\gets\id{right-sibling}[y]$
		\End
\end{codebox}
Aby wypisać wszystkie klucze drzewa $T$ w~reprezentacji ,,na lewo syn, na prawo brat'', należy wywołać $\proc{Rooted-Tree-Walk}(\id{root}[T])$.

Każdy klucz drzewa zostaje wypisany dokładnie raz, a~na każdym poziomie rekursji (być może z~wyjątkiem pierwszego) przetwarzane jest niepuste poddrzewo. Stąd wnioskujemy, że procedura wypisze wszystkie $n$ kluczy drzewa w~czasie $\Theta(n)$.

\exercise %10.4-5
W~procedurze wykorzystamy zmienną \id{direction} przyjmującą ,,kierunek'', w~którym obecnie poruszamy się po drzewie, wypisując jego klucze. Zmienna ta będzie przyjmować jedną z~czterech wartości:
\begin{itemize}
    \item \const{sw} -- kierunek w~dół drzewa do lewego syna;
    \item \const{se} -- kierunek w~dół drzewa do prawego syna;
    \item \const{ne} -- kierunek w~górę drzewa z~lewego syna;
    \item \const{nw} -- kierunek w~górę drzewa z~prawego syna.
\end{itemize}
W~zależności od wartości tej zmiennej kolejnym odwiedzanym węzłem będzie lewy syn, prawy syn albo ojciec bieżącego węzła, po czym wartość tej zmiennej zostanie odpowiednio zaktualizowana, gdyż przejście do nowego węzła mogło być w~innym kierunku od tego, po którym dotychczas przechodziliśmy po drzewie.

Zaczynając od korzenia, początkowo poruszamy się w~dół drzewa ($\id{direction}=\const{sw}$), aż osiągniemy jego najbardziej lewy liść. Wracając w~górę drzewa, odwiedzamy tą samą metodą każde nieodwiedzone prawe poddrzewo. Węzły wypisywane są podczas ich odwiedzania, gdy $\id{direction}=\const{sw}$ lub $\id{direction}=\const{se}$. Struktura drzewa nie jest zmieniana i~łatwo zauważyć, że każdy z~$n$ węzłów jest odwiedzany co najwyżej trzy razy (podczas przechodzenia do jego lewego i~prawego poddrzewa, i~podczas powrotu), zatem procedura działa w~czasie $\Theta(n)$.

Opisany algorytm zapisujemy w~postaci pseudokodu:
\begin{codebox}
\Procname{$\proc{Binary-Tree-Walk}(T)$}
\li	$x\gets\id{root}[T]$
\li	$\id{direction}\gets\const{sw}$
\li	\While $x\ne\const{nil}$
\li		\Do
			\If $\id{direction}=\const{sw}$
\li				\Then
					wypisz $\id{key}[x]$
\li					\If $\id{left}[x]\ne\const{nil}$
\li						\Then $x\gets\id{left}[x]$
\li					\ElseIf $\id{right}[x]\ne\const{nil}$
\li						\Then
							$x\gets\id{right}[x]$
\li							$\id{direction}\gets\const{se}$
\li					\ElseNoIf $x\gets\id{p}[x]$
						\End
\li						\phantom{\kw{else}} $\id{direction}\gets\const{ne}$
\li			\ElseIf $\id{direction}=\const{se}$
\li				\Then
					wypisz $\id{key}[x]$
\li					\If $\id{left}[x]\ne\const{nil}$
\li						\Then
							$x\gets\id{left}[x]$
\li							$\id{direction}\gets\const{sw}$
\li					\ElseIf $\id{right}[x]\ne\const{nil}$
\li						\Then $x\gets\id{right}[x]$
\li					\ElseNoIf $x\gets\id{p}[x]$
						\End
\li						\phantom{\kw{else}} $\id{direction}\gets\const{nw}$
\li			\ElseIf $\id{direction}=\const{ne}$
\li				\Then
					\If $\id{right}[x]\ne\const{nil}$
\li						\Then
							$x\gets\id{right}[x]$
\li							$\id{direction}\gets\const{se}$
\li						\Else
							\If $\id{p}[x]\ne\const{nil}$ i~$\id{right}[\id{p}[x]]=x$
\li								\Then $\id{direction}\gets\const{nw}$
								\End
\li							$x\gets\id{p}[x]$
						\End
\li			\ElseNoIf \If $\id{p}[x]\ne\const{nil}$ i~$\id{left}[\id{p}[x]]=x$
				\End
\li				\phantom{\kw{else} \kw{if}} \kw{then} $\id{direction}\gets\const{ne}$
\li				\phantom{\kw{else}} $x\gets\id{p}[x]$
		\End
\end{codebox}

\exercise %10.4-6
Ponieważ nie wymagamy dostępu do ojca danego węzła w~stałym czasie, to możemy wyeliminować atrybut $p$. Zauważmy ponadto, że w~reprezentacji ,,na lewo syn, na prawo brat'', jeśli węzeł $x$ jest najbardziej prawym synem swojego ojca, to $\id{right-sibling}[x]=\const{nil}$. Wykorzystamy ten wskaźnik w~węźle $x$, pokazując nim na ojca $x$. Aby móc jednoznacznie określać, czy węzeł wskazywany przez ten atrybut jest bratem, czy ojcem $x$, wykorzystamy dodatkowe pole -- zmienną boolowską -- określającą parzystość poziomu zajmowanego w~drzewie przez dany węzeł.

Nazwijmy następująco atrybuty każdego węzła $x$ w~nowej reprezentacji:
\begin{itemize}
	\item $\id{child}[x]$ -- wskazuje na najbardziej lewego syna $x$ (identyczny z~$\id{left-child}[x]$ z~reprezentacji ,,na lewo syn, na prawo brat'');
	\item $\id{next}[x]$ -- wskazuje na kolejnego brata węzła $x$ albo na ojca węzła $x$, jeśli $x$ jest najbardziej prawym synem swojego ojca;
	\item $\id{level-parity}[x]$ -- zmienna boolowska przyjmująca wartość \const{true}, jeżeli węzeł $x$ znajduje się w~drzewie na poziomie parzystym, albo \const{false} w~przeciwnym przypadku.
\end{itemize}

Oczywiście dla dowolnego węzła i~jego ojca wartości ich atrybutów \id{level-parity} różnią się. Dzięki temu, mając dany węzeł $x$, można przechodzić po jego braciach, poruszając się po wskaźnikach \id{next}, aż dotrze się do ojca $x$, którego rozróżnimy od braci $x$ na podstawie wartości atrybutu \id{level-parity}. Wyznaczenie ojca $x$ wymaga więc w~najgorszym przypadku czasu proporcjonalnego do liczby braci węzła $x$, a~wyznaczenie wszystkich synów $x$ -- czasu proporcjonalnego do ilości jego synów.

\problems

\problem{Porównanie list} %10-1
Tabela~\ref{tab:10-1} zawiera pesymistyczne czasy poszczególnych operacji słownikowych dla danych czterech typów list. Przyjmujemy, że operacje wykonywane są na listach o~rozmiarach $n$.

\begin{table}[ht]
	\begin{center}
		\[
			\begin{array}{l|c|c|c|c}
				& \text{Nieposortowana} & \text{Posortowana} & \text{Nieposortowana} & \text{Posortowana} \\
				& \text{jedno-} & \text{jedno-} & \text{dwu-} & \text{dwu-} \\
				& \text{kierunkowa} & \text{kierunkowa} & \text{kierunkowa} & \text{kierunkowa} \\
				\hline
				\proc{Search}(L,k) & \Theta(n) & \Theta(n) & \Theta(n) & \Theta(n) \\
				\hline
				\proc{Insert}(L,x) & \Theta(1) & \Theta(n) & \Theta(1) & \Theta(n) \\
				\hline
				\proc{Delete}(L,x) & \Theta(n) & \Theta(n) & \Theta(1) & \Theta(1) \\
				\hline
				\proc{Successor}(L,x) & \Theta(n) & \Theta(1) & \Theta(n) & \Theta(1) \\
				\hline
				\proc{Predecessor}(L,x) & \Theta(n) & \Theta(n) & \Theta(n) & \Theta(1) \\
				\hline
				\proc{Minimum}(L) & \Theta(n) & \Theta(1) & \Theta(n) & \Theta(1) \\
				\hline
				\proc{Maximum}(L) & \Theta(n) & \Theta(n) & \Theta(n) & \Theta(n)
			\end{array}
		\]
	\end{center}
	\caption{Porównanie złożoności operacji słownikowych dla różnych typów list.} \label{tab:10-1}
\end{table}
Jeśli w~implementacjach list będziemy dodatkowo utrzymywać atrybut \id{tail} wskazujący na ogon listy, to operację \proc{Maximum} dla list posortowanych możemy wykonywać w~czasie stałym.

\problem{Listowa reprezentacja kopców złączalnych} %10-2

\subproblem %10-2(a)
Kopiec zaimplementujemy jako posortowaną listę dwukierunkową. Operacja \proc{Make-Heap} tworzy pustą listę, co zajmuje oczywiście czas stały. Dodanie elementu do kopca polega na dodaniu go do listy. Aby zachować jej uporządkowanie, jak również sprawdzić, czy klucz wstawianego elementu nie znajduje się już w~kopcu, musimy odnaleźć miejsce, które ewentualnie zajmie nowy element, co w~pesymistycznym przypadku wymaga czasu $\Theta(n)$. Dzięki uporządkowaniu listy można podać implementacje operacji \proc{Minimum} i~\proc{Extract-Min} działające w~czasie $\Theta(1)$. Łączenie kopców sprowadza się do scalenia dwóch posortowanych list przy jednoczesnym usunięciu zduplikowanych elementów. Stosując w~tym celu procedurę \proc{Merge} z~rozdziału~2 (dostosowaną do list dwukierunkowych), jesteśmy w~stanie zaimplementować operację \proc{Union}, aby działała w~czasie $\Theta(n)$, gdzie $n$ jest liczbą elementów na wynikowej liście.

\subproblem %10-2(b)
W~tym przypadku użyjemy kopca Fibonacciego (patrz rozdział~20), którego implementacja korzysta z~list cyklicznych (nieposortowanych). Należy jednak pamiętać, że w~danym momencie w~kopcu powinny znajdować się elementy parami różne, dlatego w~operacjach \proc{Insert} i~\proc{Union} musimy wykrywać przypadki, gdy w~kopcu może pojawić się duplikat.

Zarówno utworzenie pustego kopca, jak i~odczytanie jego minimalnego elementu zajmuje czas stały, natomiast usunięcie minimalnego elementu -- czas $\Theta(\lg n)$. Dodanie nowego elementu zostanie poprzedzone przeglądnięciem wszystkich elementów kopca i~porównaniu ich z~tym, który zamierzamy dodać -- implementacja \proc{Insert} wymaga więc czasu $\Theta(n)$. Operacja \proc{Union} będzie tworzyć nowy kopiec, pobierając aktualne minimalne elementy z~kopców wejściowych operacją \proc{Extract-Min}, aż do opróżnienia obu kopców. Jeśli podczas działania procedury w~danym momencie aktualne minima będą sobie równe, to do wynikowego kopca wstawiony zostanie tylko jeden egzemplarz. \proc{Union} można zatem zrealizować w~czasie $\Theta(n\lg n)$, gdzie $n$ jest sumą rozmiarów kopców wejściowych.

\subproblem %10-2(c)
Przypadek jest identyczny z~poprzednim, ale tym razem nie jest wymagane wykrywanie powtórzeń w~operacjach \proc{Insert} i~\proc{Union}. Z~tego powodu wszystkie omawiane operacje kopca działają w~zamortyzowanym koszcie $\Theta(1)$ oprócz \proc{Extract-Min}, która działa w~zamortyzowanym koszcie $\Theta(\lg n)$.

\problem{Wyszukiwanie na posortowanej liście zajmującej spójny obszar pamięci (liście upakowanej)} %10-3
\note{W~tłumaczeniu w~pseudokodzie procedury \proc{Compact-List-Search} jest błąd -- w linijce~4 zamiast testowania, czy\/ $\id{key}[j]<k$ powinno być sprawdzenie, czy\/ $\id{key}[j]\le k$. Ponadto w~wywołaniach procedur \proc{Compact-List-Search} i~\proc{Compact-List-Search}$'$ na liście ich argumentów brakuje\/ $n$ jako drugiego argumentu.}

\subproblem %10-3(a)

\subproblem %10-3(b)
Niech $Y$ będzie zmienną losową oznaczającą ilość wykonanych iteracji pętli \kw{for} w~procedurze \proc{Compact-List-Search}$'$. Zauważmy, że $Y=q$ wtedy i~tylko wtedy, gdy pierwszym losowo wybranym indeksem $j$ równym indeksowi klucza $k$ na liście $L$ jest ten uzyskany w~\onedash{$q$}{tej} iteracji. Mamy zatem, że oczekiwaną liczbą iteracji pętli \kw{for} jest
\[
	\sum_{q=1}^tq\Pr(Y=q) = \sum_{q=1}^tq\biggl(1-\frac{1}{n}\biggr)^{q-1}\frac{1}{n} < \sum_{q=1}^tn\cdot1\cdot\frac{1}{n} = t.
\]
Na podstawie definicji zmiennej losowej $X_t$ otrzymujemy z~kolei, że średnia liczba wykonanych iteracji pętli \kw{while} wynosi $\E(X_t)$. A~zatem oczekiwanym czasem działania procedury \proc{Compact-List-Search}$'$ jest $O(t+\E(X_t))$.

\subproblem %10-3(c)
Oznaczmy przez $s$ pozycję klucza $k$ na liście $L$, a~przez $j_1$, $j_2$,~\dots,~$j_t$ -- ciąg liczb całkowitych wyznaczonych przez $t$ wywołań $\proc{Random}(1,n)$. Po $t$ iteracjach pętli \kw{for} odległość od pozycji $i$ do pozycji $s$ na liście $L$ będzie większa lub równa $r$, jeśli dla każdego $q=1$, 2,~\dots,~$t$, $j_q\le s-r$ lub $j_q>s$. Mamy więc
\[
	\Pr(X_t\ge r) = \prod_{q=1}^t\Pr(j_q\le s-r\;\;\text{lub}\;\;j_q>s) = \prod_{q=1}^t\frac{n-r}{n} = \biggl(1-\frac{r}{n}\biggr)^t.
\]
Korzystając z~tożsamości~(C.24) i~z~powyższego oszacowania, otrzymujemy
\[
	\E(X_t) = \sum_{r=1}^n\Pr(X_t\ge r) = \sum_{r=1}^n\biggl(1-\frac{r}{n}\biggr)^t.
\]

\subproblem %10-3(d)
Sumę po lewej stronie ograniczamy całką, otrzymując:
\[
	\sum_{r=0}^{n-1}r^t \le \int_0^nx^t\,dx = \biggl[\frac{x^{t+1}}{t+1}\biggr]_0^n = \frac{n^{t+1}}{t+1}.
\]

\subproblem %10-3(e)
Na podstawie punktów~(c) i~(d) mamy:
\[
	\E(X_t) \le \sum_{r=1}^n\biggl(1-\frac{r}{n}\biggr)^t = \sum_{r=1}^{n-1}\biggl(\frac{n-r}{n}\biggr)^t = \sum_{r=1}^{n-1}\biggl(\frac{r}{n}\biggr)^t = \frac{\sum_{r=0}^{n-1}r^t}{n^t} \le \frac{\frac{n^{t+1}}{t+1}}{n^t} = \frac{n}{t+1}.
\]

\subproblem %10-3(f)
Na mocy punktów~(b) i~(e) dostajemy, że oczekiwany czas działania procedury \proc{Compact-List-Search}$'(L,n,k,t)$ wynosi $O(t+\E(X_t))=O(t+n/(t+1))=O(t+n/t)$.

\subproblem %10-3(g)

\subproblem %10-3(h)
Jeśli dopuścimy, aby elementy na liście powtarzały się, to może dojść do sytuacji, w~której procedura próbuje wykonać skok na pozycję $j>i$, ale nie wykonuje go, gdyż stwierdza w~linii~4, że $\id{key}[i]=\id{key}[j]$. Jeśli każdy losowy skok będzie eliminowany na tej podstawie, to działanie procedury sprowadzi się do działania zwykłego algorytmu wyszukiwania na posortowanej liście.

\endinput