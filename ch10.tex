\chapter{Elementarne struktury danych}

\subchapter{Stosy i~kolejki}

\exercise %10.1-1
Ciąg operacji na stosie $S$ został przedstawiony na rys.~\ref{fig:10.1-1}.
\begin{figure}[ht]
    \begin{center}
		\includegraphics{fig_10.1-1}
	\end{center}
	\caption{Operacje wstawiania i~usuwania elementów na stosie $S$. {\sffamily\bfseries(a)} Pusty stos $S$ reprezentowany jako tablica $S[1\twodots6]$. {\sffamily\bfseries\doubledash{(b)}{(d)}} Stos $S$ po wykonaniu na nim kolejnych operacji \proc{Push}. {\sffamily\bfseries(e)} Po usunięciu elementu ze stosu $S$ zmieniana jest jedynie pozycja atrybutu \attrib{S}{top}, natomiast sam element pozostaje w~tablicy. {\sffamily\bfseries(f)} Wstawienie nowego elementu na stos $S$ nadpisuje stary element, który został usunięty w~poprzednim kroku. {\sffamily\bfseries(g)} Stos $S$ po wykonaniu ostatniej operacji \proc{Pop}.} \label{fig:10.1-1}
\end{figure}

\exercise %10.1-2
Z~tablicą $A$ związujemy atrybuty \attrib{A}{left-top} i~\attrib{A}{right-top}, które będą wskazywać na pozycje wierzchołków, odpowiednio, pierwszego i~drugiego stosu. Pierwszy stos będzie składał się z~elementów $A[1\twodots\attrib{A}{left-top}]$, a~drugi -- z~elementów $A[\attrib{A}{right-top}\twodots n]$. Początkowo $\attrib{A}{left-top}=0$ i~$\attrib{A}{right-top}=n+1$. Dodawanie i~usuwanie elementów w~pierwszym stosie działa identycznie jak dla pojedynczego stosu znajdującego się w~tablicy $A$, którego wierzchołek zajmuje pozycję \attrib{A}{left-top}. Drugi stos zachowuje się symetrycznie do pierwszego -- podczas dodawania do niego nowego elementu atrybut \attrib{A}{right-top} będzie dekrementowany, a~podczas usuwania -- inkrementowany. Operacje dodawania i~usuwania elementów działają oczywiście w~czasie stałym. Jeśli $\attrib{A}{left-top}=0$, to pierwszy stos jest pusty, a~jeśli $\attrib{A}{right-top}=n+1$, to drugi stos jest pusty. Przepełnienie ma miejsce tylko wtedy, gdy $\attrib{A}{left-top}=\attrib{A}{right-top}-1$ i~usiłujemy dodać nowy element do któregokolwiek stosu, czyli wówczas, gdy łączna liczba elementów na obu stosach wynosi $n$.

\exercise %10.1-3
Ciąg operacji na kolejce $Q$ ilustruje rys.~\ref{fig:10.1-3}.

\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig_10.1-3}
	\end{center}
	\caption{Operacje wstawiania i~usuwania elementów na kolejce $Q$. {\sffamily\bfseries(a)} Pusta kolejka $Q$ reprezentowana jako tablica $Q[1\twodots6]$. {\sffamily\bfseries\doubledash{(b)}{(d)}} Kolejka $Q$ po wykonaniu na niej kolejnych operacji \proc{Enqueue}. {\sffamily\bfseries(e)} Po usunięciu elementu z~kolejki $Q$ zmieniana jest jedynie pozycja atrybutu \attrib{Q}{head}, natomiast sam element pozostaje w~tablicy. {\sffamily\bfseries(f)} Wstawienie nowego elementu do kolejki $Q$ nadpisuje stary element, który został usunięty w~poprzednim kroku. {\sffamily\bfseries(g)} Kolejka $Q$ po wykonaniu ostatniej operacji \proc{Dequeue}.} \label{fig:10.1-3}
\end{figure}

\exercise %10.1-4
Poniżej znajduje się pseudokod operacji analogicznej do \proc{Stack-Empty}, ale testującej pustość kolejki. Wykorzystujemy ją podczas wykrywania błędów niedomiaru.

\begin{codebox}
\Procname{$\proc{Queue-Empty}(Q)$}
\li	\If $\attrib{Q}{head}=\attrib{Q}{tail}$
\li		\Then \Return \const{true}
\li		\Else \Return \const{false}
\End
\end{codebox}

Następujące wiersze należy dodać na początek procedury \proc{Enqueue}:
\begin{codebox}
\zi	\If $\attrib{Q}{head}=\attrib{Q}{tail}+1$
\zi		\Then \Error ,,nadmiar''
		\End
\zi	\If $\attrib{Q}{head}=1$ i~$\attrib{Q}{tail}=\attrib{Q}{length}$
\zi		\Then \Error ,,nadmiar''
		\End
\end{codebox}
Z~kolei poniższy fragment kodu umieszczamy na początku procedury \proc{Dequeue}:
\begin{codebox}
\zi	\If $\proc{Queue-Empty}(Q)$
\zi		\Then \Error ,,niedomiar''
		\End
\end{codebox}

\exercise %10.1-5
Kolejkę dwustronną implementujemy przy użyciu tablicy $D[1\twodots n]$. Podobnie jak w~zwykłej kolejce atrybut \attrib{D}{head} wskazuje na początek kolejki, natomiast~atrybut \attrib{D}{tail} wyznacza następną wolną pozycję, na którą można wstawić nowy element. Procedury \proc{Head-Enqueue} oraz \proc{Head-Dequeue} mają na celu, odpowiednio, dodanie nowego elementu na początek kolejki i~usunięcie elementu z~początku kolejki. Z~kolei procedury \proc{Tail-Enqueue} oraz \proc{Tail-Dequeue} implementują dodawanie i~usuwanie elementów na końcu kolejki. Dla skrócenia zapisu pominięto sprawdzanie błędów niedomiaru i~przepełnienia.

\begin{codebox}
\Procname{$\proc{Head-Enqueue}(D,x)$}
\li	\If $\attrib{D}{head}=1$
\li		\Then $\attrib{D}{head}\gets\attrib{D}{length}$
\li		\Else $\attrib{D}{head}\gets\attrib{D}{head}-1$
		\End
\li	$D[\attrib{D}{head}]\gets x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Head-Dequeue}(D)$}
\li	$x\gets D[\attrib{D}{head}]$
\li	\If $\attrib{D}{head}=\attrib{D}{length}$
\li		\Then $\attrib{D}{head}\gets1$
\li		\Else $\attrib{D}{head}\gets\attrib{D}{head}+1$
		\End
\li	\Return $x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Tail-Enqueue}(D,x)$}
\li	$D[\attrib{D}{tail}]\gets x$
\li	\If $\attrib{D}{tail}=\attrib{D}{length}$
\li		\Then $\attrib{D}{tail}\gets1$
\li		\Else $\attrib{D}{tail}\gets\attrib{D}{tail}+1$
		\End
\end{codebox}

\begin{codebox}
\Procname{$\proc{Tail-Dequeue}(D,x)$}
\li	\If $\attrib{D}{tail}=1$
\li		\Then $\attrib{D}{tail}\gets\attrib{D}{length}$
\li		\Else $\attrib{D}{tail}\gets\attrib{D}{tail}-1$
		\End
\li	\Return $D[\attrib{D}{tail}]$
\end{codebox}

Wszystkie powyższe operacje działają w~czasie $\Theta(1)$.

\exercise %10.1-6
Wszystkie elementy kolejki będą trzymane na jednym stosie -- drugi stos będzie pełnił funkcję pomocniczą. Dodawanie nowego elementu do kolejki oraz sprawdzanie czy kolejka jest pusta, nie różnią się od analogicznych operacji wykonywanych na pierwszym stosie. Usuwanie elementu z~kolejki jest już operacją nieco bardziej skomplikowaną, gdyż należy pobrać element znajdujący się najgłębiej na tym stosie. Ściągamy wpierw z~niego wszystkie elementy za pomocą operacji \proc{Pop} i~umieszczamy kolejno na drugim stosie, wywołując ciąg operacji \proc{Push}. W~rezultacie drugi stos będzie zawierał wszystkie elementy kolejki w~odwrotnej kolejności. Teraz pobieramy i zapamiętujemy element ze szczytu drugiego stosu, gdyż za chwilę zwrócimy go jako wynik procedury. Wcześniej trzeba bowiem przenieść pozostałą zawartość drugiego stosu z~powrotem do pierwszego, co przy okazji przywróci początkową kolejność elementów.

Łatwo sprawdzić, że testowanie pustości kolejki oraz dodawanie do niej nowego elementu, są wykonywane w~czasie stałym, natomiast usuwanie wymaga czasu proporcjonalnego do liczby elementów kolejki.

\exercise %10.1-7
Rozwiązanie jest analogiczne do rozwiązania poprzedniego zadania. Sprawdzanie czy stos jest pusty, jak również dodawanie nowego elementu, to identyczne operacje wywoływane na pierwszej kolejce. Usuwanie elementu ze stosu odbywa się poprzez pobranie wszystkich elementów z~wyjątkiem ostatniego z~pierwszej kolejki i~dodanie tych elementów do drugiej. Ostatni z~nich także usuwamy z~kolejki, zapamiętawszy go w~celu późniejszego zwrócenia jako wyniku operacji. Ostatnim krokiem jest przeniesienie reszty elementów z~powrotem do pierwszej kolejki.

Podobnie jak w~poprzednim zadaniu operacja odpowiedzialna za sprawdzenie czy stos jest pusty oraz dodawanie elementu działają w~czasie stałym, a~operacja usuwania -- w~czasie liniowym względem liczby elementów na stosie.

\subchapter{Listy}

\exercise %10.2-1
Operację \proc{Insert}, dodającą nowy element $x$ na początek listy jednokierunkowej $L$, można zaimplementować w~czasie stałym -- wystarczy ustawić pole \attrib{x}{next} na głowę listy $L$ (albo na \const{nil}, jeśli lista $L$ jest pusta) i~uaktualnić wskaźnik \attrib{L}{head}. Operacja \proc{Delete}, czyli usuwanie z~listy jednokierunkowej elementu wskazywanego przez $x$, wymaga jednak czasu wyższego niż stały. Jest tak dlatego, że jedynym sposobem na dotarcie do elementu poprzedzającego $x$ na liście $L$ w~celu aktualizacji jego pola \id{next}, jest przejście tej listy od głowy aż do tegoż elementu. Czynność ta w~najgorszym przypadku zajmuje czas proporcjonalny do liczby elementów listy $L$.

Poniżej zamieszczamy implementacje obu tych operacji -- będziemy z~nich korzystać w~późniejszych zadaniach.
\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Insert}(L,x)$}
\li	$\attrib{x}{next}\gets\attrib{L}{head}$
\li	$\attrib{L}{head}\gets x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Delete}(L,x)$}
\li	\If $x=\attrib{L}{head}$
\li		\Then $\attrib{L}{head}\gets\attrib{\attrib{L}{head}}{next}$
\li		\Else
			$y\gets\attrib{L}{head}$
\li			\While $\attrib{y}{next}\ne x$
\li				\Do $y\gets\attrib{y}{next}$
				\End
\li			$\attrib{y}{next}\gets\attrib{x}{next}$
		\End
\end{codebox}

\exercise %10.2-2
Wszystkie elementy implementowanego stosu będziemy trzymać na liście jednokierunkowej $L$ w~kolejności od szczytu w~głowie listy do dna stosu w~ogonie. Dzięki takiemu rozwiązaniu operacje dodawania i~usuwania elementów będą działać w~czasie $\Theta(1)$. Sprawdzenie pustości stosu sprowadza się do sprawdzenia pustości listy $L$. Pseudokody operacji \proc{Push} i~\proc{Pop} prezentujemy poniżej.
\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Push}(L,k)$}
\li	$\attrib{x}{key}\gets k$
\li $\proc{Singly-Linked-List-Insert}(L,x)$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Pop}(L)$}
\li	\If $\attrib{L}{head}=\const{nil}$
\li		\Then \Error ,,niedomiar''
		\End
\li	$x\gets\attrib{L}{head}$
\li	$\attrib{L}{head}\gets\attrib{x}{next}$
\li	\Return \attrib{x}{key}
\end{codebox}

\exercise %10.2-3
Elementy kolejki będziemy przechowywać na liście jednokierunkowej $L$ w~kolejności od głowy kolejki do jej ogona. Aby jednak operacja dodawania była wykonalna w~czasie $\Theta(1)$, wymagane jest związanie z~listą $L$ dodatkowego atrybutu \attrib{L}{tail}, który będzie wskazywał na ogon listy $L$ albo na \const{nil}, jeżeli lista $L$ jest pusta. Oczywiście testowanie pustości kolejki polega na sprawdzeniu, czy pusta jest lista $L$. Implementacje operacji \proc{Enqueue} i~\proc{Dequeue} znajdują się poniżej.
\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Enqueue}(L,k)$}
\li	$\attrib{x}{next}\gets\const{nil}$
\li	$\attrib{x}{key}\gets k$
\li	\If $\attrib{L}{tail}\ne\const{nil}$
\li		\Then $\attrib{\attrib{L}{tail}}{next}\gets x$
\li		\Else $\attrib{L}{head}\gets x$
		\End
\li	$\attrib{L}{tail}\gets x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Dequeue}(L)$}
\li	\If $\attrib{L}{head}=\const{nil}$
\li		\Then \Error ,,niedomiar''
		\End
\li	$x\gets\attrib{L}{head}$
\li	$\attrib{L}{head}\gets\attrib{x}{next}$
\li	\If $\attrib{L}{tail}=x$
\li		\Then $\attrib{L}{tail}\gets\const{nil}$
		\End
\li	\Return \attrib{x}{key}
\end{codebox}

\exercise %10.2-4
Zauważmy, że pole \attrib{\attrib{L}{nil}}{key} jest niewykorzystywane w~implementacji listy z~wartownikami. Możemy zatem na początku działania procedury \proc{List-Search}$'$ przypisać mu wartość $k$. Jeśli na liście $L$ nie będzie elementu o~wartości $k$, to pętla tej procedury zatrzyma się na elemencie \attrib{L}{nil}, po czym zostanie on zwrócony.

\exercise %10.2-5
Operacja wstawiania nowego elementu na jednokierunkową listę cykliczną $L$ umieszcza go jako następnik głowy listy $L$. Podczas operacji usuwania znajdowany jest poprzednik $y$ usuwanego elementu $x$, po czym \attrib{y}{next} zostaje uaktualnione. Jeśli $x$ jest głową listy, to atrybut \attrib{L}{head} zostaje ustawiony na następnik $x$ albo na \const{nil}, w~przypadku gdy $x$ stanowi jedyny element listy~$L$. Wreszcie operacja wyszukiwania przechodzi całą listę $L$, począwszy od jej głowy, zatrzymując się w~momencie odnalezienia elementu o~szukanym kluczu bądź w~chwili ponownego dotarcia do głowy listy $L$.

Poniższe procedury stanowią implementacje tych trzech operacji słownikowych.
\begin{codebox}
\Procname{$\proc{Circular-List-Insert}(L,x)$}
\li	\If $\attrib{L}{head}=\const{nil}$
\li		\Then $\attrib{L}{head}\gets\attrib{x}{next}\gets x$
\li		\Else
			$\attrib{x}{next}\gets\attrib{\attrib{L}{head}}{next}$
\li			$\attrib{\attrib{L}{head}}{next}\gets x$
		\End
\end{codebox}

\begin{codebox}
\Procname{$\proc{Circular-List-Delete}(L,x)$}
\li	$y\gets\attrib{L}{head}$
\li	\While $\attrib{y}{next}\ne x$
\li		\Do $y\gets\attrib{y}{next}$
		\End
\li	$\attrib{y}{next}\gets\attrib{x}{next}$
\li	\If $\attrib{L}{head}=x$
\li		\Then
			\If $\attrib{x}{next}=x$
\li				\Then $\attrib{L}{head}\gets\const{nil}$
\li				\Else $\attrib{L}{head}\gets\attrib{x}{next}$
				\End
		\End
\end{codebox}

\begin{codebox}
\Procname{$\proc{Circular-List-Search}(L,k)$}
\li	\If $\attrib{L}{head}=\const{nil}$
\li		\Then \Return \const{nil}
		\End
\li	\If $\attrib{\attrib{L}{head}}{key}=k$
\li		\Then \Return \attrib{L}{head}
		\End
\li	$x\gets\attrib{\attrib{L}{head}}{next}$
\li	\While $x\ne\attrib{L}{head}$
\li		\Do
			\If $\attrib{x}{key}=k$
\li				\Then \Return $x$
				\End
\li			$x\gets\attrib{x}{next}$
		\End
\li	\Return \const{nil}
\end{codebox}

Łatwo sprawdzić, że procedura implementująca operację \proc{Insert} działa w~czasie stałym, natomiast pozostałe dwie procedury dla listy o~$n$ elementach w~pesymistycznym przypadku potrzebują czasu $\Theta(n)$.

\exercise %10.2-6
Zbiory można zaimplementować jako jednokierunkowe listy cykliczne. Zbiory $S_1$ i~$S_2$ są rozłączne, więc w~reprezentacji sumy $S_1\cup S_2$ nie pojawią się powtarzające się elementy. Operacja \proc{Union} może więc tylko ,,sklejać'' listy reprezentujące zbiory $S_1$ i~$S_2$. Podczas działania tej operacji następnikiem głowy pierwszej listy staje się następnik głowy drugiej listy, a~następnikiem głowy drugiej staje się początkowy następnik głowy pierwszej. Oczywiście działania te są wykonywane tylko wtedy, gdy obie listy są niepuste. Wykonując stałą liczbę kroków, otrzymujemy w~wyniku tej operacji jednokierunkową listę cykliczną (której głową może być dowolny jej element) reprezentującą zbiór $S_1\cup S_2$.

\exercise %10.2-7
W~algorytmie wykorzystamy pomocniczą listę jednokierunkową $L'$, na którą będziemy umieszczać kolejno usuwane elementy z~głowy listy $L$. Łatwo zauważyć, że pod koniec operacji przeniesione elementy będą znajdować się w~$L'$ w~porządku odwrotnym względem początkowego ustawienia na liście $L$. Nadanie atrybutowi \attrib{L}{head} wartości \attrib{L'}{head} wystarczy, aby przenieść całą zawartość listy $L'$ do listy $L$.
\begin{codebox}
\Procname{$\proc{Singly-Linked-List-Reverse}(L)$}
\li	$\attrib{L'}{head}\gets\const{nil}$
\li	\While $\attrib{L}{head}\ne\const{nil}$
\li		\Do
			$x\gets\attrib{L}{head}$
\li			$\proc{Singly-Linked-List-Delete}(L,\attrib{L}{head})$
\li			$\proc{Singly-Linked-List-Insert}(L',x)$
		\End
\li	$\attrib{L}{head}\gets\attrib{L'}{head}$
\end{codebox}

Procedury \proc{Singly-Linked-List-Insert} i~\proc{Singly-Linked-List-Delete} zostały przedstawione w~\refExercise{10.2-1}. Ich wywołania w~powyższym algorytmie zajmują czas stały, stąd czasem działania algorytmu jest $\Theta(n)$.

\exercise %10.2-8
Zgodnie z~opisem w~treści zadania przyjmijmy, że każdy element listy zamiast wskaźników na poprzednik i~następnik posiada atrybut \id{np}, będący alternatywą wykluczającą tych dwóch wskaźników. Załóżmy, że znamy adres elementu $x$ listy $L$ i~elementu $y$ będącego poprzednikiem $x$ na liście $L$. Niech $z$ będzie następnikiem $x$ na tej liście. Wówczas $\attrib{x}{np}=z\func{xor}y$, zatem na podstawie własności operacji \func{xor}, aby dostać się do $z$, wystarczy obliczyć wartość
\[
    z = z\func{xor}0 = z\func{xor}{}(y\func{xor}y) = (z\func{xor}y)\func{xor}y = \attrib{x}{np}\func{xor}y.
\]
Podobnie ma się rzecz podczas wyznaczania $y$ na podstawie $x$ i~$z$ -- wówczas $y=\attrib{x}{np}\func{xor}z$. Zauważmy, że jeśli element $x$ jest ogonem listy, to $\attrib{x}{np}=\const{nil}\func{xor}y=0\func{xor}y=y$, skąd mamy $z=\attrib{x}{np}\func{xor}y=0=\const{nil}$ i~analogicznie dla głowy listy, z~faktu, że $\attrib{x}{np}=z\func{xor}0=z$ wynika $y=\const{nil}$. Podobnie jak w~zwykłych listach przyjmujemy, że atrybut \attrib{L}{head} przechowuje wskaźnik do głowy listy~$L$. Ponadto z~listą związujemy atrybut \attrib{L}{tail}, który będzie wskazywał na jej ogon -- jest on konieczny do tego, aby operacja odwracania kolejności elementów na liście działała w~czasie stałym.

Poniżej przedstawiono procedury implementujące operacje \proc{Search}, \proc{Insert} i~\proc{Delete} dla takiej listy.
\begin{codebox}
\Procname{$\proc{Xor-Linked-List-Search}(L,k)$}
\li	$x\gets\attrib{L}{head}$
\li	$y\gets\const{nil}$
\li	\While $x\ne\const{nil}$ i~$\attrib{x}{key}\ne k$
\li		\Do
			$z\gets\attrib{x}{np}\func{xor}y$
\li			$y\gets x$
\li			$x\gets z$
		\End
\li	\Return $x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Xor-Linked-List-Insert}(L,x)$}
\li	$\attrib{x}{np}\gets\attrib{L}{head}$
\li	\If $\attrib{L}{head}\ne\const{nil}$
\li		\Then $\attrib{\attrib{L}{head}}{np}\gets\attrib{\attrib{L}{head}}{np}\func{xor}x$
		\End
\li	$\attrib{L}{head}\gets x$
\li	\If $\attrib{L}{tail}=\const{nil}$
\li		\Then $\attrib{L}{tail}\gets x$
		\End
\end{codebox}

\begin{codebox}
\Procname{$\proc{Xor-Linked-List-Delete}(L,x)$}
\li	$x'\gets\attrib{L}{head}$
\li	$y\gets\const{nil}$
\li	\While $x'\ne x$
\li		\Do
			$z\gets\attrib{x'}{np}\func{xor}y$
\li			$y\gets x'$
\li			$x'\gets z$
		\End
\li	$z\gets\attrib{x}{np}\func{xor}y$
\li	\If $x=\attrib{L}{head}$
\li		\Then $\attrib{L}{head}\gets z$
\li		\Else $\attrib{y}{np}\gets\attrib{y}{np}\func{xor}x\func{xor}z$
		\End
\li	\If $x=\attrib{L}{tail}$
\li		\Then $\attrib{L}{tail}\gets y$
\li		\Else $\attrib{z}{np}\gets\attrib{z}{np}\func{xor}x\func{xor}y$
		\End
\end{codebox}

Procedury \proc{Xor-Linked-List-Search} i~\proc{Xor-Linked-List-Insert} są analogiczne do swoich odpowiedników dla zwykłej listy dwukierunkowej i~pesymistyczny czas ich działania wynosi odpowiednio $\Theta(n)$ oraz $\Theta(1)$. W~procedurze \proc{Xor-Linked-List-Delete} należy odszukać na liście poprzednika i~następnika elementu $x$, aby uaktualnić ich pola \id{np}, co w~pesymistycznym przypadku zajmuje czas $\Theta(n)$. Odwracanie kolejności elementów -- zarówno w~zwykłej liście dwukierunkowej, jak i~w~tak zmodyfikowanej liście -- jest możliwe w~czasie $\Theta(1)$. W~tym celu wystarczy zamienić ze sobą wartości atrybutów \attrib{L}{head} i~\attrib{L}{tail}.

\subchapter{Reprezentowanie struktur wskaźnikowych za pomocą tablic}

\exercise %10.3-1
\note{Oryginalna treść drugiej części zadania żąda, aby podany ciąg zilustrować jako listę dwukierunkową w~reprezentacji jednotablicowej.}

\noindent Rys.~\ref{fig:10.3-1} przedstawia przykładowe rozmieszczenie elementów ciągu jako listy dwukierunkowej w~reprezentacji wielotablicowej i~jednotablicowej.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig_10.3-1}
	\end{center}
	\caption{Ciąg $\langle13,4,8,19,5,11\rangle$ w~postaci listy dwukierunkowej w~reprezentacji tablicowej. {\sffamily\bfseries(a)} Lista reprezentowana za pomocą tablic \id{key}, \id{next} oraz \id{prev}. {\sffamily\bfseries(b)} Ta sama lista reprezentowana w~pojedynczej tablicy $A$.} \label{fig:10.3-1}
\end{figure}

\exercise %10.3-2
Załóżmy, że właściwa lista oraz lista wolnych pozycji znajdują się w~pojedynczej tablicy $A$. Poniższe procedury są adaptacjami operacji przydzielania i~zwalniania pamięci dla list dwukierunkowych w~reprezentacji jednotablicowej. Wykorzystujemy tutaj fakt, że polu \id{next} odpowiada przesunięcie~1 względem początku fragmentu tablicy $A$ przechowującego dany element listy.
\begin{codebox}
\Procname{$\proc{Single-Array-Allocate-Object}()$}
\li	\If $\id{free}=\const{nil}$
\li		\Then \Error ,,brak pamięci''
		\End
\li	$x\gets\id{free}$
\li	$\id{free}\gets A[x+1]$
\li	\Return $x$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Single-Array-Free-Object}(x)$}
\li	$A[x+1]\gets\id{free}$
\li	$\id{free}\gets x$
\end{codebox}

\exercise %10.3-3
Lista wolnych pozycji jest listą jednokierunkową -- nie są więc wykorzystywane w~niej pola \id{prev}.

\exercise %10.3-4
Korzystając ze wskazówki z~treści zadania, zaimplementujemy listę wolnych pozycji jako stos. Będzie on zajmował wszystkie pozycje na prawo od tej wskazywanej przez \id{free}, na której znajdzie się jego wierzchołek. Stos jest pusty wtedy i~tylko wtedy, gdy $\id{free}=\const{nil}$. Przydzielanie pamięci polega na wywołaniu na stosie wolnych pozycji operacji \proc{Pop}, a~więc procedura \proc{Compact-List-Allocate-Object} jest identyczna z~oryginalną \proc{Allocate-Object}. Z~kolei zwalnianie pamięci to wywołanie na tym stosie operacji \proc{Push}. Wcześniej jednak należy zamienić zwalniany element z~tym, który znajduje się bezpośrednio na lewo od wierzchołka stosu. Poniższy pseudokod stanowi implementację tej operacji.
\begin{codebox}
\Procname{$\proc{Compact-List-Free-Object}(x)$}
\li	\If $\id{free}=\const{nil}$
\li		\Then $y\gets\attrib{key}{length}$
\li		\Else $y\gets\id{free}-1$
		\End
\li	\If $\id{next}[x]\ne\const{nil}$
\li		\Then $\id{prev}[\id{next}[x]]\gets\id{prev}[x]$
		\End
\li	\If $\id{prev}[x]\ne\const{nil}$
\li		\Then $\id{next}[\id{prev}[x]]\gets\id{next}[x]$
		\End
\li	\If $x\ne y$
\li		\Then
			\If $\id{next}[y]\ne\const{nil}$
\li				\Then $\id{prev}[\id{next}[y]]\gets x$
				\End
\li			\If $\id{prev}[y]\ne\const{nil}$
\li				\Then $\id{next}[\id{prev}[y]]\gets x$
				\End
		\End
\li	skopiuj wartości pól \id{key}, \id{next} i~\id{prev} elementu $y$ do pól elementu $x$
\li	\If $L=y$
\li		\Then $L\gets x$
		\End
\li	$\proc{Free-Object}(y)$
\end{codebox}

\exercise %10.3-5
Ogólny zarys procedury \proc{Compactify-List} jest następujący. Podczas przechodzenia po liście $L$ wyznaczane są te elementy, które zajmują pozycje na prawo od $m$. Wszystkie one muszą być zamienione z~elementami listy $F$ znajdującymi się na pozycjach do $m$ włącznie. Aby zachować czas $\Theta(m)$, procedura nie może przechodzić po liście $F$, która składa się z~$n-m$ elementów. Zamiast tego będzie ona przeszukiwać liniowo tablice implementujące listy i~wyznaczać rekordy należące do listy wolnych pozycji. Jednym ze sposobów rozróżniania elementów list $L$ i~$F$ jest wykorzystanie wskaźników \id{prev}. Na początku działania procedury do pól \id{prev} wszystkich elementów listy $L$ zostanie wpisana specjalna wartość, nie będąca poprawnym indeksem tablicy, np.\ $-1$. Tuż przed zakończeniem działania wskaźnikom \id{prev} zostaną nadane właściwe wartości, ale wpierw pola te posłużą do identyfikacji elementów listy.
\begin{codebox}
\Procname{$\proc{Compactify-List}(L,F)$}
\li	$n\gets\attrib{key}{length}$
\li	wpisz $-1$ do pól \id{prev} elementów listy $L$ i~wyznacz liczbę jej elementów $m$ \label{li:compactify-list-preprocess}
\li $x\gets L$
\li	$x'\gets\const{nil}$
\li	$y\gets1$
\li	\While $x\ne\const{nil}$ \label{li:compactify-list-while-begin}
\li		\Do
			\If $x\le m$
\li				\Then
					$x'\gets x$
\li					$x\gets\id{next}[x]$
\li				\Else
					\While $\id{prev}[y]=-1$ \label{li:compactify-list-while2-begin}
\li						\Do $y\gets y+1$
						\End \label{li:compactify-list-while2-end}
\li					zamień wartości pól \id{key}, \id{next} i~\id{prev} elementu $x$ z~polami elementu $y$ \label{li:compactify-list-swap}
\li					\If $\id{next}[x]\ne\const{nil}$ \label{li:compactify-list-fix-neighbors-begin}
\li						\Then $\id{prev}[\id{next}[x]]\gets x$
						\End
\li					\If $\id{prev}[x]\ne\const{nil}$
\li						\Then $\id{next}[\id{prev}[x]]\gets x$
						\End \label{li:compactify-list-fix-neighbors-end}
\li					\If $x'\ne\const{nil}$ \label{li:compactify-list-fix-predecessor-begin}
\li						\Then $\id{next}[x']\gets y$
						\End \label{li:compactify-list-fix-predecessor-end}
\li					\If $L=x$ \label{li:compactify-list-fix-heads-begin}
\li						\Then $L\gets y$
						\End
\li					\If $F=y$
\li						\Then $F\gets x$
						\End \label{li:compactify-list-fix-heads-end}
\li					$x'\gets y$
\li					$x\gets\id{next}[y]$
				\End
		\End \label{li:compactify-list-while-end}
\li	przywróć poprawne wartości w~polach \id{prev} elementów listy $L$ \label{li:compactify-list-postprocess}
\end{codebox}

Procedura przechodzi przez listę $L$ trzy razy. Najpierw w~wierszu~\ref{li:compactify-list-preprocess} tablice przechowujące listy $L$ i~$F$ są przygotowywane do właściwego przetwarzania poprzez ustawienie pól \id{prev} wszystkich elementów listy $L$ na $-1$. W~tym samym kroku wyznaczana jest wartość $m$ -- rozmiar listy $L$.

Kolejne przejście po liście to właściwe kompaktowanie. Jeśli dany element $x$ listy $L$ zajmuje w~tablicach pozycję wyższą niż $m$, to zostaje zamieniony z~elementem $y$ listy $F$ znajdującym się najbardziej na lewo. Pętla \kw{while} w~wierszach \doubledash{\ref{li:compactify-list-while2-begin}}{\ref{li:compactify-list-while2-end}} wyznacza $y$ poprzez liniowe przeglądanie tablicy \id{prev}, po czym w~wierszu~\ref{li:compactify-list-swap} elementy $x$ i~$y$ zamieniają swoje pozycje. Należy jeszcze uaktualnić wartości pól \id{prev} i~\id{next} elementów sąsiednich na liście $F$ (wiersze \doubledash{\ref{li:compactify-list-fix-neighbors-begin}}{\ref{li:compactify-list-fix-neighbors-end}}), wartość pola \id{next} poprzednika $x$ na liście $L$ (wiersze \doubledash{\ref{li:compactify-list-fix-predecessor-begin}}{\ref{li:compactify-list-fix-predecessor-end}}), jak również wartości wskaźników $L$ i~$F$, w~przypadku gdy wśród zamienianych elementów była głowa którejś z~list (wiersze \doubledash{\ref{li:compactify-list-fix-heads-begin}}{\ref{li:compactify-list-fix-heads-end}}).

Ostatnim krokiem procedury jest ponowne przejście przez listę $L$ w~wierszu~\ref{li:compactify-list-postprocess} i~przywrócenie odpowiednich wartości w~polach \id{prev} wszystkich jej elementów.

Po wykonaniu procedury elementy z~listy wolnych pozycji nie zawsze będą umieszczone w~tablicach według ich kolejności na tej liście. Z~tego powodu na liście przetworzonej procedurą \proc{Compactify-List} nie możemy korzystać z~procedur \proc{Compact-List-Allocate-Object} i~\proc{Compact-List-Free-Object} z~\refExercise{10.3-4}, które zakładają, że reprezentacja tablicowa listy wolnych pozycji stanowi stos.

\subchapter{Reprezentowanie drzew (ukorzenionych)}

\exercise %10.4-1
Drzewo binarne, którego reprezentacją są podane tablice, przedstawiono na rys.~\ref{fig:10.4-1}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig_10.4-1}
	\end{center}
	\caption{Drzewo binarne o~korzeniu o~indeksie~6 reprezentowane przez tablice \id{key}, \id{left} i~\id{right}.} \label{fig:10.4-1}
\end{figure}

\exercise %10.4-2
Szukany algorytm został opisany w~Podręczniku w~podrozdziale~12.1 jako procedura \proc{Inorder-Tree-Walk}. Czas działania tego algorytmu dla drzewa o~$n$ węzłach wynosi $\Theta(n)$ -- mówi o~tym tw.~12.1 z~Podręcznika.

\exercise %10.4-3
Przedstawiona poniżej procedura stanowi nierekurencyjną implementację algorytmu przechodzenia drzewa metodą preorder (patrz podrozdział~12.1). Do emulowania rekursji wykorzystywany jest stos. Każdy węzeł drzewa jest dokładnie raz wstawiany na stos i~dokładnie raz z~niego usuwany, stąd czas działania tej procedury dla drzewa o~$n$ węzłach wynosi $\Theta(n)$.
\begin{codebox}
\Procname{$\proc{Iterative-Preorder-Tree-Walk}(T)$}
\li	\If $\attrib{T}{root}=\const{nil}$
\li		\Then \Return
		\End
\li	$\proc{Push}(S,\attrib{T}{root})$
\li	\While $\proc{Stack-Empty}(S)=\const{false}$
\li		\Do
			$x\gets\proc{Pop}(S)$
\li			wypisz \attrib{x}{key}
\li			\If $\attrib{x}{right}\ne\const{nil}$
\li				\Then $\proc{Push}(S,\attrib{x}{right})$
				\End
\li			\If $\attrib{x}{left}\ne\const{nil}$
\li				\Then $\proc{Push}(S,\attrib{x}{left})$
				\End
		\End
\end{codebox}

\exercise %10.4-4
Nasza procedura będzie przyjmować węzeł $x$ drzewa w~reprezentacji ,,na lewo syn, na prawo brat'' i~wypisywać wszystkie klucze z~poddrzewa o~korzeniu w~$x$. Jeśli $x\ne\const{nil}$, to zostanie wypisany klucz węzła $x$ i~procedura zostanie wywołana rekurencyjnie najpierw dla najbardziej lewego syna $x$, a~następnie dla kolejnego brata $x$.
\begin{codebox}
\Procname{$\proc{Tree-Walk}(x)$}
\li	\If $x\ne\const{nil}$
\li		\Then
			wypisz \attrib{x}{key}
\li			$\proc{Tree-Walk}(\attrib{x}{left-child})$
\li			$\proc{Tree-Walk}(\attrib{x}{right-sibling})$
		\End
\end{codebox}
Aby wypisać wszystkie klucze drzewa $T$ w~reprezentacji ,,na lewo syn, na prawo brat'', należy wywołać $\proc{Tree-Walk}(\attrib{T}{root})$.

Każdy węzeł drzewa jest wypisywany w~dokładnie jednym wywołaniu rekurencyjnym. Procedura wywoływana jest także dla wszystkich pustych najbardziej lewych synów i~dla wszystkich pustych braci znajdujących się w~drzewie. Stąd wnioskujemy, że procedura wypisze wszystkie $n$ kluczy drzewa w~czasie $\Theta(n)$.

\exercise %10.4-5
W~algorytmie będziemy symulować przechodzenie drzewa w~porządku inorder, używając 3 wskaźników -- \id{curr} będący aktualnie odwiedzanym węzłem oraz \id{prev} i~\id{next} -- odpowiednio, poprzednio przetwarzanym i~kolejnym do przetworzenia węzłem. Odwiedzenie danego węzła $x$ będzie realizowane przez pomocniczą procedurę $\proc{Stackless-Inorder-Visit}(x)$. Polega ono na wypisaniu klucza $x$ oraz wyznacza kolejny węzeł do przetworzenia.
\begin{codebox}
\Procname{$\proc{Stackless-Inorder-Visit}(x)$}
\li	wypisz \attrib{x}{key}
\li	\If $\attrib{x}{right}\ne\const{nil}$
\li		\Then \Return \attrib{x}{right}
\li		\Else \Return \attrib{x}{p}
		\End
\end{codebox}

Algorytm zapisujemy w~postaci pseudokodu:
\begin{codebox}
\Procname{$\proc{Stackless-Inorder-Tree-Walk}(T)$}
\li	$\id{prev}\gets\const{nil}$
\li	$\id{curr}\gets\attrib{T}{root}$
\li	\While $\id{curr}\ne\const{nil}$
\li		\Do
			\If $\id{prev}=\attrib{curr}{p}$
\li				\Then
					\If $\attrib{curr}{left}\ne\const{nil}$
\li						\Then $\id{next}\gets\attrib{curr}{left}$
\li						\Else $\id{next}\gets\proc{Stackless-Inorder-Visit}(\id{curr})$
						\End
\li				\ElseIf $\id{prev}=\attrib{curr}{left}$
\li					\Then $\id{next}\gets\proc{Stackless-Inorder-Visit}(\id{curr})$
\li				\ElseNoIf $\id{next}\gets\attrib{curr}{p}$
				\End
\li			$\id{prev}\gets\id{curr}$
\li			$\id{curr}\gets\id{next}$
		\End
\end{codebox}

\exercise %10.4-6
\note{W~oryginalnej treści zadania szukana jest taka reprezentacja drzewa, która umożliwi wyznaczanie i~uzyskiwanie dostępu do ojca danego węzła lub wszystkich jego synów w~czasie proporcjonalnym do liczby synów.}

\noindent Opiszemy modyfikacje, które należy wprowadzić w~reprezentacji ,,na lewo syn, na prawo brat'', aby spełnić wymaganie z~treści zadania. Ponieważ nie wymagamy dostępu do ojca danego węzła w~stałym czasie, to możemy wyeliminować atrybut $p$. Zauważmy ponadto, że w~reprezentacji ,,na lewo syn, na prawo brat'', jeśli węzeł $x$ jest korzeniem albo najbardziej na prawo położonym synem swojego ojca, to $\attrib{x}{right-sibling}=\const{nil}$. Wykorzystamy ten wskaźnik w~węźle $x$, pokazując nim na dziadka $x$ (czyli ojca ojca $x$ albo \const{nil}, jeśli $x$ jest korzeniem lub synem korzenia). Aby móc jednoznacznie określać, czy węzeł wskazywany przez ten atrybut jest bratem, czy dziadkiem $x$, wykorzystamy dodatkowe pole -- zmienną boolowską. Nazwijmy następująco atrybuty każdego węzła $x$ w~nowej reprezentacji:
\begin{itemize}
	\item \attrib{x}{child} -- wskazuje na najbardziej lewego syna $x$ (identyczny z~\attrib{x}{left-child} z~reprezentacji ,,na lewo syn, na prawo brat'');
	\item \attrib{x}{next} -- wskazuje na kolejnego brata węzła $x$ albo na dziadka węzła $x$, jeśli $x$ jest korzeniem lub najbardziej na prawo wysuniętym synem swojego ojca;
	\item \attrib{x}{last} -- zmienna boolowska przyjmująca wartość \const{true}, jeśli węzeł $x$ jest korzeniem lub najbardziej na prawo wysuniętym synem swojego ojca i~\const{false} w~przeciwnym przypadku.
\end{itemize}

Dzięki tak zdefiniowanym atrybutom, mając dany węzeł wewnętrzny $x$, możemy wyznaczyć wszystkich jego synów poprzez przejście do węzła \attrib{x}{child}, a~następnie poruszając się po wskaźnikach \id{next} kolejnych węzłów. Każdy napotykany węzeł $y$ pokazuje wskaźnikiem \attrib{y}{next} na swojego kolejnego brata, o~ile $\attrib{y}{last}=\const{false}$. Po dotarciu do węzła $y$, dla którego $\attrib{y}{last}=\const{true}$, wszyscy synowie węzła $x$ zostali wyznaczeni i~możemy teraz ustalić ojca $x$, przechodząc do węzła wskazywanego przez \attrib{y}{next} (czyli dziadka $y$). Jeśli węzeł ten nie istnieje, to oznacza to, że $x$ jest korzeniem drzewa. Podany opis pozwala na wyznaczenie ojca węzła wewnętrznego $x$ oraz wszystkich jego synów w~czasie proporcjonalnym do liczby synów $x$.

Rozważmy teraz przypadek, gdy $x$ jest liściem. Wtedy $\attrib{x}{child}=\const{nil}$, co daje nam informację o~braku synów $x$, ale ich nieobecność uniemożliwia nam dotarcie do ojca $x$ tak, jak to robiliśmy dla węzłów wewnętrznych. Można jednak postąpić następująco. Przechodzimy do brata węzła $x$ znajdującego się najbardziej na prawo i~docieramy do ich wspólnego dziadka $z$. Jeśli węzeł $z$ nie istnieje, to ojcem $x$ jest korzeń drzewa (wskazuje na niego atrybut \id{root} drzewa). W~przeciwnym przypadku sprawdzamy wszystkich synów węzła $z$ -- ten z~nich, którego jednym z~synów jest $x$, stanowi oczywiście ojca $x$. Dotarcie do ojca liścia $x$ tym sposobem wymaga w~najgorszym przypadku czasu proporcjonalnego do rozmiaru poddrzewa o~korzeniu będącego dziadkiem $x$.

\problems

\problem{Porównanie list} %10-1
Tabela~\ref{tab:10-1} zawiera pesymistyczne czasy poszczególnych operacji słownikowych dla danych czterech typów list. Przyjmujemy, że operacje wykonywane są na listach o~rozmiarach $n$.

\begin{table}[ht]
	\begin{center}
		\[
			\begin{array}{l|c|c|c|c}
				& \text{Nieposortowana} & \text{Posortowana} & \text{Nieposortowana} & \text{Posortowana} \\
				& \text{jedno-} & \text{jedno-} & \text{dwu-} & \text{dwu-} \\
				& \text{kierunkowa} & \text{kierunkowa} & \text{kierunkowa} & \text{kierunkowa} \\
				\hline
				\proc{Search}(L,k) & \Theta(n) & \Theta(n) & \Theta(n) & \Theta(n) \\
				\hline
				\proc{Insert}(L,x) & \Theta(1) & \Theta(n) & \Theta(1) & \Theta(n) \\
				\hline
				\proc{Delete}(L,x) & \Theta(n) & \Theta(n) & \Theta(1) & \Theta(1) \\
				\hline
				\proc{Successor}(L,x) & \Theta(n) & \Theta(1) & \Theta(n) & \Theta(1) \\
				\hline
				\proc{Predecessor}(L,x) & \Theta(n) & \Theta(n) & \Theta(n) & \Theta(1) \\
				\hline
				\proc{Minimum}(L) & \Theta(n) & \Theta(1) & \Theta(n) & \Theta(1) \\
				\hline
				\proc{Maximum}(L) & \Theta(n) & \Theta(n) & \Theta(n) & \Theta(n)
			\end{array}
		\]
	\end{center}
	\caption{Porównanie pesymistycznych złożoności operacji słownikowych dla różnych typów list.} \label{tab:10-1}
\end{table}
Jeśli w~implementacjach list będziemy dodatkowo utrzymywać atrybut \id{tail} wskazujący na ogon listy, to operację \proc{Maximum} dla list posortowanych możemy wykonywać w~czasie stałym.

\problem{Listowa reprezentacja kopców złączalnych} %10-2

\subproblem %10-2(a)
Kopiec zaimplementujemy jako posortowaną listę jednokierunkową. Operacja \proc{Make-Heap} tworzy pustą listę, co zajmuje oczywiście czas stały. Dodanie elementu do kopca polega na dodaniu go do listy. Aby zachować jej uporządkowanie, musimy odnaleźć miejsce, które zajmie nowy element, co w~pesymistycznym przypadku wymaga czasu $\Theta(n)$. Dzięki uporządkowaniu listy można zaimplementować operacje \proc{Minimum} i~\proc{Extract-Min} działające w~czasie $\Theta(1)$. Z~kolei stosując algorytm opisany w~\refExercise{6.5-8} w~wersji dla list jednokierunkowych, a~następnie przechodząc po scalonej liście w~celu usunięcia powtarzających się elementów, jesteśmy w~stanie zaimplementować operację \proc{Union} w~czasie $\Theta(n)$, gdzie $n$ jest liczbą elementów na wynikowej liście.

\subproblem %10-2(b)
W~tym przypadku także wystarczy nam lista jednokierunkowa. Zarówno utworzenie pustego kopca, jak i~dodanie do niego nowego elementu odbywa się w~czasie stałym, ale odszukanie oraz usunięcie minimalnego elementu wiąże się z~przeszukaniem całej listy, co zajmuje czas liniowy względem rozmiaru listy. Możemy jednak wprowadzić usprawnienie, dzięki któremu operacja \proc{Minimum} będzie działać w~czasie stałym. Będziemy mianowicie przechowywać minimalny element listy w~jej głowie. Podczas dodawania nowego elementu wystarczy porównać ten element z~głową listy (o~ile istnieje) i~jeśli stanowi on nowe minimum, umieścić go w~głowie listy albo, w~przeciwnym przypadku, tuż za nią. Operacja \proc{Extract-Min} po usunięciu głowy nadal jednak musi przeszukać całą listę w~celu odszukania aktualnego minimum i~umieszczenia go w~głowie listy.

Podczas operacji \proc{Union}, musimy pamiętać o~tym, że łączone listy nie zawsze reprezentują rozłączne zbiory, a~także o~tym, że w~głowie wynikowej listy powinien znaleźć się najmniejszy element z~obu łączonych list. Efektywna implementacja spełniająca oba warunki będzie polegać na wywołaniu operacji \proc{Union} z~punktu~(a) po uprzednim posortowaniu obu list, co zrealizujemy za pomocą algorytmu sortowania przez scalanie w~wersji dla list jednokierunkowych. Do zaimplementowania pomocniczej procedury \proc{Merge} możemy użyć algorytmu przedstawionego w~\refExercise{6.5-8}. Ostatecznie łączenie list jesteśmy w~stanie zaimplementować w~czasie $\Theta(n\lg n)$, gdzie $n$ jest rozmiarem wynikowej listy.

\subproblem %10-2(c)
Przypadek jest identyczny z~poprzednim, ale tym razem nie jest wymagane wykrywanie powtórzeń podczas operacji \proc{Union}. Łączenie list możemy więc zaimplementować jako ich konkatenację, to znaczy ustawienie głowy jednej listy jako elementu następującego po ogonie drugiej. To, w~jakiej kolejności skleimy listy, będzie zależeć od tego, której głowa przechowuje mniejszy element, co ma na celu spełnienie usprawnienia opisanego w~poprzednim punkcie. Operację łączenia możemy zrealizować w~czasie stałym, jeśli dla listy w~tej reprezentacji kopca będziemy pamiętać wskaźnik na jej ogon.

\bigskip
\noindent Zestawienie czasów działania poszczególnych operacji w~przypadkach pesymistycznych dla omawianych reprezentacji listowych kopców złączalnych przedstawiono w~tabeli~\ref{tab:10-2}.

\begin{table}[ht]
	\begin{center}
		\[
			\begin{array}{l|c|c|c}
				& \text{Listy posortowane} & \text{Listy nieposortowane} & \text{Listy nieposortowane,} \\
				&  &  & \text{rozłączne zbiory w~\proc{Union}} \\
				\hline
				\proc{Make-Heap} & \Theta(1) & \Theta(1) & \Theta(1) \\
				\hline
				\proc{Insert} & \Theta(n) & \Theta(1) & \Theta(1) \\
				\hline
				\proc{Minimum} & \Theta(1) & \Theta(1) & \Theta(1) \\
				\hline
				\proc{Extract-Min} & \Theta(1) & \Theta(n) & \Theta(n) \\
				\hline
				\proc{Union} & \Theta(n) & \Theta(n\lg n) & \Theta(1)
			\end{array}
		\]
	\end{center}
	\caption{Porównanie pesymistycznych czasów operacji słownikowych dla reprezentacji listowych kopców złączalnych. Dla operacji \proc{Union} $n$ oznacza rozmiar zbioru po połączeniu.} \label{tab:10-2}
\end{table}

\problem{Wyszukiwanie na posortowanej liście zajmującej spójny obszar pamięci (liście upakowanej)} %10-3
\note{W~pseudokodzie procedury \proc{Compact-List-Search} jest błąd -- w linijce~4 zamiast testowania, czy\/ $\id{key}[j]<k$, powinno być sprawdzenie, czy\/ $\id{key}[j]\le k$. Ponadto w~wywołaniach procedur \proc{Compact-List-Search} i~\proc{Compact-List-Search}$'$ na listach ich argumentów brakuje\/ $n$ jako drugiego parametru.}

\subproblem %10-3(a)
W~żadnej z~procedur nigdy nie zostanie wykonany skok na losowo wybraną pozycję bliżej głowy listy ani na pozycję zawierającą element o~kluczu większym niż $k$ -- gwarantują to warunki w~wierszach~4 obu algorytmów. Ponadto w~każdej iteracji w~pętlach \kw{while} obu procedur następuje przesunięcie indeksu $i$ o~jedną pozycję do przodu. Skoki te wykonywane są, dopóki indeks $i$ nie dotrze na pozycję elementu o~kluczu większym lub równym $k$, bądź nie osiągnie końca listy $L$. A~zatem oba wywołania zwrócą ten sam wynik.

Zauważmy, że podczas ustalonej iteracji pętli \kw{while} w~procedurze \proc{Compact-List-Search} indeks $i$ nie jest bliżej głowy listy $L$ niż ten sam indeks podczas tej samej iteracji pętli \kw{for} w~procedurze \proc{Compact-List-Search}$'$. Pętla pierwszego algorytmu nie zakończy się więc później niż pętla drugiego algorytmu, która to wykona dokładnie $t$ iteracji. A~zatem łączna liczba iteracji pętli \kw{for} i~\kw{while} w~procedurze \proc{Compact-List-Search}$'$ wynosi co najmniej $t$.

\subproblem %10-3(b)
W~wywołaniu \proc{Compact-List-Search}$'(L,n,k,t)$ zostanie wykonanych nie więcej niż $t$ iteracji pętli \kw{for}, czyli etap ten wymaga czasu $O(t)$. Na podstawie definicji zmiennej losowej $X_t$ otrzymujemy z~kolei, że średnia liczba wykonanych iteracji pętli \kw{while} wynosi $\E(X_t)$. A~zatem oczekiwanym czasem działania procedury \proc{Compact-List-Search}$'(L,n,k,t)$ jest $O(t+\E(X_t))$.

\subproblem %10-3(c)
Oznaczmy przez $s$ indeks klucza $k$ na liście $L$, a~przez $j_1$, $j_2$,~\dots,~$j_t$ -- ciąg liczb całkowitych wyznaczonych przez $t$ wywołań $\proc{Random}(1,n)$. Ponadto niech $\pi$ będzie funkcją przypisującą indeksowi elementu na liście $L$ jego rzeczywistą pozycję na tej liście wyznaczoną na podstawie łańcucha wskaźników \id{next}. Po $t$ iteracjach pętli \kw{for} odległość między szukanym kluczem a~elementem o~indeksie $i$ (mierzona długością łańcucha wskaźników \id{next}) będzie większa lub równa $r$, jeśli dla każdego $q=1$, 2,~\dots,~$t$ spełnione będzie $\pi(j_q)\le\pi(s)-r$ lub $\pi(j_q)>\pi(s)$. Mamy więc
\[
	\Pr(X_t\ge r) = \prod_{q=1}^t\Pr(\pi(j_q)\le\pi(s)-r\;\;\text{lub}\;\;\pi(j_q)>\pi(s)) = \prod_{q=1}^t\frac{n-r}{n} = \biggl(1-\frac{r}{n}\biggr)^t.
\]
Korzystając z~tożsamości~(C.24) i~z~powyższego oszacowania, otrzymujemy
\[
	\E(X_t) = \sum_{r=1}^\infty\Pr(X_t\ge r) = \sum_{r=1}^n\Pr(X_t\ge r) = \sum_{r=1}^n\biggl(1-\frac{r}{n}\biggr)^t.
\]

\subproblem %10-3(d)
Sumę ograniczamy całką, otrzymując:
\[
	\sum_{r=0}^{n-1}r^t \le \int_0^nx^t\,dx = \biggl[\frac{x^{t+1}}{t+1}\biggr]_0^n = \frac{n^{t+1}}{t+1}.
\]

\subproblem %10-3(e)
Na podstawie rozwiązań punktów~(c) i~(d) mamy:
\[
	\E(X_t) = \sum_{r=1}^n\biggl(1-\frac{r}{n}\biggr)^t = \sum_{r=1}^{n-1}\biggl(\frac{n-r}{n}\biggr)^t = \sum_{r=1}^{n-1}\biggl(\frac{r}{n}\biggr)^t = \frac{\sum_{r=0}^{n-1}r^t}{n^t} \le \frac{\frac{n^{t+1}}{t+1}}{n^t} = \frac{n}{t+1}.
\]

\subproblem %10-3(f)
Na mocy punktów~(b) i~(e) dostajemy, że oczekiwany czas działania procedury \proc{Compact-List-Search}$'(L,n,k,t)$ wynosi $O(t+\E(X_t))=O(t+n/(t+1))=O(t+n/t)$.

\subproblem %10-3(g)
Oznaczmy przez $p$ pozycję listy $L$, na którą został wykonany ostatni skok w~wierszu~5 procedury \proc{Compact-List-Search}. Zauważmy, że w~procedurze \proc{Compact-List-Search} po wykonaniu tego skoku zostanie wykonanych co najwyżej $t$ operacji $i\gets\id{next}[i]$. Z~kolei pozycja na liście $L$, będąca celem ostatniego skoku z~wiersza~5 w~\proc{Compact-List-Search}$'$, nie może znajdować się bliżej głowy listy niż pozycja $p$. Na tej podstawie wnioskujemy, że liczba wykonanych operacji $i\gets\id{next}[i]$ w~pętli \kw{while} algorytmu \proc{Compact-List-Search}$'$ również nie przekroczy $t$. Oznacza to, że etap, który na podstawie poprzedniego punktu zajmuje czas $O(n/t)$, będzie w~rzeczywistości działać w~czasie $O(t)$. Stąd $O(n/t)=O(t)$, czyli $t=O(\!\sqrt{n})$, a~więc czas działania procedury \proc{Compact-List-Search} wynosi $O(\!\sqrt{n})$.

Wynik ten jest prawdziwy także w~przypadku, gdy elementu o~kluczu $k$ nie ma na liście. Wystarczy bowiem zdefiniować zmienną losową $X_t$ jako odległość na liście (mierzoną długością łańcucha wskaźników \id{next}) od pozycji $i$ do pozycji elementu o~kluczu większym niż $k$ albo do pozycji bezpośrednio za ogonem listy, w~przypadku, gdy taki element nie istnieje. Analizę w~punktach \doubledash{(b)}{(g)} dla nowej definicji zmiennej $X_t$ przeprowadza się analogicznie.

\subproblem %10-3(h)
Jeśli dopuścimy, aby elementy na liście powtarzały się, to może dojść do sytuacji, w~której procedura próbuje wykonać skok na pozycję $j$ bliższą szukanemu elementowi niż pozycja $i$, ale nie wykonuje go, gdyż stwierdza w~linii~4, że $\id{key}[i]=\id{key}[j]$. Jeśli każdy losowy skok będzie eliminowany na tej podstawie, to działanie procedury sprowadzi się do działania zwykłego algorytmu wyszukiwania na posortowanej liście.

\endinput