\chapter{Heapsort -- sortowanie przez kopcowanie}

\subchapter{Kopce}

\exercise %6.1-1
Korzystamy z~faktu, że kopiec stanowi prawie pełne drzewo binarne, tzn.\ takie, w~którym wszystkie poziomy, być może z~wyjątkiem najniższego, zawierają komplet węzłów. Jeśli drzewo to ma wysokość $h$, to maksymalnie może mieć $2^{h+1}-1$ węzłów (gdy jest drzewem pełnym), a~minimalnie $(2^h-1)+1=2^h$ (gdy jego najniższy poziom składa się z~tylko jednego węzła).

\exercise %6.1-2
Niech $h$ oznacza wysokość kopca. Z~poprzedniego zadania mamy, że $2^h\le n<2^{h+1}$, skąd dostajemy $h\le\lg n<h+1$. Ponieważ $h$ jest całkowite, to $h=\lfloor\lg n\rfloor$.

\exercise %6.1-3
Wartość korzenia każdego poddrzewa w~kopcu typu max jest równa lub większa od wartości obu synów tego korzenia. Dla dowolnego poddrzewa można łatwo dowieść przez indukcję względem jego wysokości, że wartości węzłów wchodzących w~skład ścieżek od liści w~górę poddrzewa, tworzą ciągi niemalejące. Ponieważ wszystkie takie ścieżki kończą się w~korzeniu tego poddrzewa, to musi on mieć największą wartość w~tym poddrzewie.

\exercise %6.1-4
Analizując ścieżki w~górę drzewa jak w~poprzednim zadaniu, stwierdzamy, że najmniejsze elementy każdej takiej ścieżki znajdują się w~ich pierwszych elementach, czyli w~liściach drzewa. Ponieważ warunek kopca typu max nie wprowadza żadnej relacji między wartościami liści, to najmniejszy element kopca może być w~każdym z~nich.

\exercise %6.1-5
Powtarzając rozumowanie z~\refExercise{6.1-3} dla kopców typu min, wnioskujemy, że korzeń takiego kopca stanowi jego najmniejszy element, czyli zajmuje pierwszą pozycję w~posortowanej (niemalejąco) tablicy $A$. Dla każdego indeksu tablicy $i$ z~wyjątkiem pierwszego zachodzi $\proc{Parent}(i)<i$, a~więc $A[\proc{Parent}(i)]\le A[i]$. Własność kopca typu min jest zatem spełniona i~tablica posortowana $A$ stanowi taki kopiec.

\exercise %6.1-6
Potraktujmy ten ciąg jako tablicę $A$. Elementy na pozycjach $i=9$ oraz $\proc{Parent}(i)=4$ nie spełniają własności $A[\proc{Parent}(i)]\ge A[i]$, zatem tablica $A$ nie jest kopcem typu max.

\exercise %6.1-7
Element kopca na pozycji $i$ nie jest liściem wtedy i~tylko wtedy, gdy istnieje jego lewy syn. W~kopcu o~$n$ elementach wierzchołki wewnętrzne znajdują się zatem na pozycjach $i$ takich, że $\proc{Left}(i)\le n$. Warunek ten sprowadza się do nierówności $2i\le n$, skąd $i\le\lfloor n/2\rfloor$, bo $i$ jest całkowite. Pozostałe wierzchołki są liśćmi i~zajmują pozycje $\lfloor n/2\rfloor+1$, $\lfloor n/2\rfloor+2$,~\dots,~$n$.

\subchapter{Przywracanie własności kopca}

\exercise %6.2-1
Rys.~\ref{fig:6.2-1} przedstawia działanie procedury $\proc{Max-Heapify}(A,3)$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig06.1}
	\end{center}
	\caption{Działanie procedury $\proc{Max-Heapify}(A,3)$ dla tablicy $A=\langle$27,~17, 3, 16, 13, 10, 1, 5, 7, 12, 4, 8, 9,~0$\rangle$. {\sffamily\bfseries(a)}--{\sffamily\bfseries(b)} Drzewo binarne reprezentujące $A$, w~którym przywracana jest własność kopca typu max, odpowiednio, w~węzłach $i=3$ oraz $i=6$. {\sffamily\bfseries(c)} Wynikowy kopiec z~przywróconą własnością kopca.} \label{fig:6.2-1}
\end{figure}

\exercise %6.2-2
Poniższy pseudokod prezentuje procedurę przywracania własności kopca typu min. Ponieważ jedyną modyfikacją w~porównaniu z~procedurą \proc{Max-Heapify} jest zmiana znaków nierówności na przeciwne w~warunkach w~wierszach~\ref{li:min-heapify-check1} i~\ref{li:min-heapify-check2}, to czas działania tej procedury jest identyczny z~czasem działania \proc{Max-Heapify}, czyli $\Theta(\lg n)$.
\begin{codebox}
\Procname{$\proc{Min-Heapify}(A,i)$}
\li	$l\gets\proc{Left}(i)$
\li	$r\gets\proc{Right}(i)$
\li	\If $l\le\id{heap-size}[A]$ i~$A[l]<A[i]$ \label{li:min-heapify-check1}
\li		\Then $\id{smallest}\gets l$
\li		\Else $\id{smallest}\gets i$
		\End
\li	\If $r\le\id{heap-size}[A]$ i~$A[r]<A[\id{smallest}]$ \label{li:min-heapify-check2}
\li		\Then $\id{smallest}\gets r$
		\End
\li	\If $\id{smallest}\ne i$
\li		\Then
			zamień $A[i]\leftrightarrow A[\id{smallest}]$
\li			$\proc{Min-Heapify}(A,\id{smallest})$
		\End
\end{codebox}

\exercise %6.2-3
Jeśli element $A[i]$ jest większy niż jego synowie, to $\id{largest}$ jest ustawiane na $i$ i~warunek z~wiersza~8 nie jest spełniony. Procedura zakończy więc działanie, nie dokonując żadnej zamiany elementów.

\exercise %6.2-4
Z~\refExercise{6.1-7} mamy, że element o~indeksie $i>\id{heap-size}[A]/2$ jest liściem kopca, czyli nie istnieją jego synowie. W~dwóch pierwszych wierszach procedury \proc{Max-Heapify} obliczone zostaną wartości przekraczające $\id{heap-size}[A]$, więc zmienna $\id{largest}$ przyjmie wartość $i$. Warunek w~wierszu~8 będzie więc fałszywy i~natychmiast po jego sprawdzeniu procedura zakończy działanie.

\exercise %6.2-5
Iteracyjna wersja procedury \proc{Max-Heapify} została przedstawiona poniżej.
\begin{codebox}
\Procname{$\proc{Iterative-Max-Heapify}(A,i)$}
\li	\While \const{true}
\li		\Do
			$l\gets\proc{Left}(i)$ \label{li:iterative-max-heapify-begin}
\li			$r\gets\proc{Right}(i)$
\li			\If $l\le\id{heap-size}[A]$ i~$A[l]>A[i]$
\li				\Then $\id{largest}\gets l$
\li				\Else $\id{largest}\gets i$
				\End
\li			\If $r\le\id{heap-size}[A]$ i~$A[r]>A[\id{largest}]$
\li				\Then $\id{largest}\gets r$
				\End \label{li:iterative-max-heapify-end}
\li			\If $\id{largest}=i$ \label{li:iterative-max-heapify-cond}
\li				\Then \Return
				\End
\li			zamień $A[i]\leftrightarrow A[\id{largest}]$
\li			$i\gets\id{largest}$
		\End
\end{codebox}
Działania wykonywane w~wierszach~\ref{li:iterative-max-heapify-begin}\nobreakdash--\ref{li:iterative-max-heapify-end} są identyczne jak w~oryginalnej implementacji procedury. W~zależności od wyniku testu z~wiersza~\ref{li:iterative-max-heapify-cond} procedura kończy działanie albo zamienia elementy $A[i]$ i~$A[\id{largest}]$, po czym symuluje wywołanie rekurencyjne, aktualizując wartość zmiennej $i$ i~wykonując kolejną iterację pętli \kw{while}.

\exercise %6.2-6
Najgorszy przypadek dla procedury \proc{Max-Heapify} zachodzi wówczas, gdy zostanie ona wywołana dla korzenia kopca i~schodzi rekurencyjnie aż do jego ostatniego poziomu. Najdłuższa ścieżka od korzenia do liścia składa się z~$h=\lfloor\lg n\rfloor$ krawędzi (z~\refExercise{6.1-2}) i~tyle będzie wywołań rekurencyjnych procedury w~najgorszym przypadku. Koszt pracy wykonanej na każdym poziomie rekursji jest stały, a~więc procedura \proc{Max-Heapify} działa wtedy w~czasie $\Omega(\lg n)$. Przykładowym drzewem, dla którego procedura wykona opisane operacje, jest takie, w~którym korzeń ma wartość 0, a~każdy inny węzeł ma wartość 1.

\subchapter{Budowanie kopca}

\exercise %6.3-1
Ilustracja działania procedury \proc{Build-Max-Heap} dla tablicy $A$ znajduje się na rys.~\ref{fig:6.3-1}.
\begin{figure}[ht!]
	\begin{center}
		\includegraphics{fig06.2}
	\end{center}
	\caption{Działanie procedury \proc{Build-Max-Heap} dla tablicy $A=\langle5,3,17,10,84,19,6,22,9\rangle$. {\sffamily\bfseries(a)} Tablica $A$ i~reprezentujące ją drzewo binarne przed pierwszym wywołaniem \proc{Max-Heapify} z~wiersza~3. {\sffamily\bfseries(b)}--{\sffamily\bfseries(d)} Drzewo przed każdym kolejnym wywołaniem \proc{Max-Heapify}. {\sffamily\bfseries(e)} Wynikowy kopiec typu max.} \label{fig:6.3-1}
\end{figure}

\exercise %6.3-2
Kolejne wywołania rekurencyjne procedury $\proc{Max-Heapify}(A,i)$ schodzą na coraz niższe poziomy drzewa. A~zatem modyfikowane są tylko węzły znajdujące się w~drzewie głębiej od węzła o~indeksie $i$. Ponadto w~pojedynczym wywołaniu \proc{Max-Heapify} dowolny węzeł można przenieść w~górę drzewa o~co najwyżej jeden poziom. Jeśli węzły byłyby przetwarzane w~kolejności rosnących indeksów, to kolejne iteracje pętli \kw{for} w~\proc{Build-Max-Heap} uniemożliwiałyby transport w~górę drzewa węzłom znajdującym się na niskich poziomach.

\exercise %6.3-3
Oznaczmy kopiec przez $T$, a~przez $n_h$ -- ilość węzłów kopca $T$ znajdujących się na wysokości $h$. Udowodnimy fakt przez indukcję względem $h$.

W~pierwszym kroku indukcji musimy pokazać, że $n_0\le\lceil n/2\rceil$. W~rzeczywistości udowodnimy, że $n_0=\lceil n/2\rceil$. Rozważmy w~tym celu dwa przypadki ze względu na parzystość $n$. Gdy $n$ jest nieparzyste, to w~kopcu $T$ nie ma węzłów posiadających tylko jednego syna. Wykorzystując \refExercise{B.5-3}, mamy, że liczba węzłów wewnętrznych $m$ jest równa liczbie liści $n_0$ pomniejszonej o~1. Mamy $n=m+n_0=2n_0-1$, skąd $n_0=(n+1)/2=\lceil n/2\rceil$.

Rozważmy teraz parzyste $n$. Wówczas istnieje w~kopcu $T$ węzeł o~jednym synu. Jeśli dodamy do kopca nowy węzeł, to przypadek sprowadzi się do sytuacji z~nieparzystą ilością węzłów. Ale dodając nowy węzeł, zwiększymy liczbę liści kopca o~1, ponieważ ojciec nowego węzła posiada już syna, więc sam nie jest liściem. Kopiec będzie zatem zawierał $n+1$ węzłów, w~tym $n_0+1$ liści. Na podstawie przypadku z~nieparzystą liczbą węzłów mamy $n_0+1=\lceil(n+1)/2\rceil=\lceil n/2\rceil+1$, skąd $n_0=\lceil n/2\rceil$. A~zatem przypadek bazowy indukcji jest spełniony.

Załóżmy teraz, że $h>0$ i~$n_{h-1}\le\lceil n/2^h\rceil$. Ponadto niech $T'$ będzie kopcem powstałym z~$T$ po usunięciu z~niego wszystkich jego liści. Nowy kopiec ma zatem $n'=n-n_0$ węzłów. Ponieważ w~kroku bazowym pokazaliśmy, że $n_0=\lceil n/2\rceil$, to stąd $n'=n-\lceil n/2\rceil=\lfloor n/2\rfloor$. Węzły, które w~kopcu $T$ są na wysokości $h$, w~$T'$ zajmują wysokość $h-1$, więc jeśli oznaczymy przez $n_{h-1}'$ liczbę węzłów na wysokości $h-1$ w~kopcu $T'$, to dostaniemy zależność $n_h=n_{h-1}'$. Wykorzystując założenie indukcyjne, dostajemy
\[
    n_h = n_{h-1}' \le \lceil n'/2^h\rceil = \lceil\lfloor n/2\rfloor/2^h\rceil \le \lceil(n/2)/2^h\rceil = \lceil n/2^{h+1}\rceil,
\]
co kończy dowód.

\subchapter{Algorytm sortowania przez kopcowanie (heapsort)}

\exercise %6.4-1
Na rys.~\ref{fig:6.4-1} przedstawiono ilustrację działania sortowania przez kopcowanie dla tablicy $A$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig06.3}
	\end{center}
	\caption{Działanie procedury \proc{Heapsort} dla tablicy $A=\langle5,13,2,25,7,17,20,8,4\rangle$. {\sffamily\bfseries(a)} Kopiec zaraz po jego zbudowaniu przez \proc{Build-Max-Heap}. {\sffamily\bfseries(b)}--{\sffamily\bfseries(i)} Kopiec i~elementy z~niego usunięte po każdym wywołaniu \proc{Max-Heapify} w~wierszu~5. {\sffamily\bfseries(j)} Wynikowa posortowana tablica.} \label{fig:6.4-1}
\end{figure}

\exercise %6.4-2
\begin{description}
	\item[Inicjowanie:] Przed pierwszą iteracją pętli mamy $i=\id{length}[A]=n$. Wówczas fragment $A[1\twodots i]$ jest całą tablicą $A$, która stanowi kopiec typu max, utworzony w~wyniku działania procedury \proc{Build-Max-Heap}, natomiast fragment $A[i+1\twodots n]$ jest pusty.
	\item[Utrzymanie:] Załóżmy, że niezmiennik jest prawdziwy przed wykonaniem kolejnej iteracji pętli. Podtablica $A[1\twodots i]$ tworzy więc kopiec typu max, którego korzeniem jest $A[1]$, czyli największy element w~tej podtablicy. Po wykonaniu wiersza~3 znajdzie się on na pozycji $i$. Dekrementacja $\id{heap-size}[A]$ powoduje, że element $A[i]$ nie wchodzi teraz w~skład kopca, ale podtablica $A[i\twodots n]$ zawiera teraz $n-i+1$ największych elementów z~$A[1\twodots n]$ posortowanych niemalejąco, ponieważ element $A[i]$ jest równy lub większy od wcześniej umieszczonych tam elementów. Uaktualnienie $i$ pozwoli odtworzyć tę część niezmiennika. W~tym momencie korzeń kopca może naruszać własność kopca typu max, dlatego w~wierszu~5 zostaje wywołana dla niego procedura \proc{Max-Heapify} przywracająca tę własność.
	\item[Zakończenie:] Po zakończeniu działania pętli jest $i=1$, zatem podtablica $A[1\twodots i]$ składa się z~jednego elementu, który jest najmniejszym elementem tablicy $A$. Ponadto $n-1$ pozostałych elementów jest ustawionych w~kolejności niemalejącej w~podtablicy $A[2\twodots n]$. Stąd mamy, że tablica $A$ jest posortowana.
\end{description}

\exercise %6.4-3
Na podstawie analizy zamieszczonej w~podręczniku czasem działania algorytmu heapsort dla tablicy o~rozmiarze $n$ jest $O(n\lg n)$. Z~\refExercise{6.4-5} mamy, że jest to w~rzeczywistości oszacowanie dokładne. A~zatem w~szczególności dla tablicy posortowanej rosnąco i~tablicy posortowanej malejąco heapsort działa w~czasie $\Theta(n\lg n)$.

\exercise %6.4-4
Przypadek pesymistyczny algorytmu heapsort ma miejsce wówczas, gdy każde wywołanie \proc{Max-Heapify} z~wiersza~5 schodzi rekurencyjnie aż do ostatniego poziomu drzewa. Czasem potrzebnym na zbudowanie kopca z~tablicy \compound{$n$}{elementowej} jest $\Theta(n)$. Na mocy wyniku z~\refExercise{6.2-6} oraz wzoru~(3.18) czasem działania algorytmu heapsort w~takim przypadku jest
\[
	T(n) = \Theta(n)+\sum_{i=2}^{n}\Omega(\lg i) = \Theta(n)+\Omega(\lg(n!)) = \Omega(n\lg n).
\]

\exercise %6.4-5
Dokonamy analizy liczby wykonywanych instrukcji z~linii~9 procedury \proc{Max-Heapify} podczas działania algorytmu sortowania przez kopcowanie w~przypadku optymistycznym.

Załóżmy, że algorytm heapsort działa na tablicy $A$ o~rozmiarze $n=2^{h+1}-1$, gdzie $h$ jest pewną dodatnią liczbą całkowitą. A~zatem kopiec zbudowany z~$A$ stanowi pełne drzewo binarne o~wysokości $h$. Rozważanie tylko takich kopców nie powoduje zmniejszenia ogólności analizy. Przez \compound{$j$}{ty} etap działania algorytmu heapsort, gdzie $0\le j\le h-1$, będziemy rozumieć działania wykonane podczas iteracji pętli \kw{for} z~procedury \proc{Heapsort}, w~których $2^{h-j}\le i\le2^{h-j+1}-1$. Inaczej mówiąc, \compound{$j$}{ty} etap pozbawia kopiec \compound{$(h-j)$}{tego} poziomu.

\medskip
\noindent\textsf{\textbf{Lemat.}} \textit{Podczas\/ \compound{$j$}{tego} etapu działania algorytmu heapsort na kopcu\/ $A$ o~rozmiarze\/ $n=2^{h+1}-1$,\/ $h\ge1$, którego wszystkie elementy są różne, liczba wykonanych zamian elementów w~linii~9 procedury \proc{Max-Heapify},\/ $m_j$, jest większa niż\/ $(h-j-5)2^{h-j-3}$.}
\begin{proof}
Niech $j=0$. Bez utraty ogólności załóżmy, że $\langle A[1],A[2],\dots,A[n]\rangle$ jest permutacją $\langle1,2,\dots,n\rangle$. Liczbę $k$ będziemy nazywać \emph{dużą}, jeśli $k\ge(n+1)/2$. Niech $S$ będzie zbiorem indeksów dużych elementów w~kopcu $A$, które nie są liśćmi, czyli
\[
    S = \biggl\{\,i\in\Bigl\{1,2,\dots,\frac{n-1}{2}\Bigr\}:A[i]\ge\frac{n+1}{2}\,\biggr\}.
\]
Zauważmy, że wszystkie elementy, których pozycjami w~$A$ są indeksy ze zbioru $S$, zostaną usunięte z~kopca w~etapie $j=0$. A~zatem muszą wpierw znaleźć się w~korzeniu kopca za sprawą wykonania pewnej liczby zamian z~linii~9 procedury \proc{Max-Heapify}. Stąd $m_0$ -- ich liczba w~zerowym etapie -- spełnia nierówność
\[
    m_0 \ge \sum_{i\in S}d_i,
\]
gdzie $d_i$ oznacza głębokość węzła o~początkowej pozycji $i$ w~kopcu $A$.

Węzły o~indeksach ze zbioru $S$ tworzą w~kopcu $A$ poddrzewo $T$ o~korzeniu w~$A[1]$. Jest tak dlatego, że jeśli węzeł $A[i]$ jest duży, to $A[\proc{parent}(i)]$ również jest duży, a~więc także wszystkie węzły na ścieżce od $A[i]$ do korzenia kopca, czyli $A[1]$. Jeśli zastąpimy każde puste poddrzewo w~$T$ pojedynczym węzłem, to dostaniemy regularne drzewo binarne, którego długość ścieżki wewnętrznej (patrz \refExercise{B.5-5}) wynosi $m_0$. W~zbiorze wszystkich drzew binarnych o~$|S|$ węzłach wewnętrznych najmniejsza możliwa długość ścieżki wewnętrznej jest osiągana dla pełnego drzewa binarnego i~wynosi $\sum_{k=1}^{|S|}\lfloor\lg k\rfloor$. Korzystając ze wzoru~(3.3) i~\refExercise{8.1-2}, mamy
\[
    m_0 \ge \sum_{k=1}^{|S|}\lfloor\lg k\rfloor > \sum_{k=1}^{|S|}(\lg k-1) = \sum_{k=1}^{|S|}\lg k-|S| \ge \frac{|S|}{2}\lg\frac{|S|}{2}-|S| = \frac{|S|}{2}\lg|S|-\frac{3}{2}|S|.
\]

Pokażemy teraz, że $|S|\ge2^{h-2}$. Rozważmy w~tym celu permutację $\pi$ elementów kopca $A$ na początku zerowego etapu w~kolejności ich odwiedzania podczas przechodzenia kopca metodą inorder. Jeśli $\pi(i)$, gdzie $i\ge2$, jest liściem kopca, to $\pi(i-1)$ nie może być liściem kopca. Jeśli w~dodatku $\pi(i)$ jest dużym liściem, to $\pi(i-1)$ jest dużym węzłem wewnętrznym. Stąd indeks elementu $\pi(i-1)$ należy do $S$. Mamy więc, że $l$ -- liczba dużych liści -- nie może przekroczyć $|S|+1$, nawet jeśli $\pi(1)$ jest dużym liściem. Ponieważ liczba dużych elementów wynosi $(n+1)/2=2^h$, to otrzymujemy, że $|S|=2^h-l\ge2^h-(|S|+1)$, skąd $|S|\ge2^{h-1}-1/2\ge2^{h-2}$.

Powracając teraz do oszacowania na $m_0$, mamy
\[
    m_0 > \frac{|S|}{2}\lg|S|-\frac{3}{2}|S| = \frac{|S|}{2}(\lg|S|-3) \ge 2^{h-3}(h-5),
\]
czyli lemat jest prawdziwy, gdy $j=0$.

Na początku \compound{$j$}{tego} etapu kopiec ma wysokość $h-j$, więc dowód lematu dla \compound{$j$}{tego} etapu, gdzie $1\le j\le h-1$, sprowadza się do dowodu oszacowania $m_0$ dla kopca o~rozmiarze $n=2^{h-j+1}-1$.
\end{proof}

Załóżmy teraz, że $h\ge5$. Sumaryczną liczbę zamian elementów podczas sortowania $n$ liczb możemy dzięki powyższemu lematowi ograniczyć od dołu:
\[
    \sum_{j=0}^{h-1}m_j > \sum_{j=0}^{h-5}m_j > \sum_{j=0}^{h-5}(h-j-5)2^{h-j-3} = \sum_{j=0}^{h-5}j2^{j+2} = 4\sum_{j=0}^{h-5}j2^j.
\]
Ostatnią sumę obliczamy poprzez skorzystanie ze wzoru~(A.5):
\[
    \sum_{j=0}^{h-5}jx^j = x\cdot\frac{d}{dx}\biggl(\sum_{j=0}^{h-5}x^j\biggr) = x\cdot\frac{d}{dx}\biggl(\frac{x^{h-4}-1}{x-1}\biggr) = x\,\frac{(h-4)x^{h-5}(x-1)-(x^{h-4}-1)}{(x-1)^2}.
\]
Przyjmując teraz $x=2$ i~korzystając z~nierówności $2^h>n/2$ i~$h>\lg n-1$, mamy ostatecznie
\[
    4\sum_{j=0}^{h-5}j2^j = (h-4)2^{h-2}-2^{h-1}+8 > (h-6)2^{h-2} > \frac{1}{8}n\lg n-\frac{7}{8}n = \Omega(n\lg n).
\]
Otrzymany wynik stanowi oszacowanie czasu działania algorytmu heapsort w~przypadku optymistycznym.

\subchapter{Kolejki priorytetowe}

\exercise %6.5-1
Na rys.~\ref{fig:6.5-1} został przedstawiony kopiec wejściowy $A$ i~wynikowy kopiec otrzymany w~wyniku działania procedury \proc{Heap-Extract-Max}. W~wierszu~3 zmiennej \id{max} przypisywana jest maksymalna wartość kopca, czyli 15. Następnie korzeń otrzymuje wartość 1 i~rozmiar kopca jest pomniejszany o~1. Po przywróceniu własności kopca w~linii~6 procedura zwraca wartość \id{max}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig06.4}
	\end{center}
	\caption{Działanie procedury \proc{Heap-Extract-Max} dla kopca $A=\langle15,13,9,5,12,8,7,4,0,6,2,1\rangle$. {\sffamily\bfseries(a)} Kopiec wejściowy $A$. {\sffamily\bfseries(b)} Kopiec $A$ po usunięciu maksymalnej wartości i~przywróceniu własności kopca naruszonej przez korzeń, któremu wcześniej przypisano wartość 1.} \label{fig:6.5-1}
\end{figure}

\exercise %6.5-2
Procedura \proc{Max-Heap-Insert} rozpoczyna działanie od dodania do kopca nowego elementu o~wartości $-\infty$. Wartość ta jest następnie odpowiednio modyfikowana i~element jest umieszczany w~odpowiednim miejscu w~kopcu dzięki wywołaniu \proc{Heap-Increase-Key}. Działanie procedury $\proc{Max-Heap-Insert}(A,10)$ zostało przedstawione na rys.~\ref{fig:6.5-2}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig06.5}
	\end{center}
	\caption{Działanie procedury $\proc{Max-Heap-Insert}(A,10)$ dla kopca $A=\langle$15, 13, 9, 5, 12, 8, 7, 4, 0, 6, 2, 1$\rangle$. {\sffamily\bfseries(a)} Kopiec po dodaniu nowego elementu o~wartości początkowej $-\infty$. {\sffamily\bfseries(b)} Działa teraz procedura \proc{Heap-Increase-Key}. Na rysunku pokazano wartość zmiennej $i$ w~tej procedurze. Wartość nowego elementu została zwiększona i~wynosi teraz 10. {\sffamily\bfseries(c)} Po wykonaniu pierwszej iteracji pętli \kw{while} procedury \proc{Heap-Increase-Key} nowy element został zamieniony ze swoim ojcem. {\sffamily\bfseries(d)} Po drugiej iteracji pętli nastąpiła jeszcze jedna zamiana nowego elementu i~jego aktualnego ojca, dzięki czemu $A$ spełnia już własność kopca i~procedura kończy działanie.} \label{fig:6.5-2}
\end{figure}

\exercise %6.5-3
Zakładamy, że tablica $A$ stanowi kopiec typu min. Poniższe procedury stanowią implementację kolejki priorytetowej typu min i~działają analogicznie do odpowiadających procedur dla kolejki priorytetowej typu max.
\begin{codebox}
\Procname{$\proc{Heap-Minimum}(A)$}
\li	\Return $A[1]$
\end{codebox}
\begin{codebox}
\Procname{$\proc{Heap-Extract-Min}(A)$}
\li	\If $\id{heap-size}[A]<1$
\li		\Then \Error ``kopiec pusty''
		\End
\li	$\id{min}\gets A[1]$
\li	$A[1]\gets A[\id{heap-size}[A]]$
\li	$\id{heap-size}[A]\gets\id{heap-size}[A]-1$
\li	$\proc{Min-Heapify}(A,1)$
\li	\Return \id{min}
\end{codebox}
\begin{codebox}
\Procname{$\proc{Heap-Decrease-Key}(A,i,\id{key})$}
\li	\If $\id{key}>A[i]$
\li		\Then \Error ``nowy klucz jest większy niż klucz aktualny''
		\End
\li	$A[i]\gets\id{key}$
\li	\While $i>1$ i~$A[\proc{Parent}(i)]>A[i]$
\li		\Do
			zamień $A[i]\leftrightarrow A[\proc{Parent}(i)]$
\li			$i\gets\proc{Parent}(i)$
		\End
\end{codebox}
\begin{codebox}
\Procname{$\proc{Min-Heap-Insert}(A,\id{key})$}
\li	$\id{heap-size}[A]\gets\id{heap-size}[A]+1$
\li	$A[\id{heap-size}[A]]\gets\infty$
\li	$\proc{Heap-Decrease-Key}(A,\id{heap-size}[A],\id{key})$
\end{codebox}

\exercise %6.5-4
Po wykonaniu wiersza~1 procedury \proc{Max-Heap-Insert} wartość $A[\id{heap-size}[A]]$ pozostaje niezdefiniowana i~może zawierać liczbę większą niż \id{key}, a~wówczas wywołanie \proc{Heap-Increase-Key} zakończy się z~błędem. Operacja \proc{Increase-Key} jest częścią interfejsu kolejki priorytetowej typu max, więc procedura ją implementująca służy nie tylko jako procedura pomocnicza dla \proc{Max-Heap-Insert}.

\exercise %6.5-5
\begin{description}
	\item[Inicjowanie:] Przed wykonaniem wiersza~3 tablica $A[1\twodots\id{heap-size}[A]]$ jest kopcem typu max. Zwiększenie wartości $A[i]$ może naruszyć własność kopca tylko dla elementów $A[i]$ oraz $A[\proc{Parent}(i)]$.
	\item[Utrzymanie:] Dokonując zamiany elementów w~wierszu~5 w~bieżącej iteracji pętli, przywracamy własność kopca dla elementów $A[i]$ oraz $A[\proc{Parent}(i)]$. Jednak operacja ta może wygenerować nową parę elementów niespełniających własności kopca: $A[\proc{Parent}(i)]$ oraz $A[\proc{Parent}(\proc{Parent}(i))]$. Aktualizacja wartości $i$ powoduje zachowanie niezmiennika, albowiem nowa para elementów jest jedyną, która może naruszać własność kopca.
	\item[Zakończenie:] Pętla kończy działanie, gdy $i\le1$ lub $A[\proc{Parent}(i)]\ge A[i]$. W~pierwszym przypadku $i$ nie odnosi się do poprawnego indeksu tablicy, natomiast w~drugim przypadku jedyna para, która mogłaby naruszać własność kopca, w~rzeczywistości ją spełnia. A~zatem po zakończeniu wykonywania pętli tablica $A[1\twodots\id{heap-size}[A]]$ stanowi kopiec typu max.
\end{description}
Z~prawdziwości niezmiennika pętli wynika, że procedura \proc{Heap-Increase-Key} poprawnie zwiększa wartość węzła $i$, pozostawiając kopiec typu max.

\exercise %6.5-6
Kolejkę FIFO implementujemy, wykorzystując do tego celu kolejkę priorytetową typu min. Przy inicjalizacji kolejki będziemy ustawiać wartość pewnej dodatkowej zmiennej \id{rank} na 1. Przed dodaniem nowego elementu do kolejki FIFO nadamy mu rangę, czyli powiążemy go z~aktualną wartością zmiennej \id{rank}, po czym wstawimy element wraz z~jego rangą do kolejki priorytetowej procedurą \proc{Min-Heap-Insert}. Warunek kolejki priorytetowej spełniany będzie na podstawie wartości rang elementów. Po umieszczeniu obiektu w~kolejce wartość zmiennej \id{rank} zostanie zwiększona o~1. Z~kolei usuwanie elementów będzie odbywać się poprzez zwykłe wywołanie procedury \proc{Heap-Extract-Min}. Taka implementacja operacji na kolejce FIFO zapewnia, że w~danym momencie w~strukturze danych nie będzie dwóch różnych elementów z~tą samą rangą i~elementy pobierane będą w~odpowiedniej kolejności.

Realizacja stosu jest podobna, ale używamy do tego celu kolejki priorytetowej typu max, w~której porównań dokonujemy na rangach związanych z~elementami. Podczas wstawiania elementów na stos korzystamy z~procedury \proc{Max-Heap-Insert} i~inkrementujemy zmienną \id{rank} (początkowo zainicjalizowaną na 1). Usuwanie ze stosu polega na odnalezieniu i~pobraniu elementu z~największą rangą, co realizowane jest za pomocą \proc{Heap-Extract-Max}. W~wyniku tego elementy pobierane są w~kolejności odwrotnej do tej, w~której były wstawiane.

\exercise %6.5-7
Przedstawiona poniżej procedura \proc{Heap-Delete} usuwa węzeł $i$ z~\compound{$n$}{elementowego} kopca $A$ typu max poprzez zwiększenie wartości tego węzła tak, aby stanowił on element maksymalny kopca, a~następnie usunięcie go procedurą \proc{Heap-Extract-Max}.
\begin{codebox}
\Procname{$\proc{Heap-Delete}(A,i)$}
\li	$\proc{Heap-Increase-Key}(A,i,\infty)$
\li	$\proc{Heap-Extract-Max}(A)$
\end{codebox}

Ponieważ obie wywoływane procedury działają w~czasie $O(\lg n)$, to czasem działania \proc{Heap-Delete} jest również $O(\lg n)$.

\exercise %6.5-8
W~algorytmie wykorzystamy kolejkę priorytetową typu min jako strukturę pomocniczą. Na początku działania do kolejki zostaną przeniesione pierwsze elementy z~każdej listy. Jest oczywiste, że wśród tych elementów znajduje się najmniejszy element listy wynikowej. Aby go uzyskać, wystarczy wywołać na kolejce operację \proc{Extract-Min}. Kolejnego elementu należy szukać wśród aktualnych węzłów kolejki lub na pierwszej pozycji listy, do której początkowo należało pobrane przed chwilą minimum. Element tej listy, o~ile istnieje, przenosimy do kolejki. W~kolejnych krokach pobieramy najmniejszy element kolejki i~dodajemy do listy wynikowej, po czym uzupełniamy kolejkę pierwszym elementem z~listy, do której należał pobrany element, jeśli lista ta nie jest jeszcze pusta. Algorytm wykonujemy aż do opróżnienia kolejki, co następuje po przetworzeniu zawartości wszystkich list.

Podczas działania algorytmu wykonamy $n$ razy operację wstawienia węzła do kolejki zawierającej co najwyżej $k$ elementów i~tyle samo operacji ekstrakcji węzła o~najmniejszej wartości, co prowadzi do górnego oszacowania $O(n\lg k)$ na czas działania algorytmu, przy założeniu, że kolejka priorytetowa została zaimplementowana w~oparciu o~kopiec typu min.

\problems

\problem{Budowa kopca przez wstawianie} %6-1

\subproblem %6-1(a)
Procedury te nie zawsze generują identyczne kopce z~tej samej tablicy wejściowej. Jeśli na przykład rozważymy tablicę $A=\langle1,2,3\rangle$, to kopce budowane przez obie procedury różnią się, jak to widać na rys.~\ref{fig:6-1(a)}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig06.6}
	\end{center}
	\caption{Porównanie kopców budowanych przez obie procedury dla tablicy $A=\langle1,2,3\rangle$. {\sffamily\bfseries(a)} Wynik działania \proc{Build-Max-Heap}. {\sffamily\bfseries(b)} Wynik działania \proc{Build-Max-Heap}$'$.} \label{fig:6-1(a)}
\end{figure}

\subproblem %6-1(b)
Najgorszym przypadkiem dla procedury \proc{Build-Max-Heap}$'$ jest tablica uporządkowana rosnąco. W~każdym z~$n-1$ wywołań \proc{Max-Heap-Insert} z~wiersza~3 należy przetransportować nowy węzeł aż do korzenia kopca, co wymaga $\Theta(\lg i)$ operacji przy \compound{$i$}{elementowym} kopcu, zatem czas działania \proc{Build-Max-Heap}$'$ w~przypadku pesymistycznym wynosi
\[
	T(n) = \sum_{i=1}^{n-1}\Theta(\lg i) = \Theta(\lg(n!)) = \Theta(n\lg n),
\]
ponieważ $\lg(n!)=\Theta(n\lg n)$ (ze wzoru~(3.18)).

\problem{Analiza kopców rzędu $d$} %6-2

\subproblem %6-2(a)
\compound{$d$}{kopiec} będziemy reprezentować w~tablicy w~następujący sposób. Podobnie jak w~reprezentacji tablicowej kopców binarnych tablica $A$ reprezentująca \compound{$d$}{kopiec} ma atrybuty $\id{length}[A]$ oraz $\id{heap-size}[A]$ o~tym samym znaczeniu. Pierwsza pozycja tablicy będzie zawierać korzeń kopca, a~pozycje $2\twodots d+1$ będą zajmowane przez $d$ synów korzenia. Synowie pierwszego z~lewej syna korzenia zajmą pozycje $d+2\twodots2d+1$, synowie drugiego od lewej syna korzenia -- pozycje $2d+2\twodots3d+1$ itd. Ogólnie, mając dany indeks węzła $i$, można wyznaczyć indeks jego ojca, korzystając ze wzoru $\lceil(i-1)/d\rceil$. Na tej podstawie implementujemy uogólnienie procedury \proc{Parent} dla kopca rzędu $d$.
\begin{codebox}
\Procname{$\proc{d-ary-Parent}(d,i)$}
\zi	\Return $\lceil(i-1)/d\rceil$
\end{codebox}
Podobnie, można sprawdzić, że indeks \compound{$k$}{tego} od lewej syna węzła o~indeksie $i$, gdzie $k=1$, 2,~\dots,~$d$, jest opisany wzorem $d(i-1)+k+1$. Poniższa procedura stanowi uogólnienie procedur \proc{Left} i~\proc{Right} dla kopca rzędu $d$ -- w~porównaniu do nich przyjmuje dodatkowy parametr $k$ oznaczający numer szukanego syna węzła $i$.
\begin{codebox}
\Procname{$\proc{d-ary-Child}(d,k,i)$}
\zi	\Return $d(i-1)+k+1$
\end{codebox}

Można sprawdzić, że dla $1\le k\le d$ zachodzi $\proc{d-ary-Parent}(d,\proc{d-ary-Child}(d,k,i))=i$.

\subproblem %6-2(b)
Uogólnimy rozumowanie z~\refExercise{6.1-1} na kopce rzędu $d$. Potraktujmy taki kopiec jak drzewo \compound{$d$}{arne} o~wysokości $h$ i~$n$ węzłach. Na \compound{$i$}{tym} poziomie tego drzewa, gdzie $0\le i<h$, znajduje się $d^i$ węzłów. Najniższy, \compound{$h$}{ty} poziom może zawierać od 1 do $d^h$ węzłów. Mamy zatem
\[
    \sum_{i=0}^{h-1}d^i+1 \le n \le \sum_{i=0}^hd^i.
\]
Obie sumy ograniczające $n$ można oszacować przez $\Theta(d^h)$, skąd $h=\Theta(\log_dn)$.

\subproblem %6-2(c)
Przedstawimy najpierw implementację procedury \proc{Max-Heapify} dla kopców rzędu $d$. Ogólny zarys jej działania pozostaje niezmieniony w~porównaniu z~oryginalną procedurą \proc{Max-Heapify}. Na każdym poziomie rekursji musimy wyznaczyć maksimum z~$d+1$ wartości -- bieżącego węzła i~jego $d$ synów. W~tym celu stosujemy pętlę przebiegającą wszystkich synów bieżącego węzła.
\begin{codebox}
\Procname{$\proc{d-ary-Max-Heapify}(A,d,i)$}
\li	$\id{largest}\gets i$
\li	$k\gets1$
\li	$\id{child}\gets\proc{d-ary-Child}(d,1,i)$
\li	\While $k\le d$ i~$\id{child}\le\id{heap-size}[A]$ \label{li:d-ary-max-heapify-while-begin}
\li		\Do
			\If $A[\id{child}]>A[\id{largest}]$
\li				\Then $\id{largest}\gets\id{child}$
				\End
\li			$k\gets k+1$
\li			$\id{child}\gets\proc{d-ary-Child}(d,k,i)$ \label{li:d-ary-max-heapify-child}
		\End \label{li:d-ary-max-heapify-while-end}
\li	\If $\id{largest}\ne i$
\li		\Then
			zamień $A[i]\leftrightarrow A[\id{largest}]$
\li			$\proc{d-ary-Max-Heapify}(A,d,\id{largest})$
		\End
\end{codebox}
Zauważmy, że podczas wykonywania pętli \kw{while} w~wierszach~\ref{li:d-ary-max-heapify-while-begin}\nobreakdash--\ref{li:d-ary-max-heapify-while-end} zmienna $k$ może przyjąć wartość $d+1$ i~wówczas w~wierszu~\ref{li:d-ary-max-heapify-child} zostaje wyznaczony indeks nieistniejącego, \compound{$(d+1)$}{szego} syna węzła $i$. Jednak wartości tej nigdzie później nie wykorzystujemy, ponieważ następną operacją jest przerwanie pętli \kw{while}.

Na każdym poziomie rekursji wykonywanych jest $O(d)$ operacji. Na mocy poprzedniego punktu mamy $O(\log_dn)$ wywołań rekurencyjnych, a~zatem czasem działania powyższej procedury jest $O(d\log_dn)$.

Procedura \proc{d-ary-Extract-Max}, która implementuje operację \proc{Extract-Max} dla \compound{$d$}{kopca}, przyjmuje jako parametry kopiec $A$ oraz jego rząd $d$. Jej działanie jest identyczne jak operacji \proc{Extract-Max} dla zwykłych kopców, jednak w~wierszu~6 zamiast procedury \proc{Max-Heapify} wywoływana jest procedura \proc{d-ary-Max-Heapify} przedstawiona powyżej. Czas działania tej operacji wynosi $O(d\log_dn)$.

\subproblem %6-2(d)
Procedura \proc{d-ary-Max-Heap-Insert} implementująca operację \proc{Insert} dla \compound{$d$}{kopca} przyjmuje na wejściu kopiec $A$, rząd kopca $d$ oraz wartość \id{key}, która będzie wstawiana do $A$. Jej działanie jest analogiczne do procedury wstawiania węzła do kopca binarnego. Jedyną różnicą jest wiersz~3, który zamiast $\proc{Heap-Increase-Key}$ zawiera analogiczne wywołanie procedury \proc{d-ary-Heap-Increase-Key} zwiększającej wartość węzła w~kopcu rzędu $d$.

Czas działania operacji \proc{Insert} dla \compound{$d$}{kopca} jest tego samego rzędu co czas działania wywołania z~wiersza~3. Implementacja wywoływanej procedury \proc{d-ary-Heap-Increase-Key} i~analiza jej czasu działania zostały opisane w~następnym punkcie.

\subproblem %6-2(e)
Implementacja tej operacji jest analogiczna jak w~przypadku kopca binarnego. Jednak zamiast sprawdzania poprawności parametru $k$, do $A[i]$ jest przypisywana od razu odpowiednia wartość.
\begin{codebox}
\Procname{$\proc{d-ary-Heap-Increase-Key}(A,d,i,k)$}
\li	$A[i]\gets\max(A[i],k)$ \label{li:d-ary-heap-increase-key}
\li	\While $i>1$ i~$A[\proc{d-ary-Parent}(d,i)]<A[i]$
\li		\Do
			zamień $A[i]\leftrightarrow A[\proc{d-ary-Parent}(d,i)]$
\li			$i\gets\proc{d-ary-Parent}(d,i)$
		\End
\end{codebox}

Po wykonaniu wiersza~\ref{li:d-ary-heap-increase-key} wartość węzła $i$ może przekroczyć wartość jego ojca. W~najgorszym przypadku jeśli węzeł $i$ jest liściem i~jego nowa wartość jest największą wartością w~drzewie, to zostanie on przetransportowany aż do korzenia drzewa, co wymaga czasu proporcjonalnego do wysokości drzewa, czyli, na mocy punktu~(b), $O(\log_dn)$.

\problem{Tablice Younga} %6-3

\subproblem %6-3(a)
Jedną z~możliwych tablic Younga zawierających podane elementy jest
\[
	\begin{pmatrix}
		2 & 3 & 14 & 16 \\
		4 & 8 & \infty & \infty \\
		5 & 12 & \infty & \infty \\
		9 & \infty& \infty & \infty
	\end{pmatrix}.
\]

\subproblem %6-3(b)
Załóżmy, że $Y[1,1]=\infty$ i~tablica $Y$ nie jest pusta, tzn.\ $Y[i,j]\ne\infty$ dla pewnych $i$, $j$ takich, że $1\le i\le m$ oraz $1\le j\le n$. Ale z~własności tablicy Younga otrzymujemy, że $Y[1,1]\le Y[1,j]\le Y[i,j]$, co prowadzi do sprzeczności z~założeniem. A~więc tablica Younga $Y$, w~której $Y[1,1]=\infty$, jest pusta.

Dowód drugiej własności przebiega analogicznie. Przypuśćmy, że $Y[m,n]\ne\infty$ i~że tablica $Y$ nie jest pełna, tzn.\ $Y[i,j]=\infty$ dla pewnych $i$, $j$, gdzie $1\le i\le m$ oraz $1\le j\le n$. Wykorzystując własność tablicy Younga, dostajemy $Y[i,j]\le Y[i,n]\le Y[m,n]$, co jest sprzeczne z~założeniem. Tablica Younga $Y$, w~której $Y[m,n]\ne\infty$, jest pełna.

\subproblem %6-3(c)
Procedura ekstrakcji najmniejszego elementu tablicy Younga $Y$ o~rozmiarach $m\times n$ została oparta o~pomysł z~\proc{Max-Heapify}. Najmniejszym elementem tablicy $Y$ jest $\mu=Y[1,1]$, przetransportujemy go więc na ostatnią pozycję ostatniego wiersza tablicy, skąd będzie go można bezpiecznie usunąć przy jednoczesnym zachowaniu własności tablicy Younga. W~tym celu porównajmy $\mu$ z~elementem znajdującym się bezpośrednio na prawo i~elementem bezpośrednio w~dół od niego (o~ile istnieją). Mniejszy z~nich zamieniany jest następnie z~$\mu$, po czym procedura wywołuje się rekurencyjnie dla podtablicy Younga o~rozmiarach $(m-1)\times n$ albo $m\times(n-1)$, w~której $\mu$ stanowi pierwszy element pierwszej kolumny. Otrzymując w~wyniku tego postępowania tablicę o~rozmiarach $1\times1$, można usunąć jej jedyny element będący najmniejszym elementem początkowej tablicy Younga (zastępując go wartością $\infty$) i~zwrócić go jako wynik algorytmu.

Opisany sposób został zaimplementowany w~poniższym pseudokodzie. Aby pobrać minimum z~tablicy Younga $Y$ o~rozmiarach $m\times n$, należy wywołać $\proc{Young-Extract-Min}(Y,m,n,1,1)$.
\begin{codebox}
\Procname{$\proc{Young-Extract-Min}(Y,m,n,i,j)$}
\li	\If $i=m$ i~$j=n$
\li		\Then
			$\id{min}\gets Y[i,j]$
\li			$Y[i,j]\gets\infty$
\li			\Return \id{min}
		\End
\li	$i'\gets i$
\li	$j'\gets j+1$
\li	\If $i<m$
\li		\Then
			\If $j=n$ lub $Y[i+1,j]<Y[i,j+1]$
\li				\Then
					$i'\gets i+1$
\li					$j'\gets j$
				\End
		\End
\li	zamień $Y[i,j]\leftrightarrow Y[i',j']$
\li	\Return $\proc{Young-Extract-Min}(Y,m,n,i',j')$
\end{codebox}

Niech $T(p)$ będzie maksymalnym czasem działania powyższego algorytmu dla tablicy Younga $m\times n$, gdzie $p=m+n$ jest łączną liczbą jej kolumn i~wierszy. W~każdym wywołaniu rekurencyjnym zmniejszamy $p$ o~1, wykonując przy tym czas stały, skąd dostajemy
\[
	T(p) =
	\begin{cases}
		O(1), & \text{jeśli $p=2$}, \\
		T(p-1) + O(1), & \text{jeśli $p>2$}.
	\end{cases}
\]
Łatwo sprawdzić, że rozwiązaniem tej rekurencji jest $T(p)=O(p)=O(m+n)$.

\subproblem %6-3(d)
Ponieważ tablica Younga $Y$ nie jest pełna, to na mocy punktu~(b) mamy $Y[m,n]=\infty$, czyli pozycja ta jest pusta i~można wstawić na nią nowy element. Wówczas jednak własność tablicy Younga może być naruszona, dlatego korzystamy z~procedury \proc{Youngify} w~celu przywrócenia tej własności.
\begin{codebox}
\Procname{$\proc{Young-Insert}(Y,m,n,\id{key})$}
\li	$Y[m,n]\gets\id{key}$
\li	$\proc{Youngify}(Y,m,n)$
\end{codebox}

Procedura \proc{Youngify} działa analogicznie jak \proc{Max-Heapify}. Element $Y[i,j]$ wystarczy porównać z~jego sąsiadem znajdującym się wyżej lub sąsiadem znajdującym się po lewej stronie w~tablicy (o~ile istnieją). W~zależności od tego, który z~tych trzech elementów jest największy, dokonywana jest odpowiednia zamiana i~procedura wywoływana jest rekurencyjnie.
\begin{codebox}
\Procname{$\proc{Youngify}(Y,i,j)$}
\li	$i'\gets i$
\li	$j'\gets j$
\li	\If $i>1$ i~$Y[i-1,j]>Y[i',j']$
\li		\Then $i'\gets i-1$
		\End
\li	\If $j>1$ i~$Y[i,j-1]>Y[i',j']$
\li		\Then
			$i'\gets i$
\li			$j'\gets j-1$
		\End
\li	\If $i'\ne i$ lub $j'\ne j$
\li		\Then
			zamień $Y[i,j]\leftrightarrow Y[i',j']$
\li			$\proc{Youngify}(Y,i',j')$
		\End
\end{codebox}

Analiza poprawności i~czasu działania procedury \proc{Youngify} opiera się na analizie procedury \proc{Max-Heapify}. W~kolejnych wywołaniach rekurencyjnych jedna z~liczb, $i$ lub $j$, jest mniejsza o~1. Koniec działania następuje w~najgorszym przypadku, gdy $i=j=1$, kiedy to wykona się $O(m+n)$ operacji. A~zatem czasem działania \proc{Young-Insert} jest również $O(m+n)$.

\subproblem %6-3(e)
Niech $A$ będzie tablicą $n^2$ liczb, które należy posortować. Poniższy algorytm buduje tablicę Younga $n\times n$ z~liczb tablicy $A$, wykonując na każdej z~nich operację \proc{Young-Insert}. Następnie liczby te są pobierane w~kolejności niemalejącej dzięki $n^2$ wywołaniom \proc{Young-Extract-Min}.
\begin{codebox}
\Procname{$\proc{Young-Sort}(A)$}
\li	$n\gets\sqrt{\id{length}[A]}$
\li	\For $i\gets1$ \To $n^2$
\li		\Do $\proc{Young-Insert}(Y,n,n,A[i])$
		\End
\li	\For $i\gets1$ \To $n^2$
\li		\Do $A[i]\gets\proc{Young-Extract-Min}(Y,n,n,1,1)$
		\End
\end{codebox}

Czas działania obu wywoływanych procedur wynosi $O(n)$, zatem powyższy algorytm działa w~czasie $O(n^3)$. Jeśli mamy danych $m$ liczb, gdzie $m$ jest kwadratem liczby całkowitej, to jesteśmy w~stanie posortować je przy użyciu tego algorytmu w~czasie $O(m^{3/2})$. Jest to lepsza złożoność niż kwadratowa, ale gorsza od złożoności liniowo-logarytmicznej.

\subproblem %6-3(f)
Zbadajmy, jak szukana liczba $x$ ma się do ostatniego elementu pierwszego wiersza tablicy Younga $m\times n$. Jeśli wartości te są równe, to oczywiście można zakończyć poszukiwania z~rezultatem pozytywnym. W~przeciwnym przypadku, w~zależności od tego, która z~liczb jest większa, odrzucamy z~dalszych poszukiwań cały pierwszy wiersz lub całą ostatnią kolumnę i~kontynuujemy szukanie $x$ w~otrzymanej podtablicy, która stanowi tablicę Younga $(m-1)\times n$ albo $m\times(n-1)$. W~momencie uzyskania tablicy pustej wiadomo, że szukanej liczby nie ma w~początkowej tablicy.
\begin{codebox}
\Procname{$\proc{Young-Search}(Y,m,n,x)$}
\li	$i\gets1$
\li	$j\gets n$
\li	\While $i\le m$ i~$j\ge1$
\li		\Do
			\If $x=Y[i,j]$
\li				\Then \Return \const{true}
				\End
\li			\If $x>Y[i,j]$
\li				\Then $i\gets i+1$
\li				\Else $j\gets j-1$
				\End
		\End
\li	\Return \const{false}
\end{codebox}

W~każdym kroku pętli \kw{while} zmniejszamy o~1 liczbę kolumn lub liczbę wierszy rozważanej tablicy, wykonując przy tym stałą liczbę operacji -- jasne jest zatem, że czas działania algorytmu wynosi $O(m+n)$.

\endinput
