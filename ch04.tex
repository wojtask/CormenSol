\chapter{Rekurencje}

\subchapter{Metoda podstawiania}

\exercise %4-1.1
Niech $c>0$ będzie stałą. Przyjmujemy następujące założenie:
\[
	T(\lceil n/2\rceil) \le c\lg(\lceil n/2\rceil).
\]
Na jego podstawie oraz z~wzoru~(3.3) otrzymujemy
\begin{align*}
	T(n) &\le c\lg(\lceil n/2\rceil)+1 \\
	&< c\lg(n/2+1)+1 \\
	&\le c\lg(3n/4)+1 \\
	&= c\lg n+c\lg(3/4)+1 \\
	&\le c\lg n,
\end{align*}
przy czym ostatnia nierówność wymaga, aby $c\ge1/(2-\lg3)$. Ponadto, w~wyprowadzeniu założono, że $n\ge4$.

Niech $T(1)=1$, wtedy $T(4)=3$ i~przyjmijmy, że wartość ta stanowi przypadek brzegowy indukcji. Łatwo można sprawdzić, że w~przypadku brzegowym oszacowanie zachodzi po uprzednim przyjęciu $c=3$, co ostatecznie kończy dowód, że $T(n)=O(\lg n)$.

\exercise %4-1.2
Przyjmijmy założenie, że
\[
	T(\lfloor n/2\rfloor) \ge c\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)
\]
dla pewnej dodatniej stałej~$c$. Korzystając z~wzoru~(3.3) mamy:
\begin{align*}
	T(n) &\ge 2c\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)+n \\
	&> 2c(n/2-1)\lg(n/4)+n \\
	&= 2c((n/2)\lg n-\lg n-n+2)+n \\
	&= cn\lg n-2c\lg n-2cn+4c+n \\
	&> cn\lg n-2c\lg n+n(1-2c) \\
	&\ge cn\lg n,
\end{align*}
Ostatni krok uzasadniamy, rozwiązując nierówność $n(1-2c)-2c\lg n\ge0$ ze względu na $c$:
\[
	c \le \frac{n}{2(n+\lg n)} \le \frac{n}{2n} = \frac{1}{2},
\]
a~zatem wybierając dowolne $0<c\le1/2$ spełniamy nierówność. Można przyjąć $T(1)=1$ za przypadek brzegowy indukcji, bo $T(1)\ge c\lg1=0$. Wykazaliśmy, że $T(n)=\Omega(n\lg n)$. Skoro rozwiązanie rekurencji jest klasy $O(n\lg n)$ oraz $\Omega(n\lg n)$, to na mocy tw.~3.1, jest również w~$\Theta(n\lg n)$.

\exercise %4-1.3
Przyjmijmy założenie, że $T(\lfloor n/2\rfloor)\le c\lfloor n/2\rfloor^2$ dla pewnej stałej $c>0$, czyli chcemy udowodnić, że $T(n)=O(n^2)$. Mamy zatem
\[
	T(n) \le 2c\lfloor n/2\rfloor^2+n \le 2cn^2\!/4 + n = cn^2\!/2+n \le cn^2,
\]
co jest prawdą, jeśli przyjmiemy $c\ge2$. Widać teraz, że z~mocniejszym założeniem przypadek brzegowy $T(1)=1$ jest spełniony.

\exercise %4-1.4
Rekurencję~(4.2) można przedstawić w~następujący sposób:
\[
	T(n) =
	\begin{cases}
		c_1, & \text{jeśli $n=1$}, \\
		T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+c_2n, & \text{jeśli $n>1$},
	\end{cases}
\]
dla pewnych stałych $c_1$,~$c_2>0$. Dla innych stałych $a_1$,~$a_2>0$ przyjmujemy założenia
\[
	T(\lfloor n/2\rfloor) \ge a_1\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor) \quad\text{oraz}\quad T(\lceil n/2\rceil) \le a_2\lceil n/2\rceil\lg(\lceil n/2\rceil),
\]
otrzymując:
\begin{align*}
	T(n) &= T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+c_2n \\
 	&\ge 2T(\lfloor n/2\rfloor)+c_2n \\
 	&\ge 2a_1\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)+c_2n \\
 	&> 2a_1(n/2-1)\lg(n/4)+c_2n \\
 	&= a_1n\lg n-2a_1n-2a_1\lg(n/4)+c_2n \\
 	&\ge a_1n\lg n,
\end{align*}
ponieważ zachodzi $\lfloor n/2\rfloor>n/2-1$ i~$\lfloor n/2\rfloor\ge n/4$ oraz można tak dobrać stałą $a_1$, aby prawdziwa była ostatnia nierówność powyższego wyprowadzenia. Podstawiając $a_1=c_2/4$ sprowadza się ona do $n\ge\lg(n/4)$, co jest prawdą dla wszystkich $n$ dodatnich, a~zatem jest $T(n)=\Omega(n\lg n)$.

Wykorzystując nierówność $\lceil n/2\rceil<n/2+1$ z~wzoru~(3.3), dowodzimy górnego oszacowania:
\begin{align*}
	T(n) &= T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+c_2n \\
	&\le 2T(\lceil n/2\rceil)+c_2n \\
	&\le 2a_2\lceil n/2\rceil\lg(\lceil n/2\rceil)+c_2n \\
	&< 2a_2(n/2+1)\lg\frac{n\lceil n/2\rceil}{n}+c_2n \\
	&\le a_2n\lg n+a_2(n+2)\lg\frac{\lceil n/2\rceil}{n}+2a_2\lg n+c_2n \\
	&\le a_2n\lg n.
\end{align*}
W~ostatniej nierówności skorzystano z~tego, że dla $n\ge2$ prawdą jest $\lg\frac{\lceil n/2\rceil}{n}\le\lg(2/3)<0$, a~zatem dobierając odpowiednio duże $a_2$, można uzasadnić nierówność, gdyż funkcja liniowa rośnie szybciej od logarytmicznej. Dokładniej, okazuje się, że przyjęcie $a_2=32c_2$ wystarcza, o~ile $n\ge12$.

Jako przypadek brzegowy rekurencji można przyjąć $T(12)=12c_1+44c_2$, dla którego otrzymane oszacowania zachodzą, o~ile $c_1$ jest dostatecznie małe. W~przeciwnym przypadku górne oszacowanie może nie być wystarczające, jednak zwiększenie $a_2$ pozwala na dowolne ograniczenie rekurencji od góry w~zależności od wartości stałych $c_1$ i~$c_2$. Niezależnie od ich doboru oszacowaniem górnym rekurencji $T(n)$ jest $O(n\lg n)$, co na mocy wcześniejszego wyniku dolnego oszacowania, implikuje $T(n)=\Theta(n\lg n)$.

\exercise %4-1.5
Wykorzystując założenie
\[
	T(\lfloor n/2\rfloor+17) \le c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)
\]
dla pewnej stałej $c>0$, otrzymujemy:
\begin{align*}
	T(n) &\le 2c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)+n \\
	&\le 2c(n/2+17)\lg(n/2+17)+n \\
	&\le (cn+34c)\lg(3n/4)+n \\
	&< cn\lg n+cn\lg(3/4)+34c\lg n+n \\
	&\le cn\lg n,
\end{align*}
co zachodzi, o~ile $n/2+17\le 3n/4$, skąd $n\ge68$ oraz
\[
    cn\lg(3/4)+34c\lg n+n \le 0
\]
Badając ostatnią nierówność można dojść do wyniku, że najmniejszym $n_0$ takim, że nierówność jest spełniona dla $n\ge n_0$ jest $n_0=789$, co zachodzi po przyjęciu $c\ge3124$. 

Zauważmy, że stosowanie równania $T(n)=2T(\lfloor n/2\rfloor+17)+n$ dla $n\le35$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n\le35$ i~niech stanowi to przypadek brzegowy rekurencji. Za przypadek bazowy indukcji musimy jednak przyjąć $T(789)=24243$, ze względu na ograniczenia na $n$. Ponieważ w~tym wypadku dla $c=3124$ oszacowanie zachodzi, to prawdą jest, że $T(n)=O(n\lg n)$.

Analiza rekurencji dla każdej innej stałej w~miejscu~17 przebiega analogicznie, inne są natomiast wartości $n_0$ i~$c$, jednak w~każdym takim przypadku, rekurencja jest klasy $O(n\lg n)$.

\exercise %4-1.6
Przyjmijmy, że $n=2^m$, skąd $m=\lg n$. Rekurencja przyjmuje teraz postać
\[
	T(2^m) = 2T(2^{m/2})+1.
\]
Z~kolei podstawiając $S(m)$ za $T(2^m)$ dostajemy
\[
	S(m) = 2S(m/2)+1,
\]
której rozwiązaniem jest $O(\lg m)$ (\zad{4.1-1}), przy czym nie dbamy o~to, czy $m/2$ jest całkowite.

By uzyskać oszacowanie dokładne, pozostaje udowodnić, że $S(m)=\Omega(\lg m)$. Przyjmujemy zatem założenie, że $S(m/2)\ge c\lg(m/2)$ dla $c>0$. Na jego podstawie otrzymujemy:
\[
	S(m) \ge 2c\lg(m/2)+1 = 2c\lg m-2c+1 \ge 2c\lg m,
\]
co oczywiście jest prawdą dla $c\le1/2$. Przyjęcie $S(1)=1$ na podstawę indukcji wystarcza, bo $S(1)\ge2c\lg1=0$, a~zatem $S(m)=\Omega(\lg m)$.

Ponieważ $S(m)=\Theta(\lg m)$, więc wracając do oryginalnej rekurencji i~starej zmiennej, mamy $T(n)=T(2^m)=S(m)=\Theta(\lg m)=\Theta(\lg\lg n)$.

\subchapter{Metoda drzewa rekursji}

\exercise %4-2.1
Ponieważ podłogi i~sufity nie mają większego znaczenia w~przypadku tej rekurencji, to spróbujemy znaleźć oszacowanie dla zależności $T'(n)=3T'(n/2)+n$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.1}
	\end{center}
	\caption{Drzewo rekursji $T'(n)=3T'(n/2)+n$} \label{fig:4.2-1}
\end{figure}
W~drzewie z~rys.~\ref{fig:4.2-1} jest $\lg n+1$ poziomów, na \twoparts{$i$}{tym} z~nich znajduje się $3^i$ węzłów, zatem jest $n^{\lg3}$ liści. Koszt węzła na poziomie $i$ wynosi $n/2^i$, skąd wynika, że łączny koszt wszystkich węzłów na \twoparts{$i$}{tej} głębokości jest równy $(3/2)^in$. Ponieważ liście wnoszą stały koszt, czyli $T'(1)=\Theta(1)$, to ostatni poziom ma wartość $\Theta(n^{\lg3})$. Na podstawie tych wartości rozwiązujemy rekurencję:
\begin{align*}
	T'(n) &= n+\frac{3}{2}n+\left(\frac{3}{2}\right)^2n+\cdots+\left(\frac{3}{2}\right)^{\lg n-1}n+\Theta(n^{\lg 3}) \\
	&= \sum_{i=0}^{\lg n-1}\left(\frac{3}{2}\right)^in+\Theta(n^{\lg 3}) \\
	&= \frac{\left(\frac{3}{2}\right)^{\lg n}-1}{\frac{3}{2}-1}+\Theta(n^{\lg 3}) \\[1mm]
	&= 2(n^{\lg 3-1}-1)+\Theta(n^{\lg 3}) \\
	&= O(n^{\lg 3}).
\end{align*}

Wykorzystując otrzymany wynik i~dla oryginalnej rekurencji przyjmując założenie
\[
	T(\lfloor n/2\rfloor)n\le c(\lfloor n/2\rfloor)^{\lg 3},
\]
dowodzimy metodą przez podstawianie, otrzymując
\begin{align*}
	T(n) &= 3T(\lfloor n/2\rfloor)+n \\
	&\le 3c(\lfloor n/2\rfloor)^{\lg 3}+n \\
	&\le 3c(n/2)^{\lg 3}+n \\
	&= cn^{\lg 3}+n.
\end{align*}
Nie możemy jednak na podstawie tego wyniku wywnioskować szukanego oszacowania. Wzmocnijmy zatem nasze założenie, niech
\[
	T(\lfloor n/2\rfloor) \le c(\lfloor n/2\rfloor)^{\lg 3}-b\lfloor n/2\rfloor,
\]
dla pewnego $b>0$. Mamy teraz
\begin{align*}
	T(n) &\le 3c(\lfloor n/2\rfloor)^{\lg 3}-3b\lfloor n/2\rfloor+n \\
	&\le 3c(n/2)^{\lg 3}-3b(n/2)+n \\
	&= cn^{\lg 3}-3b(n/2)+n \\
	&\le cn^{\lg 3}-bn,
\end{align*}
co zachodzi dla $b\ge2$. Ponadto, przyjęcie $c\ge b+1$ pozwala przyjąć $T(1)=1$ za podstawę indukcji, co kończy dowód, że górnym oszacowaniem rekurencji $T(n)$ jest $O(n^{\lg3})$.

\exercise %4-2.2
Drzewo rekursji $T(n)$ nie jest pełnym drzewem binarnym. Najkrótszą ścieżką od korzenia do liścia jest $n\to n/3\to n/9\to\dots\to n/3^i\to\dots\to1$. Liść tej gałęzi znajduje się na poziomie $i=\log_3n$. Ponieważ pełne drzewo binarne o~wysokości $\log_3n+1$ wnosi niewiększy koszt niż drzewo rekurencji $T(n)$, to zachodzi $T(n)\ge cn\log_3n$ dla pewnego $c>0$, a stąd $T(n)=\Omega(n\lg n)$.

\exercise %4-2.3
Dla uproszczenia pomijamy branie części całkowitych.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.2}
	\end{center}
	\caption{Drzewo rekursji $T(n)=4T(n/2)+cn$} \label{fig:4.2-3}
\end{figure}
W drzewie rekursji z~rys.~\ref{fig:4.2-3}, na \twoparts{$i$}{tym} poziomie jest $4^i$ węzłów, z~których każdy wnosi koszt równy $cn/2^i$. Stąd, kosztem całego poziomu jest $2^icn$. Współczynnik przy $n$ w~koszcie węzła maleje dwukrotnie wraz ze wzrostem poziomu, więc wysokością drzewa jest $\lg n$. Wnioskujemy zatem, że liczbą liści w~tym drzewie jest $4^{\lg n}=n^2$ i~że koszt ostatniego poziomu wynosi $\Theta(n^2)$. Sumując koszty z~każdego poziomu, otrzymujemy:
\begin{align*}
	T(n) &= cn+2cn+2^2cn+\cdots+2^{\lg n-1}cn+\Theta(n^2) \\
	&= \sum_{i=0}^{\lg n-1}2^icn+\Theta(n^2) \\
	&= (2^{\lg n}-1)cn+\Theta(n^2) \\
	&= (n-1)cn+\Theta(n^2) \\
	&= \Theta(n^2).
\end{align*}

Sprawdzamy otrzymany wynik wykorzystując do tego celu metodę podstawiania. Badamy najpierw oszacowanie dolne $T(n)$, przyjmując założenie
\[
	T(n/2) \ge d_1(n/2)^2,
\]
dla pewnej stałej $d_1>0$. Stąd:
\[
	T(n) \ge d_1n^2+cn \ge d_1n^2, 
\]
bo $c>0$, a~więc prawdą jest, że $T(n)=\Omega(n^2)$.

By udowodnić dodatkowo, że $T(n)=O(n^2)$, możemy przyjąć takie samo założenie indukcyjne ale z~przeciwnym znakiem nierówności, jednak nie uzyskamy szukanego ograniczenia górnego na $T(n)$. Przyjmijmy zatem, że dla stałych $d_2$,~$d_3>0$ zachodzi mocniejszy warunek
\[
	T(n/2) \le d_2(n/2)^2-d_3(n/2).
\]
Dowodzimy:
\[
	T(n) \le 4(d_2n^2\!/4-d_3n/2)+cn = d_2n^2-2d_3n+cn \le d_2n^2-d_3n,
\]
co jest prawdą, o~ile $d_3\ge c$. Przyjęcie $T(1)=1$ wymusza nałożenie na stałe dodatkowych ograniczeń, $d_1\le1$ oraz $d_3\le d_2-1$, jednak $T(1)$ można wtedy potraktować jako podstawę indukcji.

Dzięki metodzie podstawiania wykazaliśmy, że $T(n)=\Theta(n^2)$.

\exercise %4-2.4
Załóżmy, że $T(n)=\Theta(1)$ w przypadku, gdy $n\le a$ i wartość taka jest zwracana bezpośrednio (bez użycia rekurencji).
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.3}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n-a)+T(a)+cn$} \label{fig:4.2-4}
\end{figure}
Wysokość drzewa z~rys.~\ref{fig:4.2-4} wynosi $\lfloor n/a\rfloor$. \twoparts{$i$}{ty} poziom (oprócz zerowego i~ostatniego) wnosi koszt równy $c(n-a(i-1))$, a~ostatni $\Theta(1)$. Obliczamy koszt całego drzewa:
\begin{align*}
	T(n) &= cn+\sum_{i=1}^{\lfloor n/a\rfloor-1}c(n-a(i-1))+\Theta(1) \\
	&= cn+c\sum_{i=0}^{\lfloor n/a\rfloor-2}(n-ai)+\Theta(1) \\
	&= cn+cn\sum_{i=0}^{\lfloor n/a\rfloor-2}1-ca\sum_{i=0}^{\lfloor n/a\rfloor-2}i+\Theta(1) \\
	&= cn+cn(\lfloor n/a\rfloor-1)-ca\frac{(\lfloor n/a\rfloor-2)(\lfloor n/a\rfloor-1)}{2}+\Theta(1) \\[2mm]
	&= \Theta(n^2).
\end{align*}

\exercise %4-2.5
Zauważmy, że drzewo rekurencji $T(n)$ na rys.~\ref{fig:4.2-5} dla parametru $\alpha$ jest symetryczne do drzewa $T(n)$ przy parametrze $1-\alpha$, przyjmijmy więc, że $0<\alpha\le1/2$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.4}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(\alpha n)+T((1-\alpha)n)+cn$} \label{fig:4.2-5}
\end{figure}

Wyznaczmy najpierw oszacowanie dolne rekurencji. Na \twoparts{$i$}{tym} poziomie drzewa najmniejszy koszt wnoszą węzły o~wartościach $c\alpha^in$, a~więc elementy ze skrajnie lewej gałęzi. Sprawdzając kiedy osiągną one wartość stałą $d>0$, wyznaczamy najgłębszy poziom o~komplecie węzłów. Niższe poziomy są coraz mniej liczne, zatem sumując koszt węzłów drzewa $T(n)$ od korzenia aż do tego poziomu, uzyskujemy oszacowanie dolne rekurencji. Na pewnej głębokości $h$, będzie $c\alpha^hn=d$, skąd otrzymujemy $h=\log_{1/\alpha}(cn/d)$. Ponieważ $\alpha$ jest stałe, to $h=\Theta(\lg n)$. Każdy poziom o~głębokości nie przekraczającej $h$ wnosi koszt $cn$, więc oszacowaniem dolnym rekurencji jest $T(n)=\Omega(cn(h+1))=\Omega(n\lg n)$.

Badając teraz skrajnie prawą gałąź, której elementy wnoszą największy koszt wśród wszystkich poziomów, możemy dojść do oszacowania górnego dla $T(n)$. Na głębokości $H$ równej wysokości drzewa, mamy $c(1-\alpha)^Hn=d$, skąd $H=\log_{1/(1-\alpha)}(cn/d)$. Także w tym przypadku mamy $H=\Theta(\lg n)$, a~więc $T(n)=O(cn(H+1))=O(n\lg n)$, skąd asymptotycznie dokładnym rozwiązaniem rekurencji jest $\Theta(n\lg n)$.

\subchapter{Metoda rekurencji uniwersalnej}

\note{Zarówno w~wersji oryginalnej jak i~w~tłumaczeniu treści twierdzenia~4.1 znajduje się poważny brak, który uniemożliwia m.in.\ rozwiązanie \zad{4.4-3}. Dla stosowanej tam stałej\/ $c$ podany jest tylko warunek, aby była ona mniejsza od\/ $1$, podczas gdy poprawnym zakresem dla niej powinien być zbiór\/ $(0,1)$.}

\exercise %4-3.1

\subexercise
W równaniu~(4.5) przyjmujemy $a=4$ i~$b=2$ oraz $f(n)=n$. Ponieważ $f(n)=O(n^{2-\epsilon})$ dla $0<\epsilon\le1$, to z~tw.~o~rekurencji uniwersalnej mamy $T(n)=\Theta(n^2)$.

\subexercise
Postępując analogicznie jak w~poprzednim punkcie, mamy te same wartości $a$ i~$b$, ale teraz $f(n)=n^2$. Z~tego, że $f(n)=\Theta(n^2)$ dostajemy $T(n)=\Theta(n^2\lg n)$.

\subexercise
Dla tych samych $a$ i~$b$ ale $f(n)=n^3$, mamy $f(n)=\Omega(n^{2+\epsilon})$ dla $0<\epsilon\le1$ oraz
\[
	4f(n/2) = 4n^3\!/8 = n^3\!/2 = f(n)/2 \le cf(n),
\]
o~ile $c\ge1/2$, a~zatem warunek regularności jest spełniony i~$T(n)=\Theta(n^3)$.

\exercise %4-3.2
Rozwiążmy $T(n)$ korzystając z~metody rekurencji uniwersalnej. Ponieważ $n^{\log_ba}=n^{\lg7}$ oraz $f(n)=n^2=O(n^{\lg7-\epsilon})$ dla $0<\epsilon\le\lg7-2$, to zachodzi $T(n)=\Theta(n^{\lg7})$.

Pozostaje teraz zbadanie nierówności $T'(n)<T(n)$ w~zależności od parametru $a$, bo w~rekurencji $T'(n)$ jest $n^{\log_ba}=n^{\log_4a}$ oraz $f(n)=n^2$. Załóżmy, że $f(n)=O(n^{\log_4a-\epsilon})$, co jest prawdą dla $a>16$ i~wtedy $T'(n)=\Theta(n^{\log_4a})$. Algorytm $A'$ jest efektywniejszy od algorytmu $A$, gdy $\log_4a<\lg7$, skąd $16<a<49$. Pozostałe przypadki tw.~4.1 można stosować, o~ile $a\le16$, ale wtedy $A'$ jest wolniejszy od $A$, zatem pomińmy ich sprawdzanie.

Największym całkowitym $a$, dla której algorytm $A'$ jest bardziej efektywny od algorytmu $A$, jest~$a=48$.

\exercise %4-3.3
Ponieważ $a=1$ oraz $b=2$, to $n^{\log_ba}=n^0=1$ jest funkcją stałą. W rekurencji tej $f(n)$ także jest stałe, a~więc $f(n)=\Theta(n^{\log_ba})$ i~$T(n)=\Theta(n^{\log_ba}\lg n)=\Theta(\lg n)$.

\exercise %4-3.4
Dla rekurencji $T(n)$ mamy $a=4$, $b=2$ oraz $f(n)=n^2\lg n$, a~więc $n^{\log_ba}=n^2$, ale nie istnieje takie $\epsilon>0$, że $f(n)=\Omega(n^{2+\epsilon})$. Nie można zatem zastosować w~rozwiązaniu twierdzenia o~rekurencji uniwersalnej, zatem znajdziemy asymptotyczne górne oszacowanie na $T(n)$ zgadując rozwiązanie, a~następnie dowodząc jego poprawności metodą podstawiania.

W~pierwszym wywołaniu, rekurencja wnosi koszt równy $n^2\lg n$. Następnie, 4~razy wywołujemy $T(n/2)$, co daje koszt
\[
	4T(n/2) = 4((n/2)^2\lg(n/2)) = n^2\lg n-n^2.
\]
Kolejne poziomy wywołań kosztują
\begin{gather*}
	16T(n/4) = 16((n/4)^2\lg(n/4)) = n^2\lg n-2n^2, \qquad\phantom{\text{itd.}} \\
	64T(n/8) = 64((n/8)^2\lg(n/8)) = n^2\lg n-3n^2, \qquad\text{itd.}
\end{gather*}

Wnioskujemy z~otrzymanych wyników, że \twoparts{$i$}{ty} poziom wprowadza koszt równy $n^2\lg n-in^2$. Ponieważ liście drzewa rekursji o~koszcie stałym znajdują się na poziomie $\lg n$, to dostajemy:
\begin{align*}
	T(n) &= \sum_{i=0}^{\lg n-1}(n^2\lg n-in^2)+\Theta(1) \\
	&= n^2\lg^2n-n^2\sum_{i=0}^{\lg n-1}i+\Theta(1) \\[1mm]
	&= n^2\lg^2n-\frac{n^2\lg n(\lg n-1)}{2}+\Theta(1) \\[1mm]
	&= O(n^2\lg^2n).
\end{align*}
Udowodnimy teraz metodą podstawiania, że otrzymane przypuszczenie jest istotnie oszacowaniem górnym dla $T(n)$. Przyjmijmy założenie
\[
	T(n/2) \le c(n/2)^2\lg^2(n/2),
\]
dla pewnej stałej $c>0$. Mamy teraz:
\begin{align*}
	T(n) &= 4T(n/2)+n^2\lg n \\
	&\le 4c(n/2)^2\lg^2(n/2)+n^2\lg n \\
	&= cn^2(\lg n-1)^2+n^2\lg n \\
	&= cn^2\lg^2n-2cn^2\lg n+cn^2+n^2\lg n \\
	&\le cn^2\lg^2n.
\end{align*}
Ostatnia nierówność jest prawdziwa, o~ile $c>1/2$ oraz $n>\sqrt{2}$. Przyjmujemy $T(1)=1$, zaś $T(2)=8$ za warunek brzegowy indukcji, ponieważ otrzymane oszacowanie w~tym przypadku jest spełnione. Rozwiązaniem rekurencji $T(n)$ jest zatem $O(n^2\lg^2n)$.

\exercise %4-3.5
Przyjmując $a=1$, $b=2$ oraz $f(n)=n(2-\cos n)$ dostajemy, że $f(n)=\Omega(n^\epsilon)$ dla pewnego $0<\epsilon<1$. Jednak dla $n=2\pi$, mamy
\[
    af(n/b) = 3\pi \quad\text{oraz}\quad f(n) = 2\pi,
\]
a więc nierówność $af(n/b)\le cf(n)$ z warunku regularności nie jest prawdziwa dla $0<c<1$.

\subchapter{Dowód twierdzenia o rekurencji uniwersalnej}

\exercise %4-4.1
Wykażemy metodą indukcji, że $n_j=\left\lceil n/b^j\right\rceil$. Z definicji~(4.12) bezpośrednio wynika prawdziwość tego wzoru dla $j=0$. Przyjmijmy zatem, że dla $j>0$ zachodzi $n_{j-1}=\left\lceil n/b^{j-1}\right\rceil$. Wykorzystując tożsamość~(3.4) otrzymujemy
\[
	n_j = \lceil n_{j-1}/b\rceil = \left\lceil\left\lceil n/b^{j-1}\right\rceil\!/b\right\rceil = \left\lceil n/b^j\right\rceil,
\]
co należało pokazać.

\exercise %4-4.2
Zastąpmy drugi przypadek tw.~4.1 ogólniejszym warunkiem, tzn.\ jeśli $f(n)=\Theta(n^{\log_ba}\lg^kn)$ dla $k\ge0$, to zachodzi $T(n)=\Theta(n^{\log_ba}\lg^{k+1}n)$. Dla tak zmodyfikowanego twierdzenia należy przeprowadzić dowód analogicznie zmodyfikowanych lematów~4.3 i~4.4 (oznaczonych poniżej przez 4.3$'$ oraz 4.4$'$).

\begin{proof}[Dowód lematu~4.3\/$'$]
	Przy założeniu, że $f(n)=\Theta(n^{\log_ba}\lg^kn)$ otrzymujemy
	\[
		f(n/b^j)=\Theta\bigl((n/b^j)^{\log_ba}\lg^k(n/b^j)\bigr)
	\]
	i podstawiamy do wzoru~(4.7):
	\[
		g(n) = \Theta\biggl(\sum_{j=0}^{\log_bn-1}a^j\left(\frac{n}{b^j}\right)^{\log_ba}\lg^k\frac{n}{b^j}\biggr).
	\]
	Mamy dalej:
	\begin{align*}
		\sum_{j=0}^{\log_bn-1}a^j\left(\frac{n}{b^j}\right)^{\log_ba}\lg^k\frac{n}{b^j} &= n^{\log_ba}\sum_{j=0}^{\log_bn-1}\left(\frac{a}{b^{\log_ba}}\right)^j\lg^k\frac{n}{b^j} \\
		&= n^{\log_ba}\sum_{j=0}^{\log_bn-1}(\lg n-j\lg b)^k \\
		&= n^{\log_ba}\cdot\Theta(\lg^{k+1}n) \\
		&= \Theta(n^{\log_ba}\lg^{k+1}n).
	\end{align*}
	Skorzystano z tego, że $(\lg n-j\lg b)^k=\Theta(\lg^kn)$ na podstawie \zad{3.1-2}, a~następnie zauważając, że
	\[
		\sum_{j=0}^{\log_bn-1}\Theta(\lg^kn) = \log_bn\cdot\Theta(\lg^kn) = \Theta(\lg^{k+1}n).
	\]
	Pokazano, że $g(n)=\Theta(n^{\log_ba}\lg^{k+1}n)$, a~więc lemat jest prawdziwy.
\end{proof}

\begin{proof}[Dowód lematu~4.4\/$'$]
	Wystarczy wykazać jedynie drugi przypadek, bo $f(n)=\Theta(n^{\log_ba}\lg^kn)$.
	\[
		T(n) = \Theta(n^{\log_ba})+\Theta(n^{\log_ba}\lg^{k+1}n) = \Theta(n^{\log_ba}\lg^{k+1}n),
	\]
	co kończy dowód i~jednocześnie pokazuje prawdziwość głównego twierdzenia.
\end{proof}

\exercise %4-4.3
Warunek $af(n/b)\le cf(n)$ implikuje
\[
	f(n) \ge (a/c)f(n/b),
\]
a~zatem iterując powyższe dostajemy
\[
	f(n) \ge (a/c)f(n/b) \ge (a/c)^2f\bigl(n/b^2\bigr) \ge \dots \ge (a/c)^if\bigl(n/b^i\bigr).
\]
Niech $i=\lceil\log_bn\rceil$, co daje
\[
	f(n) \ge (a/c)^{\lceil\log_bn\rceil}f\bigl(n/b^{\lceil\log_bn\rceil}\bigr).
\]
Na mocy nierówności~(3.3) zachodzi $\log_bn\le\lceil\log_b n\rceil<\log_bn+1$. Zauważmy, że przy zadanych ograniczeniach na $a$ i~$c$, $f$ nie może być funkcją nierosnącą, a~więc
\[
    f\bigl(n/b^{\lceil\log_bn\rceil}\bigr) > f(n/b^{\log_bn+1}) = f(1/b).
\]
Mamy następnie
\[
	f(n) > \frac{a^{\log_bn}}{c^{\log_bn+1}}f(n/b^{\log_bn+1}) = \frac{n^{\log_ba}}{cn^{\log_bc}}f(1/b) = \frac{f(1/b)}{c}\cdot\frac{n^{\log_ba}}{n^{\log_bc}}.
\]
Ponieważ $0<c<1$ oraz $b>1$, to $\log_bc<0$, przyjmijmy więc $\epsilon=-\log_bc$, skąd
\[
	f(n) > \frac{f(1/b)}{c}\cdot\frac{n^{\log_ba}}{n^{-\epsilon}} = \frac{f(1/b)}{c}\cdot n^{\log_ba+\epsilon},
\]
a~zatem $f(n)=\Omega(n^{\log_ba+\epsilon})$, co należało wykazać.

\problems

\problem{Przykłady rekurencji} %4-1
W punktach (a)\nobreakdash--(f) skorzystano z twierdzenia o rekurencji uniwersalnej.

\subproblem %4-1(a)
\[
	n^{\log_ba} = n^{\log_22} = n \quad\text{oraz}\quad f(n) = n^3 = \Omega(n^{1+\epsilon}) \quad\text{dla $0<\epsilon\le2$}
\]
Ponieważ warunek regularności jest spełniony:
\begin{align*}
	2f(n/2) &\le cf(n) \\
	2n^3\!/8 &\le cn^3 \\
	c &\ge 1/4,
\end{align*}
to stąd wnioskujemy, że $T(n)=\Theta(n^3)$.

\subproblem %4-1(b)
\[
	n^{\log_ba} = n^{\log_{10/9}1} = 1 \quad\text{oraz}\quad f(n) = n = \Omega(n^\epsilon) \quad\text{dla $0<\epsilon\le1$}
\]
Badamy warunek regularności:
\begin{align*}
	f(9n/10) &\le cf(n) \\
	9n/10 &\le cn \\
	c &\ge 9/10
\end{align*}
i~stwierdzamy, że $T(n)=\Theta(n)$.

\subproblem %4-1(c)
\[
	n^{\log_ba} = n^{\log_416} = n^2 \quad\text{oraz}\quad f(n) = n^2 = \Theta(n^2),
\]
a~stąd $T(n)=\Theta(n^2\lg n)$.

\subproblem %4-1(d)
\[
	n^{\log_ba} = n^{\log_37} \quad\text{oraz}\quad f(n) = n^2 = \Omega(n^{\log_37+\epsilon}) \quad\text{dla $0<\epsilon\le2-\log_37$}
\]
Warunek regularności zachodzi:
\begin{align*}
	7f(n/3) &\le cf(n) \\
	7n^2\!/9 &\le cn^2 \\
	c &\ge 7/9,
\end{align*}
a~zatem $T(n)=\Theta(n^2)$.

\subproblem %4-1(e)
\[
	n^{\log_ba} = n^{\lg7} \quad\text{oraz}\quad f(n) = n^2 = O(n^{\lg7-\epsilon}) \quad\text{dla $0<\epsilon\le\lg7-2$},
\]
a~stąd $T(n)=\Theta(n^{\lg7})$.

\subproblem %4-1(f)
\[
	n^{\log_ba} = n^{\log_42} = n^{1/2} \quad\text{oraz}\quad f(n) = \sqrt{n} = \Theta(n^{1/2}),
\]
a~stąd $T(n)=\Theta\bigl(\!\sqrt{n}\lg n\bigr)$.

\subproblem %4-1(g)
Zauważmy, że rekurencja rozwija się następująco:
\begin{align*}
	T(n) &= T(n-1)+n \\
	&= T(n-2)+(n-1)+n \\
	&\hspace{.5in}\vdots \\
	&= c+3+4+\cdots+n \\
	&= c+\sum_{i=3}^ni = c+\frac{n(n+1)}{2}-3,
\end{align*}
gdyż $T(2)$ jest pewną stałą $c$, a~stąd otrzymujemy, że $T(n)=\Theta(n^2)$.

\subproblem %4-1(h)
Niech $n=2^m$, skąd $m=\lg n$. Rekurencja przyjmuje teraz postać
\[
	T(2^m) = T(2^{m/2})+1.
\]
Podstawiając $S(m)$ za $T(2^m)$, otrzymujemy
\[
	S(m) = S(m/2)+1.
\]
Ponieważ rozwiązaniem ostatniej rekurencji jest $\Theta(\lg m)$ (co wykazano w~\zad{4.3-3}), to stąd mamy, że $T(n)=T(2^m)=S(m)=\Theta(\lg m)=\Theta(\lg\lg n)$.

\problem{Szukanie brakującej liczby całkowitej} %4-2
Liczby z~zakresu $0\twodots n$ reprezentowane są binarnie za pomocą $\lfloor\lg n\rfloor+1$ bitów. Można dla wygody przyjąć, że $n$ jest potęgą~2 pomniejszoną o~1. W przeciwnym przypadku wystarczy zwiększyć $n$, aby było o~1 mniejsze od najbliższej większej potęgi~2. Jednocześnie rozszerzamy tablicę $A$, umieszczając w~niej nowe liczby naturalne aż do nowej wartości $n$. Ta modyfikacja sprawi, że wszystkie liczby w $A$ będą reprezentowane tą samą ilością bitów, a~rozmiar problemu urośnie co najwyżej dwukrotnie.

Badając najmniej znaczące bity liczb z tablicy $A$, sprawdzamy ich parzystość. W~zakresie $0\twodots n$ jest $n/2$ liczb parzystych i~tyle samo nieparzystych. Jeśli wśród pobranych bitów jest więcej jedynek, to brakuje liczby parzystej, a~jeśli więcej zer, to brakująca liczba jest nieparzysta. W~zależności od przypadku, odrzucamy $n/2$ liczb o~parzystości różnej od brakującej. Wsród pozostałych badamy następnie drugi najmniej znaczący bit i~analogicznie postępując wyznaczamy $n/4$ kolejnych liczb do wyeliminowania. Powtarzając opisane czynności aż do odrzucenia wszystkich liczb z~tablicy, poznamy tę, której brakuje.

Czas działania zaprezentowanego tutaj algorytmu można zapisać w~postaci rekurencji $T(n)=T(n/2)+n$, której rozwiązaniem jest $O(n)$, co można łatwo pokazać przy użyciu twierdzenia~4.1. Widać teraz, że modyfikacja oryginalnego problemu (z~dowolnym $n$) wprowadziła tylko stały czynnik do czasu działania algorytmu.

\problem{Koszty przekazywania parametrów} %4-3

\subproblem %4-3(a)
Dla pierwszej strategii, rekurencja przyjmuje postać z~\zad{2.3-5}, której rozwiązaniem jest $T(n)=\Theta(\lg n)$. Po przyjęciu $n=N$ dostajemy $T(N)=\Theta(\lg N)$.

W przypadku drugiej strategii, na każdym poziomie rekursji należy dodać składnik $\Theta(N)$ odpowiedzialny za przekazywanie tablicy do wywołań rekurencyjnych. Otrzymujemy zatem
\[
	T(n) = \begin{cases}
		\Theta(1), & \text{jeśli $n\le1$}, \\
		T(\lfloor n/2\rfloor)+\Theta(N), & \text{jeśli $n>1$}.
	\end{cases}
\]
Ponieważ $\Theta(N)$ jest stałe ze względu na rozmiar podproblemu $n$, to stąd rozwiązaniem powyższej rekurencji jest $T(n)=\Theta(N\lg n)$, a więc $T(N)=\Theta(N\lg N)$.

W ostatnim przypadku przekazujemy podtablicę o rozmiarze równym rozmiarowi podproblemu, co prowadzi do następującej rekurencji:
\[
    T(n) = \begin{cases}
		\Theta(1), & \text{jeśli $n\le1$}, \\
		T(\lfloor n/2\rfloor)+\Theta(\lfloor n/2\rfloor), & \text{jeśli $n>1$},
	\end{cases}
\]
którą można rozwiązać przy użyciu twierdzenia o rekurencji uniwersalnej. Otrzymujemy wynik $T(n)=\Theta(n)$, a stąd $T(N)=\Theta(N)$.

\subproblem %4-3(b)
W przypadku zwykłego przekazywania wskaźnika mamy starą postać rekurencji, której rozwiązaniem dla $n=N$ jest $T(N)=\Theta(N\lg N)$.

Rekurencja dla drugiej strategii przedstawia się następująco:
\[
    T(n) = \begin{cases}
		\Theta(1), & \text{jeśli $n=1$}, \\
		2T(\lfloor n/2\rfloor)+\Theta(n)+2\Theta(N), & \text{jeśli $n>1$},
	\end{cases}
\]
ponieważ należy przekazać całą tablicę do obu wywołań rekurencyjnych. Ponieważ na każdym poziomie dodajemy składnik rzędu $\Theta(N)$, to rozwiązaniem tej rekurencji jest iloczyn tego składnika i rozwiązania rekurencji z pierwszego przypadku, czyli $T(n)=\Theta(Nn\lg n)$, a stąd mamy $T(N)=\Theta(N^2\lg N)$.

Ostatni przypadek wprowadza narzut w postaci przekazywania podtablicy o rozmiarze podproblemu do każdego wywołania rekurencyjnego, jednak czas ten jest pochłaniany przez składnik liniowy odpowiadający za czas przeznaczony na procedurę \proc{Merge}, przez co rozwiązaniem jest identyczny wynik jak w pierwszej strategii, $T(N)=\Theta(N\lg N)$.

\problem{Więcej przykładów rekurencji} %4-4

\subproblem %4-4(a)
Wykorzystując twierdzenie o rekurencji uniwersalnej, mamy
\[
	n^{\log_ba} = n^{\lg3} \quad\text{oraz}\quad f(n) = n\lg n = O(n^{\lg3-\epsilon}), \quad\text{dla $0<\epsilon<\lg3-1$,}
\]
a stąd $T(n)=\Theta(n^{\lg3})$.

\subproblem %4-4(b)
Z twierdzenia o rekurencji uniwersalnej obliczamy
\[
	n^{\log_ba} = n^{\log_55} = n,
\]
jednak dla żadnego $\epsilon>0$ nie jest prawdą, że
\[
	f(n) = \frac{n}{\lg n} = O(n^{1-\epsilon}),
\]
ponieważ dla pewnej stałej $c>0$ i dowolnie dużych $n$ musiałoby zachodzić
\[
	\frac{n^\epsilon}{\lg n} \le c,
\]
a ponieważ $n^\epsilon=\omega(\lg n)$, to niezależnie od wyboru $\epsilon$, dla dużych wartości $n$ licznik będzie dowolnie większy od mianownika i ułamka nie da się z tego powodu ograniczyć stałą.

Skorzystajmy zatem z innego sposobu na obliczenie $T(n)$, rozważając ogólną rekurencję
\[
	T_a(n) = \begin{cases}
		\Theta(1), & \text{jeśli $1\le n<a$}, \\
		aT_a(n/a)+n/\!\lg n, & \text{jeśli $n\ge a$},
	\end{cases}
\]
dla pewnego całkowitego $a\ge2$, której drzewo przedstawia rys.~\ref{fig:4-4b}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.5}
	\end{center}
	\caption{Drzewo rekursji $T_a(n)=aT_a(n/a)+n/\!\lg n$} \label{fig:4-4b}
\end{figure}
Na \twoparts{$i$}{tym} poziomie tego drzewa $a^i$ węzłów wnosi koszt równy $n/(a^i\lg(n/a^i))$, a cały poziom $n/(\lg n-i\lg a)$. Ponieważ drzewo to posiada $\log_an+1$ poziomów, to kosztem ostatniego poziomu jest $\Theta(a^{\log_an})=\Theta(n)$, skąd dostajemy
\begin{align*}
	T_a(n) &= \sum_{i=0}^{\log_an-1}\frac{n}{\lg n-i\lg a}+\Theta(n) \\
	&= \frac{n}{\lg a}\sum_{i=0}^{\log_an-1}\frac{1}{\log_an-i}+\Theta(n) \\
	&= \frac{n}{\lg a}\sum_{i=1}^{\log_an}\frac{1}{i}+\Theta(n) \\
	&= \frac{nH_{\log_an}}{\lg a}+\Theta(n) \\
	&= \Theta(n\lg\lg n),
\end{align*}
przy czym ostatnia równość wynika z wzoru~(A.7).

Wykażemy teraz otrzymane oszacowanie przy pomocy metody podstawiania. Jednak przyjęcie narzucającego się oszacowania przysparza wielu kłopotów w samym dowodzie w postaci skomplikowanych przekształceń algebraicznych. Zamiast tego wykażemy, że $T_a(n)\le n(1+H_{\lfloor\log_an\rfloor})$ oraz $T_a(n)\ge nH_{\lceil\log_an\rceil}$, przy czym dla uproszczenia dowodu definiujemy dodatkowo $H_0=0$. Ponieważ $H_k=\Theta(\lg k)$, to zachodzi $H_{\lfloor\log_an\rfloor}=\Theta(\lg\lfloor\log_an\rfloor)=\Theta(\lg\lg n)$ oraz $H_{\lceil\log_an\rceil}=\Theta(\lg\lceil\log_an\rceil)=\Theta(\lg\lg n)$, a więc nasz dowód rzeczywiście wykaże, że $T_a(n)=\Theta(n\lg\lg n)$.
\begin{align*}
	T_a(n) &= aT_a(n/a)+\frac{n}{\lg n} \\
	&\le a(n/a)(1+H_{\lfloor\log_a(n/a)\rfloor})+\frac{n\log_a2}{\log_an} \\
	&\le n(1+H_{\lfloor\log_an-1\rfloor})+\frac{n}{\log_an} \\
	&= n\left(1+H_{\lfloor\log_an\rfloor-1}+\frac{1}{\log_an}\right) \\
	&\le n\left(1+H_{\lfloor\log_an\rfloor-1}+\frac{1}{\lfloor\log_an\rfloor}\right) \\
	&= n(1+H_{\lfloor\log_an\rfloor})
\end{align*}
W dowodzie dolnego oszacowania, mamy
\begin{align*}
	T_a(n) &= aT_a(n/a)+\frac{n}{\lg n} \\
	&\ge a(n/a)H_{\lceil\log_a(n/a)\rceil}+\frac{n\log_a2}{\log_an} \\
	&\ge nH_{\lceil\log_an-1\rceil}+\frac{n}{\log_an} \\
	&= n\left(H_{\lceil\log_an\rceil-1}+\frac{1}{\log_an}\right) \\
	&\ge n\left(H_{\lceil\log_an\rceil-1}+\frac{1}{\lceil\log_an\rceil}\right) \\
	&= nH_{\lceil\log_an\rceil}.
\end{align*}

Za podstawę indukcji możemy przyjąć warunek brzegowy rekurencji $T_a(1)=1$, gdyż wtedy $\log_a1=0$ i zachodzą $T_a(1)\le 1+H_0$ oraz $T_a(1)\ge H_0$, skąd $T_a(n)=\Theta(n\lg\lg n)$.

% Dla górnego oszacowania przyjmijmy założenie
% \[
% 	T_a(n/a) \le c_1(n/a)\lg\lg(n/a).
% \]
% Mamy zatem
% \begin{align*}
% 	T_a(n) &= aT_a(n/a)+\frac{n}{\lg n} \\
% 	&\le ac_1(n/a)\lg\lg(n/a)+\frac{n}{\lg n} \\
% 	&= c_1n\lg\lg n+c_1n\lg\frac{\lg(n/a)}{\lg n}+\frac{n}{\lg n} \\
% 	&\le c_1n\lg\lg n,
% \end{align*}
% gdzie ostatnia nierówność zachodzi, o ile
% \[
% 	c_1n\lg\frac{\lg(n/a)}{\lg n}+\frac{n}{\lg n} \le 0,
% \]
% skąd
% \[
% 	c_1 \ge -\frac{1}{\lg n\lg(1-\log_na)} > 0, %zle
% \]
% dla każdego $n>a$, a więc $T_a(n)=O(n\lg\lg n)$.
% 
% W dowodzie dolnego oszacowania skorzystajmy z
% \[
% 	T_a(n/a) \ge c_2(n/a)\lg\lg(n/a)-b\lg(n/a),
% \]
% i po podstawieniu, mamy
% \begin{align*}
% 	T_a(n) &= aT_a(n/a)+\frac{n}{\lg n} \\
% 	&\ge c_2(n/a)\lg\lg(n/a)-ab\lg(n/a)+\frac{n}{\lg n} \\
% 	&\ge c_2n\lg\lg n+c_2n\lg\frac{\lg(n/a)}{\lg n}-ab\lg n+ab\lg a+\frac{n}{\lg n} \\
% 	&\ge c_2n\lg\lg n-b\lg n,
% \end{align*}
% co jest prawdą dla
% \[
% 	c_2n\lg\frac{\lg(n/a)}{\lg n}-(a-1)b\lg n+ab\lg a+\frac{n}{\lg n} \ge 0,
% \]
% czyli
% \[
% 	c_2 \le \frac{(a-1)b\lg n-ab\lg a-\frac{n}{\lg n}}{n\lg(1-\log_na)}, %wtf
% \]
% skąd mamy, że $T_a(n)=\Omega(n\lg\lg n)$ i oszacowanie dokładne na $T_a(n)$ zostało ostatecznie wykazane.

Stosując wykazane oszacowanie do rekurencji $T(n)\equiv T_5(n)$ z treści zadania, dostajemy oczywiście $T(n)=\Theta(n\lg\lg n)$.

\subproblem %4-4(c)
Z twierdzenia o rekurencji uniwersalnej,
\[
	n^{\log_ba} = n^{\lg4} = n^2 \quad\text{oraz}\quad f(n) = n^{5/2} = \Omega(n^{2+\epsilon}), \quad\text{dla $0<\epsilon\le1/2$,}
\]
Badamy warunek regularności:
\begin{align*}
	4f(n/2) &\le cf(n) \\
	\frac{4n^{5/2}}{2^{5/2}} &\le cn^{5/2} \\
	c &\ge \frac{1}{\sqrt{2}}
\end{align*}
i stwierdzamy, że $T(n)=\Theta(n^{5/2})$.

\subproblem %4-4(d)
Wykażemy, że stała~5 w argumencie $T$ nie wpływa na postać rozwiązania -- rozważając rekurencję $T'(n)=3T'(n/3)+n/2$ i~rozwiązując ją za pomocą twierdzenia o~rekurencji uniwersalnej, dostajemy $T'(n)=\Theta(n\lg n)$. Udowodnimy teraz metodą podstawiania, że identyczny wynik jest rozwiązaniem rekurencji $T(n)$.

Wykorzystując założenie
\[
	T(n/3+5) \le c(n/3+5)\lg(n/3+5)
\]
dla pewnej stałej $c>0$, otrzymujemy:
\begin{align*}
	T(n) &\le 3c(n/3+5)\lg(n/3+5)+n/2 \\
	&\le (cn+15c)\lg(n/3+n/3)+n/2 \\
	&< cn\lg n+cn\lg(2/3)+15c\lg n+n/2 \\
	&\le cn\lg n
\end{align*}
co zachodzi, o~ile $n/3\ge5$, skąd $n\ge15$ oraz
\[
    cn\lg(2/3)+15c\lg n+n/2 \le 0.
\]
Przeprowadzając podobną analizę jak w~\zad{4.1-5} dostajemy, że $c\ge227$ dla najmniejszego $n_0=196$ przy oznaczeniach z~tego zadania.

Analogicznie dla dolnego oszacowania, przyjmując, że
\[
	T(n/3+5) \ge d(n/3+5)\lg(n/3+5),
\]
gdzie $d>0$ jest pewną stałą, dostajemy
\begin{align*}
	T(n) &\ge 3d(n/3+5)\lg(n/3+5)+n/2 \\
	&> 3d(n/3)\lg(n/3+5)+n/2 \\
	&\ge dn\lg n+dn\lg\frac{n/3+5}{n}+n/2 \\
	&\ge dn\lg n,
\end{align*}
gdzie ostatnia nierówność zachodzi, o~ile
\[
    dn\lg\frac{n/3+5}{n}+n/2 \ge 0,
\]
co dla $n\ge196$ spełniamy poprzez przyjęcie $d\le0{,}3$.

Dowód asymptotycznie dokładnego oszacowania dla $T(n)$ kończymy, badając zachowanie rekurencji dla przypadku bazowego indukcji. Zauważmy, że obliczanie wartości z~wzoru $T(n)=3T(n/3+5)+n/2$ dla $n\le7$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n\le7$. Dowody oszacowań zakładały $n\ge196$, więc $T(196)=2583{,}5$ można przyjąć za podstawę indukcji po zauważeniu, że oszacowania przy wyznaczonych stałych $c$ i~$d$ są spełnione. A~zatem $T(n)=\Theta(n\lg n)$.

\subproblem %4-4(e)
Mamy do czynienia z rekurencją $T_a(n)$ dla $a=2$, którą rozważaliśmy w punkcie~(b). Zgodnie z przedstawionym tam rozumowaniem wnioskujemy, że $T(n)=\Theta(n\lg\lg n)$.

\subproblem %4-4(f)
W celu rozwiązania rekurencji wykorzystamy metodę drzewa rekursji. Drzewo to zostało przedstawione na rys.~\ref{fig:4-4f}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.6}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n/2)+T(n/4)+T(n/8)+n$} \label{fig:4-4f}
\end{figure}

Zauważmy, że najszybciej maleją argumenty na skrajnie prawej gałęzi. Koszt jej węzła na \twoparts{$i$}{tym} poziomie wynosi $n/8^i$. Dla pewnego $h$ i pewnej stałej $c>0$ zachodzi $n/8^h=c$, skąd $h=\log_8(n/c)$ i na tym poziomie gałąź ta posiada liścia. Sumując koszty poziomów drzewa od korzenia aż do \twoparts{$h$}{tego} poziomu, uzyskujemy dolne oszacowanie rekurencji:
\begin{align*}
	T(n) &\ge \sum_{i=0}^{\log_8(n/c)-1}\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&= \frac{1-\left(\frac{7}{8}\right)^{\log_8(n/c)}}{1-\frac{7}{8}}n+\Theta(1) \\
	&= 8n\left(1-\left(\frac{n}{c}\right)^{\log_8(7/8)}\right)+\Theta(1).
\end{align*}
Ponieważ dla $c\le1$, mamy
\[
    (n/c)^{\log_8(7/8)} \le n^{\log_8(7/8)} \le 7/8,
\]
to stąd
\[
    T(n) \ge 8n\left(1-\frac{7}{8}\right)+\Theta(1) = n+\Theta(1),
\]
otrzymujemy zatem, że $T(n)=\Omega(n)$.

Zbadajmy teraz górne oszacowanie rekurencji $T(n)$ poprzez dokonanie obserwacji, że najwolniej malejącymi węzłami drzewa są węzły ze skrajnie lewej gałęzi, które wnoszą koszt równy $n/2^i$ na \twoparts{$i$}{tym} poziomie, więc liść znajduje się na poziomie $H=\lg(n/d)$ dla pewnej stałej $d>0$.
\begin{align*}
	T(n) &\le \sum_{i=0}^{\lg(n/d)-1}\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&< \sum_{i=0}^\infty\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&= \frac{n}{1-\frac{7}{8}}+\Theta(1) \\
	&= 8n+\Theta(1),
\end{align*}
skąd mamy, że $T(n)=O(n)$. Asymptotycznym dokładnym oszacowaniem rekurencji jest zatem $\Theta(n)$.

\subproblem %4-4(g)
Rozwijając rekurencję, przy założeniu, że $T(1)=1$, otrzymujemy
\[
	T(n) = \frac{1}{n}+\frac{1}{n-1}+\cdots+\frac{1}{2}+\frac{1}{1} = H_n,
\]
i~korzystając z~\zad{A.2-3} mamy, że $T(n)=\Theta(\lg n)$.

\subproblem %4-4(h)
Przy założeniu, że $T(1)=0$, zachodzi
\[
	T(n) = \lg n+\lg(n-1)+\cdots+\lg2+\lg 1 = \lg\biggl(\prod_{i=1}^ni\biggr) = \lg(n!),
\]
to z~wzoru~(3.18) dostajemy $T(n)=\Theta(n\lg n)$.

\subproblem %4-4(i)
Przyjmijmy $T(2)=2$ i~rozważmy przypadek, gdy $n$ jest parzyste. Rozwijamy rekurencję, otrzymując
\begin{align*}
	T(n) &= 2\lg n+2\lg(n-2)+\cdots+2\lg4+2 \\
	&= 2\lg\biggl(\prod_{i=1}^{n/2}2i\biggr) \\
	&= 2\lg\bigl(2^{n/2}(n/2)!\bigr) \\
	&= 2\bigl(\lg 2^{n/2}+\lg((n/2)!)\bigr).
\end{align*}
Wykorzystując wzór~(3.18) dostajemy
\[
	T(n) = n+2\Theta((n/2)\lg (n/2)) = \Theta(n\lg n).
\]

Dla $n$ nieparzystego po przyjęciu $T(1)=0$, rekurencja sprowadza się do sumy
\[
    T(n) = 2\lg n+2\lg(n-2)+\cdots+2\lg3+0 = 2\lg\biggl(\prod_{i=1}^{(n-1)/2}(2i-1)\biggr),
\]
którą można ograniczyć od góry przez $2\lg\Bigl(\prod_{i=1}^{n/2}2i\Bigr)$, a~z~dołu przez $2\lg\Bigl(\prod_{i=1}^{(n-1)/2-1}2i\Bigr)$. Obie wartości można z~wzoru~(3.18) sprowadzić do postaci $\Theta(n\lg n)$, a~zatem również w~przypadku nieparzystego argumentu, $T(n)$ jest klasy $\Theta(n\lg n)$.

\subproblem %4-4(j)
Na \twoparts{$i$}{tym} poziomie drzewa rekursji $T(n)$ przedstawionego na rys.~\ref{fig:4-4j} znajduje się $n^{1-1/2^i}$ węzłów o~koszcie $n^{1/2^i}$ każdy, cały poziom wnosi zatem koszt równy $n$. Należy jeszcze zbadać, dla jakiego $i$ koszt każdego węzła na \twoparts{$i$}{tym} poziomie jest stałą:
\[
	n^{1/2^i} = d, \quad\text{skąd}\quad i = \lg\log_dn,
\]
przy czym musi być $d\le\sqrt{n}$. Jest zatem w~drzewie $\Theta(\lg\lg n)$ poziomów, skąd dostajemy, że rozwiązaniem rekurencji jest $T(n)=\Theta(n\lg\lg n)$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.7}
	\caption{Drzewo rekursji $T(n)=\sqrt{n}\;T(\!\sqrt{n})+n$} \label{fig:4-4j}
	\end{center}
\end{figure}

Udowodnimy teraz otrzymane oszacowanie wykorzystując do tego celu metodę podstawiania. Dla pewnej stałej $c>0$ przyjmijmy
\[
    T(\!\sqrt{n}) \le c\sqrt{n}\lg\lg\sqrt{n}.
\]
Mamy teraz
\begin{align*}
    T(n) &= \sqrt{n}\;T(\!\sqrt{n})+n \le \sqrt{n}\left(c\sqrt{n}\lg\lg\sqrt{n}\right)+n = cn\lg\frac{\lg n}{2}+n \\[1mm]
	&= cn(\lg\lg n-\lg2)+n = cn\lg\lg n+n-cn \le cn\lg\lg n.
\end{align*}
Ostatnia nierówność zachodzi, jeśli przyjmiemy $c\ge1$. Aby uzasadnić oszacowanie dolne, postępujemy analogicznie jak w~powyższym wyprowadzeniu, ale zmieniając znak nierówności na przeciwny. W~tym przypadku jednak musi być $c\le1$.

Ostatnim etapem dowodu jest znalezienie przypadku bazowego indukcji. Wartości $T(1)=1$ oraz $T(2)=2+\sqrt{2}$ nie spełniają powyższych nierówności, ale dla $T(3)=3+\sqrt{3}$, oba oszacowania są prawdziwe po przyjęciu odpowiednio $c_1\ge3$ dla górnego i~$0<c_2\le2$ dla dolnego oszacowania. Ostatecznie, rozwiązanie rekurencji zostało uzasadnione i~wynosi $\Theta(n\lg\lg n)$.

\problem{Liczby Fibonacciego} %4-5

\subproblem %4-5(a)
Wprost z~definicji $\mathcal{F}(z)$ mamy:
\begin{align*}
	\mathcal{F}(z) &= \sum_{i=0}^\infty F_iz^i \\
	&= F_0+zF_1+\sum_{i=2}^\infty (F_{i-1}+F_{i-2})z^i \\
	&= z+\sum_{i=2}^\infty F_{i-1}z^i+\sum_{i=2}^\infty F_{i-2}z^i \\
	&= z+\sum_{i=1}^\infty F_iz^{i+1}+\sum_{i=0}^\infty F_iz^{i+2} \\[2mm]
	&= z+z\mathcal{F}(z)+z^2\mathcal{F}(z),
\end{align*}
a~zatem tożsamość zachodzi.

\subproblem %4-5(b)
Z~wzoru z~poprzedniego punktu wynika pierwsza równość:
\begin{align}
	\mathcal{F}(z) &= z+z\mathcal{F}(z)+z^2\mathcal{F}(z) \nonumber \\
	(1-z-z^2)\mathcal{F}(z) &= z \nonumber \\
	\mathcal{F}(z) &= \frac{z}{1-z-z^2}. \label{eq:4-5b_1}
\end{align}
Mianownik prawej strony~(\ref{eq:4-5b_1}) jest trójmianem kwadratowym, który można zapisać w~równoważnej postaci:
\begin{equation}
	1-z-z^2 \equiv -(z+\phi)\bigl(z+\widehat\phi\bigr). \label{eq:4-5b_2}
\end{equation}
Trójmian~(\ref{eq:4-5b_2}) przyjmuje wartość~0 dla $z=-\phi$ lub $z=-\widehat\phi$. Ponieważ zachodzi ciekawa własność $\phi\cdot\widehat\phi=-1$, zatem można zapisać trójmian w~postaci $(1-\phi z)\bigl(1-\widehat\phi z\bigr)$, skąd wynika druga równość.

Ostatnią z~nich dowodzimy dokonując pewnych przekształceń:
\[
	\frac{1}{1-\phi z}-\frac{1}{1-\widehat\phi z} = \frac{1-\widehat\phi z-1+\phi z}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{z\bigl(\phi-\widehat\phi\bigr)}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{z\sqrt{5}}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)}
\]
i~zauważając, że zachodzi
\[
	\frac{z}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{1}{\sqrt{5}}\cdot\frac{z\sqrt{5}}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{1}{\sqrt{5}}\left(\frac{1}{1-\phi z}-\frac{1}{1-\widehat\phi z}\right).
\]

\subproblem %4-5(c)
Tezę otrzymujemy natychmiast, jeśli w~definicji $\mathcal{F}(z)$ podstawimy $F_i=\bigl(\phi^i-\widehat\phi^i\bigr)/\sqrt{5}$, co wykazano w~\zad{3.2-6}.

\subproblem %4-5(d)
Ponieważ $\bigl|\widehat\phi\bigr|<1$, to prawdą jest, że $\bigl|\widehat\phi^i\bigr|<1$ dla $i>0$ oraz $\bigl|\widehat\phi^i\bigr|/\sqrt{5}<1/\sqrt{5}<1/2$. Stąd
\[
	\frac{\phi^i}{\sqrt{5}}-1/2 < F_i = \frac{\phi^i-\widehat\phi^i}{\sqrt{5}} = \frac{\phi^i}{\sqrt{5}}-\frac{\widehat\phi^i}{\sqrt{5}} < \frac{\phi^i}{\sqrt{5}}+1/2,
\]
a~zatem $F_i$ jest równe liczbie całkowitej najbliższej $\phi^i/\sqrt{5}$.

\subproblem %4-5(e)
Tożsamość została udowodniona w~\zad{3.2-7}.

\problem{Testowanie układów VLSI} %4-6

\subproblem %4-6(a)
Załóżmy, że w~zbiorze układów jest więcej niż $n/2$ dobrych układów i~potraktujmy wynik każdego testu dwóch układów jako parę $(r_1,r_2)\in\{{\scriptstyle\rm D},{\scriptstyle\rm Z}\}^2$. Pierwszy element pary jest stwierdzeniem pierwszego układu o drugim, a~drugi element -- drugiego o~pierwszym, przy czym ${\scriptstyle\rm D}$ oznacza pozytywny wynik testu, a~${\scriptstyle\rm Z}$ -- negatywny. Możliwe jest uzyskanie jednego z~czterech wyników:
\begin{itemize}
	\item $({\scriptstyle\rm D},{\scriptstyle\rm D})$ -- implikuje, że oba układy są dobre albo oba są złe,
	\item $({\scriptstyle\rm D},{\scriptstyle\rm Z})$ -- zachodzi tylko wtedy, gdy pierwszy z~układów jest zły,
	\item $({\scriptstyle\rm Z},{\scriptstyle\rm D})$ -- zachodzi tylko wtedy, gdy drugi z~układów jest zły,
	\item $({\scriptstyle\rm Z},{\scriptstyle\rm Z})$ -- co najmniej jeden z~układów jest zły.
\end{itemize}
Ponieważ drugi i~trzeci wynik natychmiast determinują nam naturę jednego układu, to załóżmy, że podczas testowania nie uzyskaliśmy żadnego z~nich, możemy bowiem odrzucić wyznaczone złe układy z~dalszej analizy.

Rozpatrzmy graf $G=(V,E)$, w~którym $V$ jest zbiorem układów, a~$(u,v)\in E$ wtedy i~tylko wtedy, gdy podczas testowania układów $u$ i~$v$ otrzymano wynik $({\scriptstyle\rm D},{\scriptstyle\rm D})$. Oznacza to, że każde sąsiednie wierzchołki w~tym grafie muszą być albo jednocześnie dobre, albo jednocześnie złe. Zauważmy, że jeśli relacja $R$, której reprezentacją jest graf $G$ nie jest przechodnia, to możemy wtedy wskazać pewne złe układy -- co najmniej jeden z~wierzchołków nie będących w~relacji jest zły, a~to z~kolei indukuje kolejne złe, które są z~nim w~relacji. Niech zatem $R$ będzie przechodnia. Jest też oczywiście zwrotna i~symetryczna, a~jako taka dzieli zbiór $V$ na klasy abstrakcji. To prowadzi do badania grafów będących sumami podgrafów pełnych (klik), jako że każda klasa abstrakcji relacji $R$ tworzy pewną klikę. Każdy z~układów dowolnej kliki jest jednocześnie dobry lub jednocześnie zły z~każdym innym układem ze swojej kliki, podczas gdy między klikami nie istnieje żadna krawędź, więc co najmniej jedna z dwóch badanych klik musi zawierać wyłącznie złe układy.

Zauważmy, że możemy traktować $G$ jako hipergraf pełny $H=(V_H,E_H)$, gdzie $V_H$ jest zbiorem klik. Ponieważ dla każdej pary $(U,V)\in V_H^2$ co najmniej jedna z~klik $U$ lub $V$ zawiera złe elementy, to złymi są elementy należące do klik z~$V_H$ z wyjątkiem jednej. Układy z~tej kliki są dobre, co gwarantuje nam założenie, że zawsze będzie istnieć w~$V_H$ taka klika, która zawiera więcej niż $n/2$ układów. Pozostawiając ją jako dobrą, a oznaczając inne jako złe, będziemy mieć wyznaczone jednoznacznie wszystkie dobre układy spośród $n$ badanych. Istnienie większej ilości złych układów nie pozwoliłoby na wyznaczenie ``największego'' elementu z~$V_H$.

\subproblem %4-6(b)
Utwórzmy ciąg układów $u_1,u_2,\dots,u_n$ i wykonajmy $\lfloor n/2\rfloor$ testów -- między układami $u_1$ i $u_2$, $u_2$ i $u_3$, itd.\ aż do $u_{\lfloor n/2\rfloor}$ i $u_{\lfloor n/2\rfloor+1}$. Pozostałe układy pozostaną nieprzetestowane w danym etapie. Tak jak w poprzednim punkcie zakładamy, że nie możemy dostać wyniku $({\scriptstyle\rm D},{\scriptstyle\rm Z})$ lub $({\scriptstyle\rm Z},{\scriptstyle\rm D})$.

Rozważmy ciągi układów, dla których zaszło $({\scriptstyle\rm D},{\scriptstyle\rm D})$ między każdą parą sąsiadów. 

\subproblem %4-6(c)
Wykorzystując wynik poprzedniego punktu, dostajemy następującą rekurencję opisującą liczbę testów koniecznych do znalezienia jednego dobrego układu:
\[
	T(n) =
	\begin{cases}
		\Theta(1), & \text{jeśli $n=1$}, \\
		T(\lfloor n/2\rfloor) + \lfloor n/2\rfloor, & \text{jeśli $n>1$}.
	\end{cases}
\]
Ignorując podłogi i~stosując twierdzenie o~rekurencji uniwersalnej, dostajemy jej rozwiązanie: $T(n)=\Theta(n)$.

Ponieważ w~poprzednim punkcie znaleźliśmy dobry układ $u$, to wykorzystajmy go do znalezienia kolejnych. Testujemy tenże układ z~pozostałymi $n-1$. Wynikiem testu $u$ z~pewnym innym układem $v$, nie może być $({\scriptstyle\rm D},{\scriptstyle\rm Z})$, a~więc możliwe są trzy sytuacje. Jeśli otrzymamy $({\scriptstyle\rm D},{\scriptstyle\rm D})$, to oznacza to, że oba układy są tak samo dobre, a więc $v$ również jest dobry. Uzyskując wynik $({\scriptstyle\rm Z},{\scriptstyle\rm D})$, mamy natychmiast, że $v$ jest zły, podobnie w~wypadku, gdy wynikiem testu będzie $({\scriptstyle\rm Z},{\scriptstyle\rm Z})$ -- wtedy co najmniej jeden z~testowanych układów jest zły, ale nie może nim być $u$. Wynika stąd, że sprawdzając $u$ z~$n-1$ innymi układami, wykonamy $n-1$ testów, a~ponieważ stwierdziliśmy, że $u$ jest dobre za pomocą $\Theta(n)$ testów, to znalezienie wszystkich dobrych układów można wykonać przeprowadzając również $\Theta(n)$ testów.

\problem{Tablice Monge'a} %4-7

\subproblem %4-7(a)
\noindent\emph{Dowód $\Rightarrow$.} Tablica Monge'a $A$ spełnia nierówność
\[
	A[i,j]+A[k,l] \le A[i,l]+A[k,j], \quad\text{dla $1\le i<k\le m$ oraz $1\le j<l\le n$}.
\]
W~szczególności zaś może być $k=i+1$ oraz $l=j+1$, zatem implikacja zachodzi.
\bigskip

\noindent\emph{Dowód $\Leftarrow$.} Dowodzimy przez indukcję względem liczby wierszy $m$. Zauważmy, że warunek tablicy Monge'a nie ma większego sensu dla tablic o~jednej kolumnie lub jednym wierszu, zatem przyjmijmy $m=2$ za podstawę indukcji. Wtedy $i=1$ oraz $k=2$ i~przyjmując $l=j+1$ mamy
\begin{equation}
	A[1,j]+A[2,j+1] \le A[1,j+1]+A[2,j], \label{eq:4-7a}
\end{equation}
dla $1\le j<n$. Dodajmy teraz powyższą nierówność dla pewnego $j<n-1$ (przy założeniu, że $n>2$) do niej samej ale z~$l=j+1$ w~miejscu $j$. Po zredukowaniu zbędnych składników, dostajemy
\[
	A[1,j]+A[2,j+2] \le A[1,j+2]+A[2,j].
\]
Do ostatniej nierówności można ponownie dodawać~(\ref{eq:4-7a}) podstawiając w~miejsce $j$ coraz większe $l<n$ i~otrzymując dowolną nierówność stanowiącą warunek tablicy Monge'a.

Niech teraz $m>2$. Dowód wykorzystuje ten sam pomysł z~pierwszego kroku indukcji, z~tym, że teraz $i$ może przyjmować każdą dopuszczalną wartość. Przyjmujemy ponadto założenie indukcyjne, że dla tablica $A$ pozbawiona ostatniego wiersza stanowi tablicę Monge'a. Pozostaje zatem wykazać, że zachodzą wszystkie nierówności z~definicji tablicy Monge'a dla $k=m$. Zachodzi
\[
	A[i,j]+A[i+1,j+1] \le A[i,j+1]+A[i+1,j], \quad\text{dla $1\le i<m-1$ oraz $1\le j<n$}.
\]
Dodajemy tę nierówność do niej samej po uprzednim podstawieniu w~ostatniej $l=j+1<n$ w~miejsce $j$. Dzięki temu otrzymamy
\[
	A[i,j]+A[i+1,j+2] \le A[i,j+2]+A[i+1,j].
\]
Podobnie jak wcześniej, możemy tak dodawać żądaną ilość razy przyjmując coraz większe wartości $l<n$ zamiast $j$ i~dostając wszystkie wymagane nierówności.

Widać zatem, że implikacja jest prawdziwa dla tablic o~pewnej ustalonej liczbie kolumn. Dowód dla zmiennej liczby kolumn przeprowadza się analogicznie przez indukcję po $n\ge2$, pokazując tym samym, że twierdzenie zachodzi dla tablic o~dowolnych wymiarach.

\subproblem %4-7(b)
Korzystając z~poprzedniego punktu można pokazać, że nierówność
\[
	A[1,2]+A[2,3] \le A[1,3]+A[2,2]
\]
jest fałszywa, co zaburza właściwość tablicy Monge'a. By przywrócić własność, można zamienić $A[1,3]$ na~25.

\subproblem %4-7(c)
Korzystając z~poniższej nierówności, prawdziwej dla tablicy Monge'a $A$:
\begin{equation}
	A[i,j]+A[i+1,j+r] \le A[i,j+r]+A[i+1,j] \label{eq:4-7c}
\end{equation}
dla $0<r\le n-j$, wnioskujemy w~następujący sposób. Znajdujemy w~pierwszym wierszu tablicy $A$ pierwsze minimum z~lewej strony, które oznaczmy przez $\mu$. Indeksem $\mu$ jest oczywiście $f(1)$. Stwierdzamy teraz, że dla $1\le j<f(1)$ spełnione jest~(\ref{eq:4-7c}), czyli
\[
    A[1,j]+A[2,f(1)] \le \mu+A[2,j].
\]
Z~drugiej strony, $\mu<A[1,j]$ dla każdego $1\le j<f(1)$. Łącząc oba fakty, otrzymujemy $A[2,f(1)]<A[2,j]$, a~to oznacza, że pierwsze z~lewej strony minimum wiersza~2 występuje w~nim na indeksie niemniejszym niż $f(1)$, skąd $f(1)\le f(2)$.

Dowód kolejnych nierówności przebiega analogicznie, skąd dostajemy tezę.

\subproblem %4-7(d)
Korzystając z~twierdzenia z~poprzedniego punktu, szukając minimum wiersza \twoparts{$i$}{tego}, będziemy sprawdzać indeksy minimów wierszy \twoparts{$(i-1)$}{szego} oraz \twoparts{$(i+1)$}{szego}. Szukane minimum znajduje się pomiędzy nimi. Oczywiście nie istnieje wiersz zerowy, dlatego przetwarzając pierwszy wiersz nie szukamy minimum poprzedniego, ale przyjmujemy dla uproszczenia procedury, że $f(0)=1$. Podobny przypadek może się zdarzyć dla ostatniego nieparzystego wiersza, jeśli jest on ostatnim wierszem tablicy, wtedy wystarczy przyjąć wartość $f(m+1)=n$.

Po wyznaczeniu $f(i-1)$ oraz $f(i+1)$, sprawdzamy $f(i+1)-f(i-1)+1$ komórek wiersza $i$ w~poszukiwaniu jego minimum. W~ciągu całej procedury sprawdzimy w~pesymistycznym przypadku
\begin{align*}
	\sum_{\begin{subarray}{l}1\le i\le m\\2\,\nmid\,i\end{subarray}}\bigl(f(i+1)-f(i-1)+1\bigr) &= \sum_{k=0}^{\lceil m/2\rceil-1}\bigl(f(2k+2)-f(2k)+1\bigr) \\
	&= \sum_{k=0}^{\lceil m/2\rceil-1}\bigl(f(2k+2)-f(2k))+\lceil m/2\rceil \\[1mm]
	&= f(2\lceil m/2\rceil)-f(0)+\lceil m/2\rceil \\[2mm]
	&= n-1+\lceil m/2\rceil
\end{align*}
komórek, która to liczba jest rzędu $O(m+n)$.

\subproblem %4-7(e)
Na podstawie oszacowania z~poprzedniego punktu oraz z~tego, że na ostatnim poziomie rekursji wyznaczenie minimum jednego wiersza tablicy wymaga sprawdzenia co najwyżej $O(n)$ komórek, formułujemy następującą rekurencję:
\[
	T(m,n) =
	\begin{cases}
		O(n), & \text{jeśli $m=1$}, \\
		T(\lfloor m/2\rfloor,n)+O(m+n), & \text{jeśli $m>1$}.
	\end{cases}
\]
Na \twoparts{$i$}{tym} poziomie, rekurencja wprowadza koszt równy $O(m/2^i+n)$. Łatwo zauważyć, że jest $\lfloor\lg m\rfloor+1$ poziomów, a~zatem całkowity koszt wynosi
\begin{align*}
	T(n) &= \sum_{i=0}^{\lfloor\lg m\rfloor-1}O\Bigl(\frac{m}{2^i}+n\Bigr)+O(n) \\
	&= O\biggl(\sum_{i=0}^{\lfloor\lg m\rfloor-1}\left(\frac{m}{2^i}\right)\biggr)+O(n\lg m) \\
	&= O\biggl(m\sum_{i=0}^{\lfloor\lg m\rfloor-1}\left(\frac{1}{2^i}\right)\biggr)+O(n\lg m) \\
	&= O(m+n\lg m),
\end{align*}
ponieważ suma z~przedostatniej równości jest ograniczona od góry przez stałą.

\endinput
