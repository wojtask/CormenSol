\chapter{Rekurencje}

\section{Metoda podstawiania}

\subsection{} %4-1.1
Niech $c>0$ będzie stałą. Przyjmujemy następujące założenie:
\[
	T(\lceil n/2\rceil) \le c\lg(\lceil n/2\rceil).
\]
Na jego podstawie oraz z wzoru (3.3) otrzymujemy:
\[
	T(n) \le c\lg(\lceil n/2\rceil)+1 < c\lg (n/2)+2 = c\lg n-c\lg 2+2 \le c\lg n,
\]
o ile $c\ge2$. Niech $T(1)=1$. Ale wtedy otrzymujemy sprzeczność, bo $T(1)\le c\lg1=0$. Ponieważ dla $n>2$ rekurencja nie zależy bezpośrednio od $T(1)$, to przyjmijmy, że $T(2)=2$ stanowi przypadek brzegowy indukcji, dla którego już zachodzi $T(2)\le c\lg2$.

\subsection{} %4-1.2
Przyjmijmy założenie, że
\[
	T(\lfloor n/2\rfloor) \ge c\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)
\]
dla pewnej dodatniej stałej $c$. Korzystając z wzoru (3.3) mamy:
\begin{eqnarray*}
	T(n) &\ge& 2c\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)+n \\
	&>& 2c(n/2-1)\lg(n/4)+n \\
	&=& 2c((n/2)\lg n-\lg n-n+2)+n \\
	&=& cn\lg n-2c\lg n-2cn+4c+n \\
	&>& cn\lg n-2c\lg n+n(1-2c) \\
	&\ge& cn\lg n,
\end{eqnarray*}
Ostatni krok uzasadniamy, rozwiązując nierówność $n(1-2c)-2c\lg n\ge0$ ze względu na $c$:
\[
	c \le \frac{n}{2(n+\lg n)} \le \frac{n}{2n} = \frac{1}{2},
\]
a zatem wybierając dowolne $0<c\le1/2$ spełniamy nierówność. Można przyjąć $T(1)=1$ za przypadek brzegowy indukcji, bo $T(1)\ge c\lg1=0$. Wykazaliśmy, że $T(n)=\Omega(n\lg n)$. Skoro rozwiązanie rekurencji jest klasy $O(n\lg n)$ oraz $\Omega(n\lg n)$, to na mocy tw.~3.1, jest również w $\Theta(n\lg n)$.

\subsection{} %4-1.3
Przyjmijmy założenie, że $T(\lfloor n/2\rfloor)\le c\lfloor n/2\rfloor^2$ dla pewnej stałej $c>0$, czyli chcemy udowodnić, że $T(n)=O(n^2)$. Mamy zatem
\[
	T(n) \le 2c\lfloor n/2\rfloor^2+n \le 2cn^2\!/4 + n = cn^2\!/2+n \le cn^2,
\]
co jest prawdą, jeśli przyjmiemy $c\ge2$. Widać teraz, że z mocniejszym założeniem przypadek brzegowy $T(1)=1$ jest spełniony.

%podlogi i sufity
\subsection{} %4-1.4
Rekurencję $T(n)$ można przedstawić w następujący sposób:
\[
	T(n) =
	\begin{cases}
		c_1, & \hbox{dla }n=1, \\
		T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+c_2n, & \hbox{dla }n>1,
	\end{cases}
\]
dla pewnych stałych $c_1$,~$c_2>0$.
% Przyjmując założenie, że $T(n/2)=d(n/2)\lg(n/2)$ dla pewnej stałej $d>0$, otrzymujemy:
% \begin{eqnarray*}
% 	T(n) &=& 2d(n/2)\lg(n/2)+c_2n \\
% 	&=& dn(\lg n-\lg 2)+c_2n \\
% 	&=& dn\lg n-dn+c_2n \\
% 	&=& dn\lg n,
% \end{eqnarray*}
% w przypadku, gdy wybierzemy $d=c_2$. Zachodzi zatem $T(n)=\Theta(n\lg n)$.
% 
% Przyjmując $T(1)=c_1$ otrzymujemy sprzeczność, zatem należy przyjąć $T(2)=2c_1+2c_2$ i $T(3)=2c_1+3c_2$ jako podstawę indukcji.
% 
% Przyjmijmy założenie, że $T(\lfloor n/2\rfloor)\ge d\lfloor n/2\rfloor\lg\lfloor n/2\rfloor$ dla pewnej stałej $d>0$. W zależności od parzystości $n$, $\lfloor n/2\rfloor = n/2$ albo $\lceil n/2\rceil = n/2$. Otrzymujemy:
% \begin{eqnarray*}
% 	T(n) &=& T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+c_2n \\
% 	&\ge& 2T(\lfloor n/2\rfloor)+c_2n \\
% 	&\ge& 2d\lfloor n/2\rfloor\lg\lfloor n/2\rfloor+c_2n \\
% 	&\ge& 2d(n/2-1)\lg(n/2-1)+c_2n \\
% 	&\ge& dn\lg(n-2)-2\lg(n-2)-d(n-2) \\
% 	&\ge& dn\lg n+dn\lg\left(\frac{n-2}{n}\right)-2\lg(n-2)-d(n-2) \\
% 	&\ge& dn\lg n
% \end{eqnarray*}

\subsection{} %4-1.5
Wykorzystując założenie
\[
	T(\lfloor n/2\rfloor+17) \le c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)
\]
dla pewnej stałej $c>0$, otrzymujemy:
\begin{eqnarray*}
	T(n) &\le& 2c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)+n \\
	&\le& 2c(n/2+17)\lg(\lfloor n/2\rfloor+\lceil n/2\rceil)+n \\
	&=& 2c(n/2+17)\lg n+n \\
	&=& cn\lg n+34c\lg n+n,
\end{eqnarray*}
co zachodzi, o ile $17\le\lceil n/2\rceil$, skąd $n>32$. Niestety wyrażenie $34c\lg n+n$ jest nieujemne, a więc nie udowodnimy tezy. Przyjmijmy zatem, że zachodzi mocniejsze założenie:
\[
	T(\lfloor n/2\rfloor+17) \le c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)-b(\lfloor n/2\rfloor+17),
\]
dla stałych $b$,~$c>0$. Mamy teraz:
\begin{eqnarray*}
	T(n) &\le& 2c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)-2b(\lfloor n/2\rfloor+17)+n \\
	&\le& 2c(n/2+17)\lg(\lfloor n/2\rfloor+\lceil n/2\rceil)-2b(\lfloor n/2\rfloor+\lceil n/2\rceil)+n \\
	&=& 2c(n/2+17)\lg n-2bn+n \\
	&=& cn\lg n-bn+34c\lg n-(b-1)n \\
	&\le& cn\lg n-bn,
\end{eqnarray*}
gdy $c=1$ i $b$ jest dostatecznie duże, bo składnik $(b-1)n$ rośnie szybciej od $34c\lg n$. Także w tym przypadku założyliśmy, że $n>32$, więc dla $c=1$, możemy przyjąć $b\ge7$. Ograniczenie dolne dowodzimy w analogiczny sposób, przy wykorzystaniu mocniejszego założenia. Otrzymaliśmy żądane ograniczenie $T(n)$, pozostaje jedynie zbadać zachowanie rekurencji dla przypadków brzegowych.

Zauważmy, że stosowanie równania $T(n)=2T(\lfloor n/2\rfloor+17)+n$ dla $n\le35$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n\le35$ i niech stanowi to przypadek brzegowy rekurencji. Jednak aby zachodziła tożsamość, należałoby szukać bardzo dużego $n$, a wszystkie niższe wyrazy rekurencji przyjąć za przypadek brzegowy indukcji. Okazuje się, że można tę trudność przezwyciężyć, przyjmując większe $c$, np. $c=100$. Dla takiej wartości, $b\ge533$ i wtedy można zauważyć, że od $T(43)$ zależność zachodzi.

\subsection{} %4-1.6
Przyjmijmy, że $n=2^m$, skąd $m=\lg n$. Rekurencja przyjmuje teraz postać
\[
	T(2^m) = 2T(2^{m/2})+1.
\]
Z kolei podstawiając $S(m)$ za $T(2^m)$ dostajemy
\[
	S(m) = 2S(m/2)+1,
\]
której rozwiązaniem jest $O(\lg m)$ (zad.~4.1-1.). Zgodnie ze wskazówką, nie dbamy o to, czy $m/2$ jest całkowite.

By uzyskać oszacowanie dokładne, pozostaje udowodnić, że $S(m)=\Omega(\lg m)$. Przyjmujemy zatem założenie, że $S(m/2)\ge c\lg(m/2)$ dla $c>0$. Na jego podstawie otrzymujemy:
\[
	S(m) \ge 2c\lg(m/2)+1 = 2c\lg m-2c+1 \ge 2c\lg m,
\]
co oczywiście jest prawdą dla $c\le1/2$. Przyjęcie $S(1)=1$ na podstawę indukcji wystarcza, bo $S(1)\ge2c\lg1=0$, a zatem $S(m)=\Omega(\lg m)$.

Ponieważ $S(m)=\Theta(\lg m)$, więc wracając do oryginalnej rekurencji i starej zmiennej, mamy $T(n)=T(2^m)=S(m)=\Theta(\lg m)=\Theta(\lg\lg n)$.

\section{Metoda drzewa rekursji}

\subsection{} %4-2.1
\begin{figure}[h]
	\begin{center}
		\includegraphics{fig04.1}
	\end{center}
	\caption{Drzewo rekursji $T(n)=3T(n/2)+n$} \label{fig:4.2-1}
\end{figure}
Ponieważ podłogi i sufity nie mają w tym wypadku znaczenia, to badana rekurencja przyjmuje postać $T(n)=3T(n/2)+n$. W drzewie tej rekurencji z rys. \ref{fig:4.2-1} jest $\lg n$ poziomów, na $i$-tym z nich znajduje się $3^i$ węzłów, zatem jest $n^{\lg3}$ liści. Koszt węzła na poziomie $i$ wynosi $\frac{n}{2^i}$, skąd wynika, że łączny koszt wszystkich węzłów na $i$-tej głębokości jest równy $\left(\frac{3}{2}\right)^in$. Ponieważ liście wnoszą stały koszt, czyli $T(1)=\Theta(1)$, to ostatni poziom ma wartość $\Theta(n^{\lg3})$. Na podstawie tych wartości rozwiązujemy rekurencję:
\begin{eqnarray*}
	T(n) &=& n+\frac{3}{2}n+\left(\frac{3}{2}\right)^2n+\cdots+\left(\frac{3}{2}\right)^{\lg n-1}n+\Theta(n^{\lg 3}) \\
	&=& \sum_{i=0}^{\lg n-1}\left(\frac{3}{2}\right)^in+\Theta(n^{\lg 3}) \\
	&=& \frac{\left(\frac{3}{2}\right)^{\lg n}-1}{\frac{3}{2}-1}+\Theta(n^{\lg 3}) \\
	&=& 2(n^{\lg 3-1}-1)+\Theta(n^{\lg 3}) \\
	&=& O(n^{\lg 3}).
\end{eqnarray*}

Wykorzystując otrzymany wynik i przyjmując założenie:
\[
	T(\lfloor n/2\rfloor)n\le c(\lfloor n/2\rfloor)^{\lg 3},
\]
dowodzimy metodą przez podstawianie, otrzymując
\[
	T(n) = 3T(\lfloor n/2\rfloor)+n \le 3c(\lfloor n/2\rfloor)^{\lg 3}+n \le 3c(n/2)^{\lg 3}+n = cn^{\lg 3}+n.
\]
Nie dostaliśmy jednak żądanego wyniku, zatem należy przyjąć mocniejsze założenie:
\[
	T(\lfloor n/2\rfloor) \le c(\lfloor n/2\rfloor)^{\lg 3}-b\lfloor n/2\rfloor,
\]
dla pewnego $b>0$. Mamy teraz
\begin{eqnarray*}
	T(n) &\le& 3c(\lfloor n/2\rfloor)^{\lg 3}-3b\lfloor n/2\rfloor+n \\
	&\le& 3c(n/2)^{\lg 3}-3b(n/2)+n \\
	&=& cn^{\lg 3}-3b(n/2)+n \\
	&\le& cn^{\lg 3}-bn,
\end{eqnarray*}
co zachodzi dla $b\ge2$, a więc rzeczywiście oszacowaniem górnym rekurencji $T(n)$ jest $O(n^{\lg3})$.

\subsection{} %4-2.2
Drzewo rekursji $T(n)$ nie jest pełnym drzewem binarnym. Najkrótsza gałąź od korzenia do liścia biegnie przez gałąź $n\to\frac{n}{3}\to\frac{n}{9}\to\dots\to\frac{n}{3^i}\to\dots\to1$. Jej liść jest na poziomie $i=\log_3n$. Ponieważ pełne drzewo binarne o~wysokości $\log_3n$ wnosi niewiększy koszt niż drzewo rekurencji $T(n)$, to zachodzi $T(n)\ge cn\log_3n$, a stąd $T(n)=\Omega(n\lg n)$.

\subsection{} %4-2.3
\begin{figure}[h]
	\begin{center}
		\includegraphics{fig04.2}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n/3)+T(2n/3)+cn$} \label{fig:4.2-3}
\end{figure}

W drzewie rekursji z rys. \ref{fig:4.2-3}, na $i$-tym poziomie jest $2^i$ węzłów, z których każdy wnosi koszt równy $\frac{cn}{2^i}$. Stąd, kosztem całego poziomu jest $2^icn$. Ponieważ współczynnik przy $n$ w koszcie węzła maleje 2-krotnie wraz ze wzrostem poziomu, więc wysokością drzewa jest $\lg n$. Wnioskujemy zatem, że liczbą liści w tym drzewie jest $2^{\lg n}=n$ i że koszt ostatniego poziomu wynosi $\Theta(n)$. Sumując koszty z każdego poziomu, otrzymujemy:
\begin{eqnarray*}
	T(n) &=& cn+2cn+2^2cn+\cdots+2^{\lg n-1}cn+\Theta(n) \\
	&=& \sum_{i=0}^{\lg n-1}2^icn+\Theta(n) \\
	&=& (2^{\lg n}-1)cn+\Theta(n) \\
	&=& (n-1)cn+\Theta(n) \\
	&=& \Theta(n^2).
\end{eqnarray*}

Sprawdzamy otrzymany wynik wykorzystując do tego celu metodę podstawiania. Badamy najpierw oszacowanie dolne $T(n)$, przyjmując założenie
\[
	T(n/2) \ge d_1(n/2)^2,
\]
dla pewnej stałej $d_1>0$. Stąd:
\[
	T(n) \ge d_1n^2+cn \ge d_1n^2, 
\]
bo $c>0$, a więc prawdą jest, że $T(n)=\Omega(n^2)$.

By udowodnić dodatkowo, że $T(n)=O(n^2)$, możemy przyjąć takie samo założenie indukcyjne ale z przeciwnym znakiem nierówności, jednak nie uzyskamy szukanego ograniczenia górnego na $T(n)$. Przyjmijmy zatem, że dla stałych $d_2$,~$d_3>0$ zachodzi
\[
	T(n/2) \le d_2(n/2)^2-d_3(n/2).
\]
Dowodzimy:
\[
	T(n) \le 4(d_2n^2\!/4-d_3n/2)+cn = d_2n^2-2d_3n+cn \le d_2n^2-d_3n,
\]
co jest prawdą, o ile $d_3\ge c$.

Dzięki metodzie podstawiania wykazaliśmy, że $T(n)=\Theta(n^2)$.

\subsection{} %4-2.4
Załóżmy, że w przypadku, gdy $n\le a$, to $T(n)=\Theta(1)$ i wartość taką zwracamy bezpośrednio (bez użycia rekurencji).
\begin{figure}[h]
	\begin{center}
		\includegraphics{fig04.3}
	\end{center}
	\caption{Drzewo rekursji $T(n)=3T(n/2)+n$} \label{fig:4.2-4}
\end{figure}
Drzewo z rys.~\ref{fig:4.2-4} ma wysokość wynoszącą $\lfloor n/a\rfloor$. $i$-ty poziom (oprócz zerowego i ostatniego) wnosi koszt równy $c(n-ia)$, a ostatni -- $\Theta(1)$. Obliczamy koszt całego drzewa:
\begin{eqnarray*}
	T(n) &=& cn+\sum_{i=1}^{\lfloor n/a\rfloor-1}c(n-ia)+\Theta(1) \\
	&=& cn+cn\sum_{i=1}^{\lfloor n/a\rfloor-1}1-ca\sum_{i=1}^{\lfloor n/a\rfloor-1}i+\Theta(1) \\
	&=& cn+cn(\lfloor n/a\rfloor-1)-ca\frac{\lfloor n/a\rfloor(\lfloor n/a\rfloor-1)}{2}+\Theta(1) \\
	&=& \Theta(n^2).
\end{eqnarray*}

\subsection{} %4-2.5
\begin{figure}[h]
	\begin{center}
		\includegraphics{fig04.4}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n-a)+T(a)+cn$} \label{fig:4.2-5}
\end{figure}

Zauważmy, że drzewo rekurencji $T(n)$ na rys.~\ref{fig:4.2-5} dla parametru $\alpha=k$ jest symetryczne do drzewa $T(n)$ przy parametrze $\alpha=1-k$, przyjmijmy więc, że $0<\alpha\le1/2$.

Wyznaczmy najpierw oszacowanie górne rekurencji. Na $i$-tym poziomie drzewa najmniejszy koszt wnoszą węzły o~wartościach $c\alpha^in$, gdy $0<\alpha\le1/2$, a więc elementy ze skrajnie lewej gałęzi. Sprawdzając kiedy osiągną one wartość stałą $d>0$, wyznaczamy ilość poziomów tego drzewa. Na pewnej wysokości $h$, będzie $c\alpha^hn=d$, skąd otrzymujemy $h=\log_{1/\alpha}(cn/d)$. Ponieważ $\alpha$ jest stałe, to $h=\Theta(\lg n)$. Każdy poziom drzewa wnosi koszt $cn$, więc oszacowaniem górnym rekurencji jest $T(n)=O(cnh)=O(n\lg n)$.

Badając teraz skrajnie prawą gałąź, której elementy wnoszą największy koszt na każdym poziomie, możemy dojść do oszacowania dolnego dla $T(n)$. Na wysokości $h'$ mamy $c(1-\alpha)^{h'}n=d$, skąd $h'=\log_{1/(1-\alpha)}(cn/d)=\Theta(1)$. Poziom na wysokości $h'$ jest ostatnim, który ma komplet węzłów; niższe poziomy są coraz mniej liczne, zatem obliczając koszt drzewa $T(n)$ od korzenia do wysokości $h'$, uzyskujemy dobre oszacowanie dolne rekurencji. Także w tym przypadku mamy $h'=\Theta(\lg n)$, a więc $T(n)=\Omega(cnh')=\Omega(n\lg n)$, skąd asymptotycznie dokładnym rozwiązaniem rekurencji jest $\Theta(n\lg n)$.

\section{Metoda rekurencji uniwersalnej}

\subsection{} %4-3.1

\subsubsection{}
W równaniu (4.5) przyjmujemy $a=4$ i $b=2$ oraz $f(n)=n$. Ponieważ $f(n)=O(n^{2-\epsilon})$ dla pewnej stałej $\epsilon>0$, to z tw.~o rekurencji uniwersalnej mamy $T(n)=\Theta(n^2)$.

\subsubsection{}
Postępując analogicznie jak w poprzednim punkcie, mamy te same wartości $a$ i $b$, ale teraz $f(n)=n^2$. Z tego, że $f(n)=\Theta(n^2)$ dostajemy $T(n)=\Theta(n^2\lg n)$.

\subsubsection{}
Dla tych samych $a$ i $b$ ale $f(n)=n^3$, mamy $f(n)=\Omega(n^{2+\epsilon})$ dla pewnej stałej $\epsilon>0$ oraz
\[
	4f(n/2) = 4n^3\!/8 = n^3\!/2 = f(n)/2,
\]
czyli warunek regularności jest spełniony dla stałej $c=1/2$, a zatem $T(n)=\Theta(n^3)$.

\subsection{} %4-3.2
Rozwiążmy rekurencję $T(n)$. Ponieważ $n^{\log_ba}=n^{\lg7}$ oraz $f(n)=n^2=O(n^{\lg7-\epsilon})$ dla pewnej stałej $\epsilon>0$, to z tw.~4.1 zachodzi $T(n)=\Theta(n^{\lg7})$.

Pozostaje teraz zbadanie nierówności $T'(n)<T(n)$ w zależności od wartości $a$, bo w rekurencji $T'(n)$ jest $n^{\log_ba}=n^{\log_4a}$ oraz $f(n)=n^2$. Załóżmy, że $f(n)=O(n^{\log_4a-\epsilon})$, co jest prawdą dla $a>16$ i wtedy $T'(n)=\Theta(n^{\log_4a})$. Algorytm $A'$ jest efektywniejszy od algorytmu $A$, gdy $\log_4a<\lg7$, skąd $16<a<49$. Pozostałe przypadki tw.~4.1 można stosować, o ile $a\le16$, zatem pomińmy ich sprawdzanie.

Największą wartością $a$, dla której algorytm $A'$ jest bardziej efektywny od algorytmu $A$, jest $48$.

\subsection{} %4-3.3
Ponieważ $a=1$ oraz $b=2$, to $n^{\log_ba}=n^0=1$ jest funkcją stałą. W rekurencji tej $f(n)$ także jest stałe, a więc $f(n)=\Theta(n^{\log_ba})$ oraz $T(n)=\Theta(n^{\log_ba}\lg n)=\Theta(\lg n)$.

\subsection{} %4-3.4
Dla rekurencji $T(n)$ mamy $a=4$, $b=2$ oraz $f(n)=n^2\lg n$, a więc $n^{\log_ba}=n^2$ i $f(n)=\Omega(n^{\log_ba})$ i stosujemy trzeci przypadek twierdzenia~4.1. Pozostaje jeszcze zbadać, czy zachodzi warunek regularności:
\[
	4f(n/2) = 4(n^2\!/4)\lg(n/2) = n^2\lg n-n^2 = n^2(\lg n-1) \le cf(n).
\]
Szukamy stałej $c<1$ takiej, by była spełniona ostatnia nierówność. Po jej rozwiązaniu, otrzymujemy $c\ge1-1/\!\lg n$, jednak dla $n$ dążącego do $\infty$, wartość $c$ musiałaby być dowolnie bliska 1, czyli musiałoby zachodzić $c\ge1$, a to jest sprzeczne z wcześniej przyjętym ograniczeniem na $c$.

Nie można zatem zastosować twierdzenia o rekurencji uniwersalnej w celu rozwiązania tej rekurencji, zatem znajdziemy dla niej asymptotyczne górne oszacowanie zgadując rozwiązanie, a następnie dowodząc jego poprawność metodą podstawiania.

Po pierwszym wywołaniu, rekurencja wnosi koszt równy $n^2\lg n$. Następnie, 4 razy wywołujemy $T(n/2)$, co daje koszt
\[
	4\left(\frac{n^2}{4}\lg n-\frac{n^2}{4}\right) = n^2\lg n-n^2.
\]
Kolejne poziomy wywołań kosztują
\[
	8\left(\frac{n^2}{16}\lg n-\frac{n^2}{16}\right) = \frac{n^2\lg n}{2}-\frac{n^2}{2},
\]
\[
	16\left(\frac{n^2}{64}\lg n-\frac{n^2}{64}\right) = \frac{n^2\lg n}{4}-\frac{3n^2}{64},\qquad\hbox{itd.}
\]

Najbardziej znaczący wyraz na kolejnych poziomach wywołań jest prawdopodobnie równy $\frac{n^2\lg n}{2^i}$ dla $i$-tego poziomu. Ponieważ na poziomie mniej więcej $\lg n$ mamy liście, które wnoszą stały koszt, to otrzymujemy:
\[
	\sum_{i=1}^{\lg n}\frac{n^2\lg n}{2^i} = n^2\lg n\sum_{i=1}^{\lg n}\frac{1}{2^i} = n^2\lg n\left(2-\frac{2}{n}\right) = O(n^2\lg n).
\]
Zgadujemy więc, że rozwiązaniem $T(n)$ jest $O(n^2\lg n)$. Przyjmijmy założenie
\[
	T(n/2) \le c(n/2)^2\lg(n/2),
\]
dla pewnej stałej $c>0$. Otrzymujemy:
\begin{eqnarray*}
	T(n) &=& 4T(n/2)+n^2\lg n \\
	&\le& 4c(n/2)^2\lg(n/2)+n^2\lg n \\
	&=& cn^2(\lg n-1)+n^2\lg n \\
	&=& cn^2\lg n+n^2(\lg n-c) \\
	&\le& cn^2\lg n,
\end{eqnarray*}
co zachodzi dla $c\le\lg n$, ale zakładając, że badaliśmy rekurencję począwszy od $n=2$, możemy uważać $c$ za stałą nie przekraczającą 1. Przypadkiem brzegowym jest $T(2)=1$, dla którego nierówność istotnie zachodzi. Rozwiązaniem rekurencji $T(n)$ jest zatem $O(n^2\lg n)$.

\subsection{} %4-3.5
Przyjmując $a=4$, $b=2$ oraz $f(n)=n^2\lg n$ mamy sytuację z poprzedniego zadania.

\section{Dowód twierdzenia o rekurencji uniwersalnej}

\subsection{} %4-4.1
Z tożsamości (3.4) mamy
\[
	\lceil\lceil n/b\rceil/b\rceil = \left\lceil n/b^2\right\rceil,
\]
\[
	\lceil\lceil\lceil n/b\rceil/b\rceil/b\rceil = \left\lceil\left\lceil n/b^2\right\rceil\!/b\right\rceil = \left\lceil n/b^3\right\rceil,\qquad\hbox{itd.,}
\]
a zatem dostajemy $n_j=\left\lceil n/b^j\right\rceil$.

\subsection{} %4-4.2
Zastąpmy drugi przypadek twierdzenia~4.1 ogólniejszym warunkiem, tzn. jeśli $f(n)=\Theta(n^{\log_ba}\lg^kn)$, to zachodzi $T(n)=\Theta(n^{\log_ba}\lg^{k+1}n)$, dla $k\ge0$. Dla tak zmodyfikowanego twierdzenia należy przeprowadzic dowód analogicznie zmodyfikowanych lematów 4.3 i 4.4.\\

\noindent\emph{Dowód lematu~4.3.}

\noindent Przy założeniu, że $f(n)=\Theta(n^{\log_ba}\lg^kn)$ otrzymujemy, że
\[
	f(n/b^j)=\Theta\bigl((n/b^j)^{\log_ba}\lg^k(n/b^j)\bigr).
\]
Po podstawieniu do wzoru na $g(n)$:
\[
	g(n) = \Theta\biggl(\sum_{j=0}^{\log_bn-1}a^j\left(\frac{n}{b^j}\right)^{\log_ba}\lg^k\frac{n}{b^j}\biggr).
\]
Mamy dalej:
\begin{eqnarray*}
	\sum_{j=0}^{\log_bn-1}a^j\left(\frac{n}{b^j}\right)^{\log_ba}\lg^k\frac{n}{b^j} &=& n^{\log_ba}\sum_{j=0}^{\log_bn-1}\left(\frac{a}{b^{\log_ba}}\right)^j\lg^k\frac{n}{b^j} \\
	&=& n^{\log_ba}\sum_{j=0}^{\log_bn-1}(\lg n-j\lg b)^k \\
	&=& n^{\log_ba}\cdot\Theta(\lg^{k+1}n) \\
	&=& \Theta(n^{\log_ba}\lg^{k+1}n).
\end{eqnarray*}
Skorzystano z tego, że $(\lg n-j\lg b)^k=\Theta(\lg^kn)$ na podstawie zad.~3.1-2., a~następnie zauważając, że
\[
	\sum_{j=0}^{\log_bn-1}\Theta(\lg^kn) = \log_bn\cdot\Theta(\lg^kn) = \Theta(\lg^{k+1}n).
\]
Lemat~4.3 został udowodniony.\\

\noindent\emph{Dowód lematu 4.4.}

\noindent Wystarczy wykazać jedynie drugi przypadek z racji tego, że $f(n)=\Theta(\lg^{k+1}n)$.
\[
	T(n) = \Theta(n^{\log_ba})+\Theta(n^{\log_ba}\lg^{k+1}n) = \Theta(n^{\log_ba}\lg^{k+1}n),
\]
co kończy dowód i jednocześnie pokazuje prawdziwość głównego twierdzenia.

%dokonczyc
\subsection{} %4-4.3
Oszacowanie funkcji
\[
	g(n) = \sum_{j=0}^{\lfloor\log_bn\rfloor-1}a^jf(n/b^j)
\]
dla przypadku~3 twierdzenia~4.1 wynosi $\Theta(f(n))$ (z lematu~4.3). Podstawiając je do równania~(4.6), dostajemy $T(n)=\Omega(n^{\log_ba+\epsilon})+\Theta(f(n))$. 
%w tym miejscu
Ponieważ lemat~4.3 nie korzysta z założenia, że $f(n)=\Omega(n^{\log_ba+\epsilon})$, a zatem nie jest ono konieczne.

\problems

\subsection{} %4-1
W punktach (a)--(f) skorzystano z twierdzenia o rekurencji uniwersalnej.

\subsubsection{} %4-1(a)
\[
	n^{\log_ba} = n^{\log_22} = n \quad\hbox{oraz}\quad f(n) = n^3 = \Omega(n)
\]
Ponieważ warunek regularności jest spełniony:
\begin{eqnarray*}
	2f(n/2) &\le& cf(n) \\
	2n^3\!/8 &\le& cn^3 \\
	c &\ge& 1/4,
\end{eqnarray*}
to stąd wnioskujemy, że $T(n)=\Theta(n^3)$.

\subsubsection{} %4-1(b)
\[
	n^{\log_ba} = n^{\log_{10/9}1} = 1 \quad\hbox{oraz}\quad f(n) = n = \Omega(n^{\log_ba})
\]
Badamy warunek regularności:
\begin{eqnarray*}
	f(9n/10) &\le& cf(n) \\
	9n/10 &\le& cn \\
	c &\ge& 9/10
\end{eqnarray*}
i stwierdzamy, że $T(n)=\Theta(n)$.

\subsubsection{} %4-1(c)
\[
	n^{\log_ba} = n^{\log_416} = n^2 \quad\hbox{oraz}\quad f(n) = n^2 = \Theta(n^2),
\]
a stąd $T(n)=\Theta(n^2\lg n)$.

\subsubsection{} %4-1(d)
\[
	n^{\log_ba} = n^{\log_37} \quad\hbox{oraz}\quad f(n) = n = \Omega(n^{\log_37})
\]
Warunek regularności zachodzi:
\begin{eqnarray*}
	7f(n/3) &\le& cf(n) \\
	7n^2\!/9 &\le& cn^2 \\
	c &\ge& 7/9,
\end{eqnarray*}
a zatem $T(n)=\Theta(n^2)$.

\subsubsection{} %4-1(e)
\[
	n^{\log_ba} = n^{\lg7} \quad\hbox{oraz}\quad f(n) = n^2 = O(n^{\lg7}),
\]
a stąd $T(n)=\Theta(n^{\lg 7})$.

\subsubsection{} %4-1(f)
\[
	n^{\log_ba} = n^{\log_42} = n^{1/2} \quad\hbox{oraz}\quad f(n) = \sqrt{n} = \Omega(n^{1/2}),
\]
a stąd $T(n)=\Theta\bigl(\sqrt{n}\lg n\bigr)$.

\subsubsection{} %4-1(g)
Zauważmy, że rekurencja rozwija się następująco:
\begin{eqnarray*}
	T(n) &=& T(n-1)+n=T(n-2)+(n-1)+n=\cdots \\
	&=& 1+2+\cdots+(n-1)+n \\
	&=& \sum_{i=1}^ni = \frac{n(n+1)}{2},
\end{eqnarray*}
a stąd otrzymujemy, że $T(n)=\Theta(n^2)$.

\subsubsection{} %4-1(h)
Niech $n=2^m$, skąd $m=\lg n$. Rekurencja przyjmuje teraz postać
\[
	T(2^m) = T(2^{m/2})+1.
\]
Podstawiając $S(m)$ za $T(2^m)$, otrzymujemy
\[
	S(m) = S(m/2)+1.
\]
Ponieważ rozwiązaniem ostatniej rekurencji jest $\Theta(\lg m)$ (co wykazano w zad.~4.3-3.), to stąd mamy, że $T(n)=T(2^m)=S(m)=\Theta(\lg m)=\Theta(\lg\lg n)$.

\subsection{} %4-2
Liczby z zakresu $0\twodots n$ reprezentowane są binarnie za pomocą $\lfloor\lg n\rfloor+1$ bitów. Można dla wygody przyjąć, że $n$ jest potęgą 2 pomniejszoną o 1. W przeciwnym przypadku rozszerzamy tablicę $A$, umieszczając w niej kolejne liczby naturalne większe od starego rozmiaru $A$ tak, by $n$ było o 1 mniejsze od pewnej potęgi 2. Ta modyfikacja sprawi, że wszystkie liczby w $A$ będą mieć tyle samo bitów, a rozmiar problemu urośnie co najwyżej dwukrotnie.

Badając najmniej znaczące bity liczb z tablicy $A$, sprawdzamy ich parzystość. W zakresie $0\twodots n$ jest $n/2$ liczb parzystych i tyle samo nieparzystych. Jeśli wsród pobranych bitów jest więcej jedynek, to brakuje liczby parzystej, a~jeśli więcej zer, to brakująca liczba jest nieparzysta. W zależności od przypadku, odrzucamy $n/2$ liczb o parzystości różnej od brakującej. Wsród pozostałych badamy następnie drugi najmniej znaczący bit i analogicznie postępując wyznaczamy $n/4$ kolejnych liczb do wyeliminowania. Powtarzając opisane czynności aż do odrzucenia wszystkich liczb z tablicy, poznamy tę, której brakuje.

Czas działania zaprezentowanego tu algorytmu można zapisać w postaci rekurencji $T(n)=T(n/2)+n$, której rozwiązaniem jest $O(n)$, co można łatwo pokazać przy użyciu twierdzenia 4.1. Widać teraz, że oryginalny problem (z~dowolnym $n$) wprowadził tylko stały czynnik do czasu działania algorytmu.

\subsection{} %4-3()

\subsubsection{} %4-3(a)
\begin{enumerate}
	\item
	\begin{eqnarray*}
		T(N) &=& T(N/2)+\Theta(1) \\
		T(N) &=& O(\lg N)
	\end{eqnarray*}
	Wynik został wykazany w zad.~4.3-3.
	\item
	\begin{eqnarray*}
		T(N) &=& T(N/2)+\Theta(N) \\
		T(N) &=& O(N\lg N)
	\end{eqnarray*}
	Rozwiązanie jest identyczne z rozwiązaniem rekurencji~(4.4).
	\item
	\begin{eqnarray*}
		T(N) &=& T(N/2)+\Theta(N) \\
		T(N) &=& O(N\lg N)
	\end{eqnarray*}
\end{enumerate}

\subsubsection{} %4-3(b)
\begin{enumerate}
	\item
	\begin{eqnarray*}
		T(N) &=& 2T(N/2)+\Theta(N)+O(1) \\
		T(N) &=& 2T(N/2)+\Theta(N) \\
		T(N) &=& O(N\lg N)
	\end{eqnarray*}
	\item
	\begin{eqnarray*}
		T(N) &=& 2T(N/2)+\Theta(N)+O(N) \\
		T(N) &=& 2T(N/2)+\Theta(N) \\
		T(N) &=& O(N\lg N)
	\end{eqnarray*}
	\item
	\begin{eqnarray*}
		T(N) &=& 2T(N/2)+\Theta(N)+O(N) \\
		T(N) &=& O(N\lg N)
	\end{eqnarray*}
\end{enumerate}

\subsection{} %4-4
Punkty (a)--(g) dowodzimy wykorzystując twierdzenie o rekurencji uniwersalnej.

\subsubsection{} %4-4(a)
\[
	n^{\log_ba} = n^{\lg3} \quad\hbox{oraz}\quad f(n) = n\lg n = O(n^{\lg3}),
\]
a stąd $T(n)=\Theta(n^{\lg3})$.

\subsubsection{} %4-4(b)
\[
	n^{\log_ba} = n^{\log_55} = n \quad\hbox{oraz}\quad f(n) = n/\!\lg n = O(n),
\]
a stąd $T(n)=\Theta(n)$.

\subsubsection{} %4-4(c)
\[
	n^{\log_ba} = n^{\lg 4} = n^2 \quad\hbox{oraz}\quad f(n) = n^{5/2} = \Omega(n^2)
\]
Badamy warunek regularności:
\begin{eqnarray*}
	4f(n/2) &\le& cf(n) \\
	\frac{4n^{5/2}}{2^{5/2}} &\le& cn^{5/2} \\
	c &\ge& \frac{1}{\sqrt{2}}
\end{eqnarray*}
i stwierdzamy, że $T(n)=\Theta(n^{5/2})$.

%dokonczyc, poprawic (korzystając z 4.1-5)
\subsubsection{} %4-4(d)
Ponieważ stała 5 nie wpływa na postać rozwiązania, rozważmy rekurencję $T'(n)=3T'(n/3)+n/2$. Rozwiązując ją za pomocą twierdzenia o~rekurencji uniwersalnej, dostajemy $T'(n)=\Theta(n\lg n)$. Udowodnimy teraz metodą podstawiania, że identyczny wynik jest rozwiązaniem rekurencji $T(n)$.

Wykorzystując założenie
\[
	T(\lfloor n/3\rfloor+5) \le c(\lfloor n/3\rfloor+5)\lg(\lfloor n/3\rfloor+5)
\]
dla pewnej stałej $c>0$, otrzymujemy:
\begin{eqnarray*}
	T(n) &\le& 3c(\lfloor n/3\rfloor+5)\lg(\lfloor n/3\rfloor+5)+n/2 \\
	&\le& 3c(n/3+5)\lg(\lfloor n/3\rfloor+n-\lfloor n/3\rfloor)+n/2 \\
	&=& 3c(n/3+5)\lg n+n/2 \\
	&=& cn\lg n+15c\lg n+n/2,
\end{eqnarray*}
co zachodzi, o ile $5\le n-\lfloor n/3\rfloor$, skąd $n\ge7$. Niestety wyrażenie $15c\lg n+n/2$ jest nieujemne, a więc nie udowodnimy tezy. Przyjmijmy zatem, że zachodzi mocniejsze założenie:
\[
	T(\lfloor n/3\rfloor+5) \le c(\lfloor n/3\rfloor+5)\lg(\lfloor n/3\rfloor+5)-b(\lfloor n/3\rfloor+5),
\]
dla stałych $b$,~$c>0$. Mamy teraz:
\begin{eqnarray*}
	T(n) &\le& 3c(\lfloor n/3\rfloor+5)\lg(\lfloor n/3\rfloor+5)-3b(\lfloor n/3\rfloor+5)+n/2 \\
	&\le& 3c(n/3+5)\lg n-3bn+n/2 \\
	&=& cn\lg n-bn+15c\lg n-(2b-1/2)n \\
	&\le& cn\lg n-bn,
\end{eqnarray*}
gdy $c=1$ i $b$ jest dostatecznie duże, bo składnik $(2b-1/2)n$ rośnie szybciej od $15c\lg n$. Także w tym przypadku założyliśmy, że $n\ge7$, więc dla $c=1$, możemy przyjąć $b\ge4$. Otrzymaliśmy żądane ograniczenie $T(n)$, pozostaje jedynie zbadać zachowanie rekurencji dla przypadków brzegowych.

Zauważmy, że stosowanie równania $T(n)=3T(n/3+5)+n/2$ dla $n\le8$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n\le8$ i niech stanowi to przypadek brzegowy rekurencji. Ponieważ $T(9)=3T(8)+4{,}5\le9\lg9-4$, to przyjmujemy tą wartość za przypadek brzegowy indukcji.

% Ponieważ stała $5$ nie wpływa na postać rozwiązania, rozważmy rekurencję $T'(n)=3T'(n/3)+n/2$. Rozwiązując ją za pomocą twierdzenia o~rekurencji uniwersalnej, dostajemy $T'(n)=\Theta(n\lg n)$. Udowodnijmy teraz metodą podstawiania, że identyczne rozwiązanie posiada $T(n)$.
% 
% Wykorzystując założenie
% \[
% 	T(\lfloor n/3\rfloor+5)\le c(\lfloor n/3\rfloor+5)\lg(\lfloor n/3\rfloor+5)
% \]
% dla pewnej stałej $c>0$, otrzymujemy:
% \begin{eqnarray*}
% 	T(n) &\le& 3c(\lfloor n/3\rfloor+5)\lg(\lfloor n/3\rfloor+5)+n/2 \\
% 	&\le& 3c(n/3+5)\lg(\lfloor n/3\rfloor+\lceil 2n/3\rceil)+n/2 \\
% 	&=& 3c(n/3+5)\lg n+n/2 \\
% 	&=& cn\lg n+15c\lg n+n/2,
% \end{eqnarray*}
% co zachodzi, o ile $5\le\lceil 2n/3\rceil$, skąd $n\ge 8$. Niestety wyrażenie $15c\lg n+n/2$ jest nieujemne, a więc nie udowodnimy tezy. Przyjmijmy zatem, że zachodzi mocniejsze założenie:
% \[
% 	T(\lfloor n/3\rfloor+5)\le c(\lfloor n/3\rfloor+5)\lg(\lfloor n/3\rfloor+5)-b(\lfloor n/3\rfloor+5),
% \]
% dla stałych $b,c>0$. Mamy teraz:
% \begin{eqnarray*}
% 	T(n) &\le& 3c(\lfloor n/3\rfloor+5)\lg(\lfloor n/3\rfloor+5)-3b(\lfloor n/3\rfloor+5)+n/2 \\
% 	&\le& 3c(n/3+5)\lg(\lfloor n/3\rfloor+\lceil 2n/3\rceil)-3b(\lfloor n/3\rfloor+\lceil n/3\rceil)+n/2 \\
% 	&=& 3c(n/3+5)\lg n-3bn+n/2 \\
% 	&=& cn\lg n-bn+15c\lg n-(2b-1/2)n \\
% 	&\le& cn\lg n-bn,
% \end{eqnarray*}
% gdy $c=1$ i $b$ jest dostatecznie duże, bo składnik $(2b-1/2)n$ rośnie szybciej od $15c\lg n$. Także w tym przypadku założyliśmy, że $n>32$, więc dla $c=1$, możemy przyjąć $b\ge 7$. Otrzymaliśmy żądane ograniczenie $T(n)$, pozostaje jedynie zbadać zachowanie rekurencji dla przypadków brzegowych.
% 
% Zauważmy, że stosowanie równania $T(n)=T(\lfloor n/2\rfloor+17)+n$ dla $n\le 35$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n\le 35$ i niech stanowi to przypadek brzegowy rekurencji. Jednak

\subsubsection{} %4-4(e)
\[
	n^{\log_ba} = n \quad\hbox{oraz}\quad f(n) = n/\!\lg n = O(n),
\]
a stąd $T(n)=\Theta(n)$.

\subsubsection{} %4-4(f)
W celu rozwiązania rekurencji wykorzystamy metodę drzewa rekursji.
\begin{figure}[h]
	\begin{center}
		\includegraphics{fig04.5}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n/2)+T(n/4)+T(n/8)+n$} \label{fig:4-4f}
\end{figure}
Zauważmy, że najszybciej maleją argumenty na skrajnie prawej gałęzi. Koszt jej węzła na $i$-tym poziomie wynosi $\frac{n}{8^i}$. Dla pewnego $h$ i pewnej stałej $c>0$ zachodzi $\frac{n}{8^h}=c$, skąd $h=\log_8(n/c)$ i na tym poziomie gałąź ta ma liścia. Sumując koszty poziomów drzewa od korzenia aż do $h$-tego poziomu uzyskujemy dolne oszacowanie rekurencji:
\begin{eqnarray*}
	T(n) &\ge& \sum_{i=0}^{\log_8(n/c)-1}\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&=& \frac{1-\left(\frac{7}{8}\right)^{\log_8(n/c)}}{1-\frac{7}{8}}n+\Theta(1) \\
	&=& 8n\left(1-\left(\frac{n}{c}\right)^{\log_8(7/8)}\right)+\Theta(1) \\
	&\ge& 8n\left(1-\left(\frac{n}{c}\right)\right)+\Theta(1).
\end{eqnarray*}
Oszacowaniem ostatniego wyrażenia jest $\Theta(n)$, otrzymujemy zatem, że $T(n)=\Omega(n)$.

Zbadajmy teraz górne oszacowanie rekurencji $T(n)$ poprzez dokonanie obserwacji, że najwolniej malejącymi węzłami drzewa są węzły ze skrajnie lewej gałęzi, które wnoszą koszt równy $\frac{n}{2^i}$ na $i$-tym poziomie, więc liść znajduje się na poziomie $h'=\lg(n/d)$ dla pewnej stałej $d>0$.
\begin{eqnarray*}
	T(n) &\le& \sum_{i=0}^{\lg(n/d)}\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&<& \sum_{i=0}^\infty\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&=& \frac{n}{1-\frac{7}{8}}+\Theta(1) \\
	&=& 8n+\Theta(1),
\end{eqnarray*}
skąd mamy, że $T(n)=O(n)$. Asymptotycznym dokładnym oszacowaniem rekurencji jest zatem $\Theta(n)$.

\subsubsection{} %4-4(g)
Rozwinięciem rekurencji jest
\[
	T(n) = \frac{1}{n}+\frac{1}{n-1}+\cdots+\frac{1}{2}+\frac{1}{1} = H_n,
\]
a korzystając z zad.~A.2-3. mamy, że $T(n)=\Theta(\lg n)$.

\subsubsection{} %4-4(h)
Ponieważ
\[
	T(n) = \lg n+\lg(n-1)+\cdots+\lg2+\lg 1 = \lg\biggl(\prod_{i=1}^ni\biggr) = \lg(n!),
\]
to z wzoru~(3.18) dostajemy $T(n)=\Theta(n\lg n)$.

\subsubsection{} %4-4(i)
Rozwijając rekurencję, otrzymujemy
\begin{eqnarray*}
	T(n) &=& 2\lg n+2\lg(n-2)+\cdots+2\lg4+2\lg2 \\
	&=& 2\lg\biggl(\prod_{i=1}^{n/2}2i\biggr) \\
	&=& 2\lg\bigl(2^{n/2}(n/2)!\bigr) \\
	&=& 2\bigl(\lg 2^{n/2}+\lg((n/2)!)\bigr).
\end{eqnarray*}
Wykorzystując wzór~(3.18) dostajemy
\[
	T(n) = n+2\Theta((n/2)\lg (n/2)) = \Theta(n\lg n).
\]

%dokonczyc, zrobic poprawne drzewo
\subsubsection{} %4-4(j)
\begin{figure}[h]
	\begin{center}
		\includegraphics{fig04.6}
	\caption{Drzewo rekursji $T(n)=\sqrt{n}\;T(\!\sqrt{n})+n$} \label{fig:4-4j}
	\end{center}
\end{figure}

\subsection{} %4-5

\subsubsection{} %4-5(a)
\begin{eqnarray*}
	\mathcal{F}(z) &=& z+z\mathcal{F}(z)+z^2\mathcal{F}(z) \\
	&=& z\biggl(1+\sum_{i=0}^\infty F_iz^i+\sum_{i=0}^\infty F_iz^{i+1}\biggr) \\
	&=& z\biggl(1+\sum_{i=1}^\infty F_iz^i+\sum_{i=1}^\infty F_{i-1}z^i\biggr) \\
	&=& z\biggl(1+\sum_{i=1}^\infty (F_i+F_{i-1})z^i\biggr) \\
	&=& z\biggl(1+\sum_{i=1}^\infty F_{i+1}z^i\biggr) \\
	&=& z\sum_{i=0}^\infty F_{i+1}z^i \\
	&=& \sum_{i=0}^\infty F_{i+1}z^{i+1} \\
	&=& \sum_{i=0}^\infty F_iz^i,
\end{eqnarray*}
co zgadza się z definicją $\mathcal{F}(z)$.

\subsubsection{} %4-5(b)
Z tożsamości z poprzedniego punktu wynika pierwsza równość:
\begin{eqnarray}
	\mathcal{F}(z) &=& z+z\mathcal{F}(z)+z^2\mathcal{F}(z)\nonumber \\
	(1-z-z^2)\mathcal{F}(z) &=& z\nonumber \\
	\mathcal{F}(z) &=& \frac{z}{1-z-z^2}.\label{eq-4-5b_1}
\end{eqnarray}
Mianownik prawej strony~(\ref{eq-4-5b_1}) jest trójmianem kwadratowym, które można zapisać w równoważnej postaci:
\begin{equation}
	1-z-z^2 \equiv -(z+\phi)\bigl(z+\widehat\phi\bigr).\label{eq-4-5b_2}
\end{equation}
Trójmian~(\ref{eq-4-5b_2}) przyjmuje wartość 0 dla $z=-\phi$ lub $z=-\widehat\phi$. Ponieważ zachodzi ciekawa własność $\phi\cdot\widehat\phi=-1$, zatem można zapisać trójmian w postaci $(1-\phi z)\bigl(1-\widehat\phi z\bigr)$, skąd wynika druga równość.

Ostatnią z nich dowodzimy dokonując pewnych przekształceń:
\[
	\frac{1}{1-\phi z}-\frac{1}{1-\widehat\phi z} = \frac{1-\widehat\phi z-1+\phi z}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{z\bigl(\phi-\widehat\phi\bigr)}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{z\sqrt{5}}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)}
\]
i zauważając, że zachodzi
\[
	\frac{z}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{1}{\sqrt{5}}\cdot\frac{z\sqrt{5}}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{1}{\sqrt{5}}\left(\frac{1}{1-\phi z}-\frac{1}{1-\widehat\phi z}\right).
\]

\subsubsection{} %4-5(c)
Tezę otrzymujemy natychmiast, jeśli w definicji $\mathcal{F}(z)$ podstawimy $F_i=\frac{\phi^i-\widehat\phi^i}{\sqrt{5}}$, co wykazano w zad.~3.2-6.

\subsubsection{} %4-5(d)
Ponieważ $\bigl|\widehat\phi\bigr|<1$, to prawdą jest, że $\phi^i<1$ dla $i>0$ oraz $\frac{\widehat\phi^i}{\sqrt{5}}<1$. Stąd
\[
	F_i = \frac{\phi^i-\widehat\phi^i}{\sqrt{5}} = \frac{\phi^i}{\sqrt{5}}-\frac{\widehat\phi^i}{\sqrt{5}} < \frac{\phi^i}{\sqrt{5}}-1.
\]
Podstawiając $F_i$ za $\lceil x\rceil$ oraz $\frac{\phi^i}{\sqrt{5}}$ za $x$ we wzorze~(3.5), dowodzimy, że
\[
	F_i = \left\lceil\frac{\phi^i}{\sqrt{5}}\right\rceil.
\]

\subsubsection{} %4-5(e)
Tożsamość została udowodniona w zad.~3.2-7.

\subsection{} %4-6

\subsubsection{} %4-6(a)
Załóżmy, że w zbiorze układów jest więcej niż $n/2$ dobrych układów i potraktujmy wynik każdego testu dwóch układów jako parę $(r_1,r_2)\in\{D,Z\}^2$. Pierwszy element pary jest stwierdzeniem pierwszego układu o drugim, a drugi element -- drugiego o pierwszym. $D$ oznacza pozytywny wynik testu, a~$Z$ -- negatywny. Możliwe jest uzyskanie jednego z czterech wyników:
\begin{itemize}
	\item $(D,D)$ -- implikuje, że oba układy są dobre albo oba są złe,
	\item $(D,Z)$ -- zachodzi tylko wtedy, gdy pierwszy z układów jest zły,
	\item $(Z,D)$ -- zachodzi tylko wtedy, gdy drugi z układów jest zły,
	\item $(Z,Z)$ -- co najmniej jeden z układów jest zły.
\end{itemize}
Ponieważ drugi i trzeci wynik natychmiast determinują nam naturę jednego układu, to załóżmy, że podczas testowania nie uzyskaliśmy żadnego z nich, możemy bowiem odrzucić wyznaczone złe układy z dalszej analizy.

Rozpatrzmy graf $G=(V,E)$, w którym $V$ jest zbiorem układów, a $(u,v)\in E$ wtedy i tylko wtedy, gdy podczas testowania układów $u$ i $v$ otrzymano wynik $(D,D)$. Oznacza to, że każde sąsiednie wierzchołki w tym grafie muszą być albo jednocześnie dobre, albo jednocześnie złe. Zauważmy że jeśli relacja $R$, której reprezentacją jest graf $G$ nie jest przechodnia, to możemy wtedy wskazać pewne złe układy -- co najmniej jeden z wierzchołków nie będących w relacji jest zły, a to z kolei indukuje kolejne złe, które są z nim w relacji. Niech zatem $R$ będzie przechodnia. Jest też oczywiście zwrotna i symetryczna, a jako taka dzieli zbiór $V$ na klasy abstrakcji. To sprowadza nas do badania grafów będących sumami podgrafów pełnych (klik), jako że każda klasa abstrakcji relacji $R$ jest pewną kliką. Każdy z układów dowolnej kliki jest jednocześnie dobry lub jednocześnie zły z każdym innym układem ze swojej kliki, podczas gdy między klikami nie istnieje żadna krawędź, więc co najmniej jedna z dwóch badanych klik musi zawierać wyłącznie złe układy.

Zauważmy, że możemy rozważać $G$ jako hipergraf pełny $H=(V_H,E_H)$, gdzie $V_H$ jest zbiorem klik. Ponieważ dla każdej pary $(U,V)\in V_H^2$ co najmniej jedna z klik $U$ lub $V$ zawiera złe elementy, to złymi są elementy należące do klik z $V_H$ z wyjątkiem jednej. Układy z tej kliki są dobre, co gwarantuje nam założenie, że zawsze będzie istnieć w $V_H$ taka klika, która zawiera więcej niż $n/2$ układów. Pozostawiając ją jako dobrą, a oznaczając inne jako złe, będziemy mieć wyznaczone jednoznacznie wszystkie dobre układy spośród $n$ badanych. Istnienie większej ilości złych układów nie pozwoli na wyznaczenie ``największego'' elementu z $V_H$.

\subsubsection{} %4-6(b)
Utwórzmy ciąg układów $u_1,u_2,\dots,u_n$ i wykonajmy $\lfloor n/2\rfloor$ testów -- między układami $u_1$ i $u_2$, $u_2$ i $u_3$, itd. aż do $u_{\lfloor n/2\rfloor}$ i $u_{\lfloor n/2\rfloor+1}$. Pozostałe układy pozostaną nieprzetestowane w danym etapie. Tak jak w poprzednim punkcie zakładamy, że nie możemy dostać wyniku $(D,Z)$ lub $(Z,D)$.

Rozważmy ciągi układów, dla których zaszło $(D,D)$ między każdą parą sąsiadów. 

\subsubsection{} %4-6(c)
Następująca rekurencja opisuje liczbę testów koniecznych do znalezienia jednego dobrego układu:
\[
	T(n) =
	\begin{cases}
		T(\lfloor n/2\rfloor) + \lfloor n/2\rfloor, & \hbox{dla }n>2, \\
		\Theta(1), & \hbox{dla }1\le n\le 2.
	\end{cases}
\]
Jej rozwiązaniem jest $T(n)=\Theta(n)$.

Ponieważ w poprzednim punkcie znaleźliśmy dobry układ $u$, to wykorzystajmy go do znalezienia kolejnych. Testujemy tenże układ z pozostałymi $n-1$. Wynikiem testu $u$ z pewnym innym układem $v$, nie może być $(D,Z)$, a więc mamy trzy sytuacje. Jeśli otrzymamy $(D,D)$, to oznacza to, że oba układy są tak samo dobre, a więc $v$ również jest dobry. Uzyskując wynik $(Z,D)$, mamy natychmiast, że $v$ jest zły, podobnie w wypadku, gdy wynikiem testu będzie $(Z,Z)$ -- wtedy co najmniej jeden z testowanych układów jest zły, ale nie może nim być $u$. Wynika stąd, że sprawdzając $u$ z~$n-1$ innymi układami, wykonamy $n-1$ testów, a ponieważ stwierdziliśmy, że $u$ jest dobre za pomocą $\Theta(n)$ testów, to znalezienie wszystkich dobrych układów można wykonać wykonując również $\Theta(n)$ testów.

\subsection{} %4-7 %poprawic, dokonczyc

\subsubsection{} %4-7(a)
\noindent\emph{Dowód $\Rightarrow$.} Dla tablicy Monge'a $A$ spełniona jest nierówność
\[
	A[i,j]+A[k,l] \le A[i,l]+A[k,j], \quad\hbox{dla }1\le i<k\le m\hbox{ oraz }1\le j<l\le n.
\]
W szczególności zaś może być $k=i+1$ oraz $l=j+1$, zatem implikacja zachodzi.\\

\noindent\emph{Dowód $\Leftarrow$.}

\subsubsection{} %4-7(b)
Korzystając z poprzedniego punktu można pokazać, że nierówność
\[
	A[1,2]+A[2,3] \le A[1,3]+A[2,2]
\]
jest fałszywa, przez co zaburza właściwość tablicy Monge'a. By przywrócić własność, można zamienić np. $A[1,3]$ na 25.

\subsubsection{} %4-7(c)
Korzystając z nierówności
\begin{equation}
	A[i,j]+A[i+1,j+r] \le A[i,j+r]+A[i+1,j]\label{eq-4-7c}
\end{equation}
dla $r>0$, wnioskujemy w następujący sposób.

Znajdujemy w pierwszym wierszu tablicy $A$ pierwsze minimum z lewej strony, które oznaczamy przez $\mu$. Indeksem $\mu$ jest oczywiście $f(1)$. Stwierdzamy teraz, że dla $1\le j<f(1)$ spełnione jest~(\ref{eq-4-7c}), czyli $A[1,j]+A[2,f(1)]\le\mu+A[2,j]$. Z drugiej strony, $\mu<A[1,j]$ dla każdego $1\le j<f(1)$. Dodając obie nierówności stronami, otrzymujemy $A[2,f(1)]<A[2,j]$, a to oznacza, że albo $A[2,f(1)]$ jest pierwszym minimum z lewej strony wiersza 2 albo mniejszy od niego element jest w tym wierszu na pewnym indeksie $f(2)>f(1)$. W obu przypadkach zachodzi jednak $f(1)\le f(2)$.

Dowód kolejnych nierówności przebiega analogicznie, skąd dostajemy tezę.

%sprawdzic czy mozna napisac (i+1)-szego
\subsubsection{} %4-7(d)
Korzystając z twierdzenia z poprzedniego punktu, szukając minimum wiersza $i$-tego, sprawdzamy indeksy minimów wierszy $(i-1)$-szego oraz $(i+1)$-szego. Szukane minimum znajduje się pomiędzy tymi indeksami. Sprawdzamy dzięki temu w pesymistycznym przypadku $m+n$ komórek wierszy nieparzystych, więc czas działania wynosi $O(m+n)$.

\subsubsection{} %4-7(e)
Korzystając z oszacowania z poprzedniego punktu oraz tego, że na ostatnim poziomie rekursji wyznaczenie minimum jednego wiersza tablicy wymaga sprawdzenia co najwyżej $O(n)$ komórek, formułujemy następującą rekurencję:
\[
	T(m,n) =
	\begin{cases}
		T(\lfloor m/2\rfloor,n)+O(m+n), & \hbox{dla }m>2, \\
		O(n), & \hbox{dla }m\le2.
	\end{cases}
\]
Na $i$-tym poziomie, rekurencja wprowadza koszt równy $O(m/2^i+n)$. Łatwo zauważyć, że jest $\lfloor\lg m\rfloor$ poziomów, a zatem całkowity koszt wynosi
\begin{eqnarray*}
	T(n) &=& \sum_{i=0}^{\lfloor\lg m\rfloor-1}O\left(\frac{m}{2^i}+n\right)+O(n) \\
	&=& O\biggl(\sum_{i=0}^{\lfloor\lg m\rfloor-1}\left(\frac{m}{2^i}\right)\biggr)+O(n\lg m) \\
	&=& O(m+n\lg m).
\end{eqnarray*}
