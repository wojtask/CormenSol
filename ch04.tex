\chapter{Rekurencje}

\subchapter{Metoda podstawiania}

\exercise %4.1-1
Niech $c>0$ będzie stałą. Przyjmujemy następujące założenie:
\[
	T(\lceil n/2\rceil) \le c\lg(\lceil n/2\rceil).
\]
Na jego podstawie oraz z~wzoru~(3.3) otrzymujemy
\begin{align*}
	T(n) &\le c\lg(\lceil n/2\rceil)+1 \\
	&< c\lg(n/2+1)+1 \\
	&\le c\lg(3n/4)+1 \\
	&= c\lg n+c\lg(3/4)+1 \\
	&\le c\lg n,
\end{align*}
przy czym ostatnia nierówność wymaga, aby $c\ge\log_{4/3}2$. Ponadto w~wyprowadzeniu założono, że $n\ge4$.

Niech $T(1)=1$, jednak nie można dobrać stałej $c$ tak, aby $T(1)\le c\lg1=0$. Dla $n>2$ rekurencja nie zależy bezpośrednio od $T(1)$, więc przyjmijmy $T(2)=2$ za podstawę indukcji, ponieważ dla dowolnego $c\ge2$ zachodzi $T(2)\le c\lg 2=c$. Mamy więc $T(n)=O(\lg n)$.

\exercise %4.1-2
Przyjmijmy założenie, że
\[
	T(\lfloor n/2\rfloor) \ge c\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)
\]
dla pewnej dodatniej stałej~$c$. Korzystając z~wzoru~(3.3), mamy:
\begin{align*}
	T(n) &\ge 2c\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)+n \\
	&> 2c(n/2-1)\lg(n/4)+n \\
	&= 2c((n/2)\lg n-\lg n-n+2)+n \\
	&= cn\lg n-2c\lg n-2cn+4c+n \\
	&> cn\lg n-2c(n+\lg n)+n \\
	&\ge cn\lg n,
\end{align*}
Ostatni krok uzasadniamy, rozwiązując nierówność $-2c(n+\lg n)+n\ge0$ ze względu na $c$:
\[
	c \le \frac{n}{2(n+\lg n)} \le \frac{n}{2n} = \frac{1}{2},
\]
a~zatem wybierając dowolne $0<c\le1/2$, spełniamy ostatni krok wyprowadzenia. Można przyjąć $T(1)=1$ za podstawę indukcji, bo $T(1)\ge c\lg1=0$. Wykazaliśmy, że $T(n)=\Omega(n\lg n)$, a~zatem na mocy tw.~3.1 mamy $T(n)=\Theta(n\lg n)$.

\exercise %4.1-3
Przyjmijmy założenie, że $T(\lfloor n/2\rfloor)\le c\lfloor n/2\rfloor^2$ dla pewnej stałej $c>0$, czyli chcemy udowodnić, że $T(n)=O(n^2)$. Mamy zatem
\[
	T(n) \le 2c\lfloor n/2\rfloor^2+n \le 2cn^2\!/4 + n = cn^2\!/2+n \le cn^2,
\]
co jest prawdą, jeśli przyjmiemy $c\ge2$. Widać teraz, że z~mocniejszym założeniem warunek brzegowy $T(1)=1$ może stanowić podstawę indukcji, bo $T(1)\le c\cdot1^2=c$.

\exercise %4.1-4
Rekurencję~(4.2) można przedstawić w~alternatywny sposób:
\[
	T(n) =
	\begin{cases}
		d_1, & \text{jeśli $n=1$}, \\
		T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+d_2n, & \text{jeśli $n>1$},
	\end{cases}
\]
dla pewnych stałych $d_1$,~$d_2>0$. Dla innych stałych $c_1$,~$c_2>0$ przyjmujemy założenia
\[
	T(\lfloor n/2\rfloor) \ge c_1\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor) \quad\text{oraz}\quad T(\lceil n/2\rceil) \le c_2\lceil n/2\rceil\lg(\lceil n/2\rceil).
\]
W~przypadku dolnego oszacowania mamy:
\begin{align*}
	T(n) &\ge 2T(\lfloor n/2\rfloor)+d_2n \\
	&\ge 2c_1\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)+d_2n \\
	&> 2c_1(n/2-1)\lg(n/4)+d_2n \\
	&= c_1n\lg n-2c_1n-2c_1\!\lg(n/4)+d_2n \\
	&\ge c_1n\lg n,
\end{align*}
ponieważ zachodzi $\lfloor n/2\rfloor>n/2-1$ i~$\lfloor n/2\rfloor\ge n/4$ oraz można tak dobrać stałą $c_1$, aby prawdziwa była ostatnia nierówność powyższego wyprowadzenia. Po podstawieniu $c_1=d_2/4$ sprowadza się ona do $n\ge\lg(n/4)$, co jest prawdą dla wszystkich $n$ dodatnich. Podstawę indukcji stanowi $T(1)=d_1$, gdyż $T(1)\ge d_2/4\cdot 1\cdot\lg1=0$, a~zatem $T(n)=\Omega(n\lg n)$.

Wykorzystując nierówność $\lceil n/2\rceil<n/2+1$ z~wzoru~(3.3), dowodzimy górnego oszacowania:
\begin{align*}
	T(n) &\le 2T(\lceil n/2\rceil)+d_2n \\
	&\le 2c_2\lceil n/2\rceil\lg(\lceil n/2\rceil)+d_2n \\
	&< 2c_2(n/2+1)\lg\frac{n\lceil n/2\rceil}{n}+d_2n \\
	&\le c_2n\lg n+c_2(n+2)\lg\frac{\lceil n/2\rceil}{n}+2c_2\lg n+d_2n \\
	&\le c_2n\lg n.
\end{align*}
W~ostatniej nierówności skorzystano z~tego, że dla $n\ge2$ wyrażenie $\lg\frac{\lceil n/2\rceil}{n}$ jest ujemne, a~zatem dobierając odpowiednio duże $c_2$, można uzasadnić nierówność, gdyż funkcja liniowa rośnie szybciej od logarytmicznej. Dokładniej, okazuje się, że przyjęcie $c_2\ge10d_2$ wystarcza, aby spełnić nierówność dla $n\ge4$.

Ponieważ dla $n\ge4$ rekurencja nie zależy bezpośrednio od $T(1)$, to za podstawę indukcji należy przyjąć $T(2)=2d_1+2d_2$ oraz $T(3)=3d_1+5d_2$. Można sprawdzić, że otrzymane oszacowanie dla nich zachodzi, o~ile $d_1$ jest dostatecznie małe. W~przeciwnym przypadku górne oszacowanie może nie być wystarczające, jednak zwiększenie $c_2$ pozwala na dowolne ograniczenie rekurencji od góry w~zależności od wartości stałych $d_1$ i~$d_2$. Niezależnie od ich doboru oszacowaniem górnym rekurencji $T(n)$ jest $O(n\lg n)$, co na mocy wcześniejszego wyniku dolnego oszacowania implikuje $T(n)=\Theta(n\lg n)$.

\exercise %4.1-5
Wykorzystując założenie
\[
	T(\lfloor n/2\rfloor+17) \le c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)
\]
dla pewnej stałej $c>0$, otrzymujemy:
\begin{align*}
	T(n) &\le 2c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)+n \\
	&\le 2c(n/2+17)\lg(n/2+17)+n \\
	&\le c(n+34)\lg(11n/20)+n \\
	&< cn\lg n+cn\lg(11/20)+34c\lg n+n \\
	&\le cn\lg n,
\end{align*}
co zachodzi, o~ile $n/2+17\le 11n/20$, skąd $n\ge340$ oraz
\[
	cn\lg(11/20)+34c\lg n+n \le 0.
\]
Badając ostatnią nierówność, można dojść do rezultatu, że przyjęcie $c=47$ wystarcza, aby spełnić nierówność dla wszystkich $n\ge n_0$, gdzie $n_0=340$.

Zauważmy, że stosowanie równania $T(n)=2T(\lfloor n/2\rfloor+17)+n$ dla $n\le35$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n\le35$ i~niech stanowi to przypadek brzegowy rekurencji. Za podstawę indukcji musimy jednak przyjąć wszystkie $T(i)$, gdzie $187\le i\le339$. Wykorzystując program komputerowy, można wykazać, że dla $c=47$ wartości te spełniają oszacowanie, a~zatem $T(n)=O(n\lg n)$.

Analiza rekurencji dla każdej innej stałej w~miejscu~17 przebiega analogicznie, zmianie ulegają natomiast wartości $n_0$ i~$c$, jednak w~każdym takim przypadku rekurencja jest klasy $O(n\lg n)$.

\exercise %4.1-6
Przyjmijmy, że $n=2^m$, skąd $m=\lg n$. Rekurencja przyjmuje teraz postać
\[
	T(2^m) = 2T(2^{m/2})+1.
\]
Z~kolei podstawiając $S(m)$ za $T(2^m)$, dostajemy nową rekurencję
\[
	S(m) = 2S(m/2)+1,
\]
dla której udowodnimy rozwiązanie $O(\lg m)$.

Ponieważ nie dbamy o~to, czy $m/2$ jest całkowite, to możemy sprowadzić rekurencję do postaci $S(m)=S(\lfloor m/2\rfloor)+S(\lceil m/2\rceil)+1$, o~której wiemy, że jej rozwiązanie wynosi $O(m)$.

Aby uzyskać oszacowanie dokładne pozostaje udowodnić, że $S(m)=\Omega(m)$. Przyjmujemy zatem założenie, że $S(m/2)\ge c(m/2)$ dla $c>0$. Na jego podstawie otrzymujemy:
\[
	S(m) \ge 2cm/2+1 = cm+1 > cm,
\]
co zachodzi dla dowolnej wartości $c$. Przyjęcie $S(1)=1$ na podstawę indukcji wystarcza, bo warunek $S(1)\ge c$ spełnia każde $c\le1$, a~zatem $S(m)=\Omega(m)$.

Stosując tw.~3.1, mamy $S(m)=\Theta(m)$, więc wracając do oryginalnej rekurencji i~starej zmiennej, dostajemy $T(n)=T(2^m)=S(m)=\Theta(m)=\Theta(\lg n)$.

\subchapter{Metoda drzewa rekursji}

\exercise %4.2-1
Dokonajmy pewnego uproszczenia, opuszczając podłogę w~rekurencji $T(n)$ i~rozważając zależność $T'(n)=3T'(n/2)+n$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.1}
	\end{center}
	\caption{Drzewo rekursji $T'(n)=3T'(n/2)+n$} \label{fig:4.2-1}
\end{figure}
W~drzewie z~rys.~\ref{fig:4.2-1} jest $\lg n+1$ poziomów, a~na \twoparts{$i$}{tym} z~nich znajduje się $3^i$ węzłów, zatem jest $n^{\lg3}$ liści. Koszt węzła na poziomie $i$ wynosi $n/2^i$, skąd wynika, że łączny koszt wszystkich węzłów na \twoparts{$i$}{tej} głębokości jest równy $(3/2)^in$. Ponieważ liście wnoszą stały koszt, czyli $T'(1)=\Theta(1)$, to ostatni poziom ma wartość $\Theta(n^{\lg3})$. Na podstawie tych wartości rozwiązujemy rekurencję:
\begin{align*}
	T'(n) &= n+\frac{3}{2}n+\left(\frac{3}{2}\right)^2n+\cdots+\left(\frac{3}{2}\right)^{\lg n-1}n+\Theta(n^{\lg 3}) \\
	&= \sum_{i=0}^{\lg n-1}\left(\frac{3}{2}\right)^in+\Theta(n^{\lg 3}) \\
	&= \frac{\left(\frac{3}{2}\right)^{\lg n}-1}{\frac{3}{2}-1}\cdot n+\Theta(n^{\lg 3}) \\[1mm]
	&= 2n(n^{\lg 3-1}-1)+\Theta(n^{\lg 3}) \\
	&= O(n^{\lg 3}).
\end{align*}

Wykorzystując otrzymany wynik, przyjmujemy założenie, że $T(\lfloor n/2\rfloor)\le c(\lfloor n/2\rfloor)^{\lg 3}$ dla pewnej stałej $c>0$ i~dowodzimy oszacowania dla oryginalnej rekurencji metodą przez podstawianie:
\begin{align*}
	T(n) &\le 3c(\lfloor n/2\rfloor)^{\lg 3}+n \\
	&\le 3c(n/2)^{\lg 3}+n \\
	&= cn^{\lg 3}+n.
\end{align*}
Nie możemy jednak na podstawie tego wyniku wywnioskować szukanego oszacowania. Wzmocnijmy zatem nasze założenie, niech
\[
	T(\lfloor n/2\rfloor) \le c(\lfloor n/2\rfloor)^{\lg 3}-b\lfloor n/2\rfloor,
\]
dla nowej stałej $b\ge0$. Korzystając z~wzoru~(3.3), mamy teraz
\begin{align*}
	T(n) &\le 3c(\lfloor n/2\rfloor)^{\lg 3}-3b\lfloor n/2\rfloor+n \\
	&< 3c(n/2)^{\lg 3}-3b(n/2-1)+n \\
	&= cn^{\lg 3}-3bn/2+3b+n \\
	&\le cn^{\lg 3}-bn,
\end{align*}
co zachodzi dla $b\ge14$ oraz $n\ge7$. Przyjmujemy $T(1)=1$ na warunek brzegowy rekurencji oraz wszystkie $T(i)$, gdzie $1\le i\le6$, na podstawę indukcji, ponieważ z~braku dodatkowych ograniczeń na $c$ można dobrać dla niego odpowiednią wartość tak, aby udowodnione oszacowania zachodziły dla $T(i)$. To kończy dowód, a~więc górnym oszacowaniem rekurencji $T(n)$ jest $O(n^{\lg3})$.

\exercise %4.2-2
Drzewo rekursji $T(n)$ nie jest pełnym drzewem binarnym. Najkrótszą ścieżką od korzenia do liścia jest $n\to n/3\to n/9\to\dots\to n/3^i\to\dots\to1$. Liść tej gałęzi znajduje się na poziomie $i=\log_3n$. Ponieważ pełne drzewo binarne o~wysokości $\log_3n+1$ wnosi koszt nie większy niż drzewo rekurencji $T(n)$, to zachodzi $T(n)\ge cn\log_3n$ dla pewnego $c>0$, a~stąd $T(n)=\Omega(n\lg n)$.

\exercise %4.2-3
Dla uproszczenia pomijamy branie części całkowitych.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.2}
	\end{center}
	\caption{Drzewo rekursji $T(n)=4T(n/2)+cn$} \label{fig:4.2-3}
\end{figure}
W~drzewie rekursji z~rys.~\ref{fig:4.2-3} na \twoparts{$i$}{tym} poziomie jest $4^i$ węzłów, z~których każdy wnosi koszt równy $cn/2^i$. Stąd kosztem całego poziomu jest $2^icn$. Współczynnik przy $n$ w~koszcie węzła maleje dwukrotnie wraz ze wzrostem poziomu, więc wysokością drzewa jest $\lg n$. Wnioskujemy zatem, że liczbą liści w~tym drzewie jest $4^{\lg n}=n^2$ i~że koszt ostatniego poziomu wynosi $\Theta(n^2)$. Sumując koszty z~każdego poziomu, otrzymujemy:
\begin{align*}
	T(n) &= cn+2cn+2^2cn+\cdots+2^{\lg n-1}cn+\Theta(n^2) \\
	&= \sum_{i=0}^{\lg n-1}2^icn+\Theta(n^2) \\
	&= (2^{\lg n}-1)cn+\Theta(n^2) \\
	&= (n-1)cn+\Theta(n^2) \\
	&= \Theta(n^2).
\end{align*}

Sprawdzamy otrzymany wynik, wykorzystując do tego celu metodę podstawiania. Badamy najpierw oszacowanie dolne $T(n)$, przyjmując założenie
\[
	T(n/2) \ge c_1(n/2)^2,
\]
dla pewnej stałej $c_1>0$. Stąd
\[
	T(n) \ge c_1n^2+cn \ge c_1n^2,
\]
bo $c>0$. Podstawą indukcji jest $T(1)=1$, które spełnia oszacowanie dla $c_1\le1$, a~więc prawdą jest, że $T(n)=\Omega(n^2)$.

By udowodnić dodatkowo, że $T(n)=O(n^2)$, możemy przyjąć takie samo założenie indukcyjne ale z~przeciwnym znakiem nierówności, jednak nie uzyskamy szukanego ograniczenia górnego na $T(n)$. Przyjmijmy zatem, że dla stałych $c_2>0$ oraz $c_3\ge0$ zachodzi mocniejszy warunek
\[
	T(n/2) \le c_2(n/2)^2-c_3(n/2).
\]
Dowodzimy:
\[
	T(n) \le 4(c_2n^2\!/4-c_3n/2)+cn = c_2n^2-2c_3n+cn \le c_2n^2-c_3n,
\]
co jest prawdą, jeśli przyjmiemy $c_3\ge c$. Aby móc potraktować $T(1)=1$ jako podstawę indukcji, musimy nałożyć na stałe dodatkowe ograniczenie, $c_3\le c_2-1$.

Dzięki metodzie podstawiania oraz z~tw.~3.1 wykazaliśmy, że $T(n)=\Theta(n^2)$.
\medskip %korekcja underfull vboxa

\exercise %4.2-4
Dla uproszczenia przyjmijmy, że $T(n)=cn$ w~przypadku, gdy $n\le a$, czyli dla dostatecznie małego $n$ rekurencja przyjmuje wartość stałą.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.3}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n-a)+T(a)+cn$} \label{fig:4.2-4}
\end{figure}
Wysokość drzewa rekursji $T(n)$ z~rys.~\ref{fig:4.2-4} wynosi $\lfloor n/a\rfloor$. Koszt wnoszony przez \twoparts{$i$}{ty} poziom (oprócz zerowego i~ostatniego) wynosi $c(n-a(i-1))$. Na ostatnim poziomie jest tylko jeden liść, który kosztuje $\Theta(1)$. Mamy:
\begin{align*}
	T(n) &= cn+\sum_{i=1}^{\lfloor n/a\rfloor-1}c(n-a(i-1))+\Theta(1) \\
	&= cn+c\sum_{i=0}^{\lfloor n/a\rfloor-2}(n-ai)+\Theta(1) \\
	&= cn+cn\sum_{i=0}^{\lfloor n/a\rfloor-2}1-ca\sum_{i=0}^{\lfloor n/a\rfloor-2}i+\Theta(1) \\
	&= cn+cn(\lfloor n/a\rfloor-1)-ca\frac{(\lfloor n/a\rfloor-2)(\lfloor n/a\rfloor-1)}{2}+\Theta(1) \\[2mm]
	&= \Theta(n^2).
\end{align*}

\exercise %4.2-5
Zauważmy, że drzewo rekurencji $T(n)$ na rys.~\ref{fig:4.2-5} dla parametru $\alpha$ jest symetryczne do drzewa $T(n)$ przy parametrze $1-\alpha$, przyjmijmy więc, że $0<\alpha\le1/2$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.4}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(\alpha n)+T((1-\alpha)n)+cn$, gdzie $0<\alpha\le1/2$} \label{fig:4.2-5}
\end{figure}

Wyznaczmy najpierw oszacowanie dolne rekurencji. Na \twoparts{$i$}{tym} poziomie drzewa najmniejszy koszt wnoszą węzły o~wartościach $c\alpha^in$, a~więc elementy ze skrajnie lewej gałęzi. Sprawdzając kiedy osiągną one wartość stałą $d>0$, wyznaczamy najgłębszy poziom o~komplecie węzłów. Niższe poziomy są coraz mniej liczne, zatem sumując koszt węzłów drzewa $T(n)$ od korzenia aż do tego poziomu, uzyskujemy oszacowanie dolne rekurencji. Na pewnej głębokości $h$ będzie $c\alpha^hn=d$, skąd otrzymujemy $h=\log_{1/\alpha}(cn/d)$. Ponieważ $\alpha$ jest stałe, to $h=\Theta(\lg n)$. Każdy poziom o~głębokości nieprzekraczającej $h$ wnosi koszt $cn$, więc oszacowaniem dolnym rekurencji jest $T(n)=\Omega(cn(h+1))=\Omega(n\lg n)$.

Badając teraz skrajnie prawą gałąź, której elementy wnoszą największy koszt wśród wszystkich poziomów, możemy dojść do oszacowania górnego dla $T(n)$. Na głębokości $H$ równej wysokości drzewa mamy $c(1-\alpha)^Hn=d$, skąd $H=\log_{1/(1-\alpha)}(cn/d)$. Także w~tym przypadku mamy $H=\Theta(\lg n)$, a~więc $T(n)=O(cn(H+1))=O(n\lg n)$, skąd asymptotycznie dokładnym rozwiązaniem rekurencji jest $\Theta(n\lg n)$.

\subchapter{Metoda rekurencji uniwersalnej}

\note{Zarówno w~wersji oryginalnej jak i~w~tłumaczeniu treści twierdzenia~4.1 znajduje się poważny brak, który uniemożliwia m.in.\ rozwiązanie \zad{4.4-3}. Dla stosowanej tam stałej\/ $c$ podany jest tylko warunek, aby była ona mniejsza od\/ $1$, podczas gdy poprawnym zakresem dla niej powinien być zbiór\/ $(0,1)$.}

\exercise %4.3-1

\subexercise
W~równaniu~(4.5) przyjmujemy $a=4$ i~$b=2$ oraz $f(n)=n$. Ponieważ $f(n)=O(n^{2-\epsilon})$ dla $0<\epsilon\le1$, to z~tw.~o~rekurencji uniwersalnej mamy $T(n)=\Theta(n^2)$.

\subexercise
Postępując analogicznie jak w~poprzednim punkcie, mamy te same wartości $a$ i~$b$, ale teraz $f(n)=n^2$. Z~tego, że $f(n)=\Theta(n^2)$ dostajemy $T(n)=\Theta(n^2\lg n)$.

\subexercise
Dla tych samych $a$ i~$b$ ale $f(n)=n^3$, mamy $f(n)=\Omega(n^{2+\epsilon})$ dla $0<\epsilon\le1$ oraz
\[
	4f(n/2) = 4n^3\!/8 = n^3\!/2 = f(n)/2 \le cf(n),
\]
o~ile $c\ge1/2$, a~zatem warunek regularności jest spełniony i~$T(n)=\Theta(n^3)$.

\exercise %4.3-2
Rozwiążmy $T(n)$, korzystając z~metody rekurencji uniwersalnej. Ponieważ $n^{\log_ba}=n^{\lg7}$ oraz $f(n)=n^2=O(n^{\lg7-\epsilon})$ dla $0<\epsilon\le\lg7-2$, to zachodzi $T(n)=\Theta(n^{\lg7})$.

Pozostaje teraz zbadanie nierówności $T'(n)<T(n)$ w~zależności od parametru $a$, bo w~rekurencji $T'(n)$ jest $n^{\log_ba}=n^{\log_4a}$ oraz $f(n)=n^2$. Załóżmy, że $f(n)=O(n^{\log_4a-\epsilon})$, co jest prawdą dla $a>16$ i~wtedy $T'(n)=\Theta(n^{\log_4a})$. Algorytm $A'$ jest efektywniejszy od algorytmu $A$, gdy $\log_4a<\lg7$, skąd $16<a<49$. Pozostałe przypadki tw.~4.1 można stosować, o~ile $a\le16$, ale wtedy $A'$ jest wolniejszy od $A$, zatem pomińmy ich sprawdzanie.

Największym całkowitym $a$, dla którego algorytm $A'$ jest bardziej efektywny od algorytmu $A$, jest~$a=48$.

\exercise %4.3-3
Ponieważ $a=1$ oraz $b=2$, to $n^{\log_ba}=n^0=1$ jest funkcją stałą. W~rekurencji tej $f(n)$ także jest stałe, a~więc $f(n)=\Theta(n^{\log_ba})$ i~$T(n)=\Theta(n^{\log_ba}\lg n)=\Theta(\lg n)$.

\exercise %4.3-4
Dla rekurencji $T(n)$ mamy $a=4$, $b=2$ oraz $f(n)=n^2\lg n$, a~więc $n^{\log_ba}=n^2$, ale nie istnieje takie $\epsilon>0$, że $f(n)=\Omega(n^{2+\epsilon})$. Nie można zatem zastosować w~rozwiązaniu twierdzenia o~rekurencji uniwersalnej, zatem znajdziemy asymptotyczne górne oszacowanie na $T(n)$, zgadując rozwiązanie, a~następnie dowodząc jego poprawności metodą podstawiania.

W~pierwszym wywołaniu rekurencja wnosi koszt równy $n^2\lg n$. Następnie 4~razy wywołujemy $T(n/2)$, co daje koszt
\[
	4T(n/2) = 4(n/2)^2\lg(n/2) = n^2\lg n-n^2.
\]
Kolejne poziomy wywołań kosztują
\begin{gather*}
	16T(n/4) = 16(n/4)^2\lg(n/4) = n^2\lg n-2n^2, \qquad\phantom{\text{itd.}} \\
	64T(n/8) = 64(n/8)^2\lg(n/8) = n^2\lg n-3n^2, \qquad\text{itd.}
\end{gather*}
Wnioskujemy z~otrzymanych wyników, że \twoparts{$i$}{ty} poziom wprowadza koszt równy $n^2\lg n-in^2$. Liście o~koszcie stałym znajdują się na poziomie $\lg n$ i~jest ich $4^{\lg n}=n^2$, więc dostajemy:
\begin{align*}
	T(n) &= \sum_{i=0}^{\lg n-1}(n^2\lg n-in^2)+\Theta(n^2) \\
	&= n^2\lg^2n-n^2\sum_{i=0}^{\lg n-1}i+\Theta(n^2) \\[1mm]
	&= n^2\lg^2n-\frac{n^2\lg n(\lg n-1)}{2}+\Theta(n^2) \\[1mm]
	&= O(n^2\lg^2n).
\end{align*}

Udowodnimy teraz metodą podstawiania, że otrzymane przypuszczenie jest istotnie oszacowaniem górnym dla $T(n)$. Przyjmijmy założenie
\[
	T(n/2) \le c(n/2)^2\lg^2(n/2),
\]
dla pewnej stałej $c>0$. Mamy teraz:
\begin{align*}
	T(n) &\le 4c(n/2)^2\lg^2(n/2)+n^2\lg n \\
	&= cn^2(\lg n-1)^2+n^2\lg n \\
	&= cn^2\lg^2n-2cn^2\lg n+cn^2+n^2\lg n \\
	&\le cn^2\lg^2n.
\end{align*}
Ostatnią nierówność dla wszystkich $n\ge2$ spełniamy, dobierając $c\ge1$. Przyjmujemy $T(1)=1$ za warunek brzegowy rekurencji, zaś $T(2)=8$ oraz $T(3)=4+9\lg3$ jako podstawę indukcji, ponieważ dla $n>3$ rekurencja nie zależy już bezpośrednio od $T(1)$ oraz otrzymane oszacowanie dla $T(2)$ i~$T(3)$ jest spełnione. Rozwiązaniem rekurencji $T(n)$ jest zatem $O(n^2\lg^2n)$.

\exercise %4.3-5
Przyjmując $a=1$, $b=2$ oraz $f(n)=n(2-\cos n)$, dostajemy, że $f(n)=\Omega(n^\epsilon)$ dla pewnego $0<\epsilon\le1$. Jednak dla $n=2\pi$ mamy
\[
	af(n/b) = 3\pi \quad\text{oraz}\quad f(n) = 2\pi,
\]
a~więc nierówność $af(n/b)\le cf(n)$ z~warunku regularności nie zachodzi dla żadnego $0<c<1$.

\subchapter{Dowód twierdzenia o~rekurencji uniwersalnej}

\exercise %4.4-1
Wykażemy metodą indukcji, że $n_j=\left\lceil n/b^j\right\rceil$. Z~definicji~(4.12) bezpośrednio wynika prawdziwość tego wzoru dla $j=0$. Przyjmijmy zatem, że dla $j>0$ zachodzi $n_{j-1}=\left\lceil n/b^{j-1}\right\rceil$. Wykorzystując tożsamość~(3.4), otrzymujemy
\[
	n_j = \lceil n_{j-1}/b\rceil = \left\lceil\left\lceil n/b^{j-1}\right\rceil\!/b\right\rceil = \left\lceil n/b^j\right\rceil,
\]
co należało pokazać.

\exercise %4.4-2
Zastąpmy drugi przypadek tw.~4.1 ogólniejszym warunkiem, tzn.\ jeśli $f(n)=\Theta(n^{\log_ba}\lg^kn)$ dla $k\ge0$, to zachodzi $T(n)=\Theta(n^{\log_ba}\lg^{k+1}n)$. Dla tak zmodyfikowanego twierdzenia należy przeprowadzić dowód analogicznie zmodyfikowanych lematów~4.3 i~4.4 (oznaczonych poniżej przez 4.3$'$ oraz 4.4$'$).

\begin{proof}[Dowód lematu~4.3\/$'$]
	Przy założeniu, że $f(n)=\Theta(n^{\log_ba}\lg^kn)$, otrzymujemy
	\[
		f(n/b^j)=\Theta\bigl((n/b^j)^{\log_ba}\lg^k(n/b^j)\bigr)
	\]
	i podstawiamy do wzoru~(4.7):
	\[
		g(n) = \Theta\biggl(\sum_{j=0}^{\log_bn-1}a^j\left(\frac{n}{b^j}\right)^{\log_ba}\lg^k\frac{n}{b^j}\biggr).
	\]
	Mamy dalej:
	\begin{align*}
		\sum_{j=0}^{\log_bn-1}a^j\left(\frac{n}{b^j}\right)^{\log_ba}\lg^k\frac{n}{b^j} &= n^{\log_ba}\sum_{j=0}^{\log_bn-1}\left(\frac{a}{b^{\log_ba}}\right)^j\lg^k\frac{n}{b^j} \\
		&= n^{\log_ba}\sum_{j=0}^{\log_bn-1}(\lg n-j\lg b)^k \\
		&= n^{\log_ba}\cdot\Theta(\lg^{k+1}n) \\
		&= \Theta(n^{\log_ba}\lg^{k+1}n).
	\end{align*}
	Skorzystano z~wzoru~(3.2), podstawiając $\lg n$ w~miejsce $n$, a~następnie zauważając, że
	\[
		\sum_{j=0}^{\log_bn-1}\Theta(\lg^kn) = \log_bn\cdot\Theta(\lg^kn) = \Theta(\lg^{k+1}n).
	\]
	Pokazano, że $g(n)=\Theta(n^{\log_ba}\lg^{k+1}n)$, a~więc lemat jest prawdziwy.
\end{proof}

\begin{proof}[Dowód lematu~4.4\/$'$]
	Wystarczy wykazać jedynie drugi przypadek, bo $f(n)=\Theta(n^{\log_ba}\lg^kn)$. Z~lematu~4.2:
	\[
		T(n) = \Theta(n^{\log_ba})+\Theta(n^{\log_ba}\lg^{k+1}n) = \Theta(n^{\log_ba}\lg^{k+1}n),
	\]
	co kończy dowód i~jednocześnie pokazuje prawdziwość głównego twierdzenia.
\end{proof}

\exercise %4.4-3
Warunek $af(n/b)\le cf(n)$ implikuje
\[
	f(n) \ge (a/c)f(n/b),
\]
a~zatem iterując powyższe, dostajemy
\[
	f(n) \ge (a/c)f(n/b) \ge (a/c)^2f\bigl(n/b^2\bigr) \ge \dots \ge (a/c)^if\bigl(n/b^i\bigr).
\]
Niech $i=\lceil\log_bn\rceil$, co daje
\[
	f(n) \ge (a/c)^{\lceil\log_bn\rceil}f\bigl(n/b^{\lceil\log_bn\rceil}\bigr).
\]
Na mocy nierówności~(3.3) zachodzi $\log_bn\le\lceil\log_b n\rceil<\log_bn+1$. Zauważmy, że przy zadanych ograniczeniach na $a$ i~$c$, $f$ nie może być funkcją nierosnącą, a~więc
\[
	f\bigl(n/b^{\lceil\log_bn\rceil}\bigr) > f(n/b^{\log_bn+1}) = f(1/b).
\]
Mamy następnie
\[
	f(n) > \frac{a^{\log_bn}}{c^{\log_bn+1}}f(n/b^{\log_bn+1}) = \frac{n^{\log_ba}}{cn^{\log_bc}}f(1/b) = \frac{f(1/b)}{c}\cdot\frac{n^{\log_ba}}{n^{\log_bc}}.
\]
Ponieważ $0<c<1$ oraz $b>1$, to $\log_bc<0$, przyjmijmy więc $\epsilon=-\log_bc$, skąd
\[
	f(n) > \frac{f(1/b)}{c}\cdot\frac{n^{\log_ba}}{n^{-\epsilon}} = \frac{f(1/b)}{c}\cdot n^{\log_ba+\epsilon},
\]
a~zatem $f(n)=\Omega(n^{\log_ba+\epsilon})$, co należało wykazać.

\problems

\problem{Przykłady rekurencji} %4-1
W~punktach~(a)\nobreakdash--(f) skorzystano z~twierdzenia o~rekurencji uniwersalnej.

\subproblem %4-1(a)
\[
	n^{\log_ba} = n^{\log_22} = n \quad\text{oraz}\quad f(n) = n^3 = \Omega(n^{1+\epsilon}) \quad\text{dla $0<\epsilon\le2$}
\]
Ponieważ warunek regularności jest spełniony:
\begin{align*}
	2f(n/2) &\le cf(n) \\
	2n^3\!/8 &\le cn^3 \\
	c &\ge 1/4,
\end{align*}
to stąd wnioskujemy, że $T(n)=\Theta(n^3)$.

\subproblem %4-1(b)
\[
	n^{\log_ba} = n^{\log_{10/9}1} = 1 \quad\text{oraz}\quad f(n) = n = \Omega(n^\epsilon) \quad\text{dla $0<\epsilon\le1$}
\]
Badamy warunek regularności:
\begin{align*}
	f(9n/10) &\le cf(n) \\
	9n/10 &\le cn \\
	c &\ge 9/10
\end{align*}
i~stwierdzamy, że $T(n)=\Theta(n)$.

\subproblem %4-1(c)
\[
	n^{\log_ba} = n^{\log_416} = n^2 \quad\text{oraz}\quad f(n) = n^2 = \Theta(n^2),
\]
a~stąd $T(n)=\Theta(n^2\lg n)$.

\subproblem %4-1(d)
\[
	n^{\log_ba} = n^{\log_37} \quad\text{oraz}\quad f(n) = n^2 = \Omega(n^{\log_37+\epsilon}) \quad\text{dla $0<\epsilon\le2-\log_37$}
\]
Warunek regularności zachodzi:
\begin{align*}
	7f(n/3) &\le cf(n) \\
	7n^2\!/9 &\le cn^2 \\
	c &\ge 7/9,
\end{align*}
a~zatem $T(n)=\Theta(n^2)$.

\subproblem %4-1(e)
\[
	n^{\log_ba} = n^{\lg7} \quad\text{oraz}\quad f(n) = n^2 = O(n^{\lg7-\epsilon}) \quad\text{dla $0<\epsilon\le\lg7-2$},
\]
a~stąd $T(n)=\Theta(n^{\lg7})$.

\subproblem %4-1(f)
\[
	n^{\log_ba} = n^{\log_42} = n^{1/2} \quad\text{oraz}\quad f(n) = \sqrt{n} = \Theta(n^{1/2}),
\]
a~stąd $T(n)=\Theta\bigl(\!\sqrt{n}\lg n\bigr)$.

\subproblem %4-1(g)
Zauważmy, że rekurencja rozwija się następująco:
\begin{align*}
	T(n) &= T(n-1)+n \\
	&= T(n-2)+(n-1)+n \\
	&\hspace{.5in}\vdots \\
	&= c+3+4+\cdots+n \\
	&= c+\sum_{i=3}^ni = c+\frac{n(n+1)}{2}-3,
\end{align*}
gdyż $T(2)$ jest pewną stałą $c$, a~stąd otrzymujemy, że $T(n)=\Theta(n^2)$.

\subproblem %4-1(h)
Niech $n=2^m$, skąd $m=\lg n$. Rekurencja przyjmuje teraz postać
\[
	T(2^m) = T(2^{m/2})+1.
\]
Podstawiając $S(m)$ za $T(2^m)$, otrzymujemy
\[
	S(m) = S(m/2)+1.
\]
Ponieważ rozwiązaniem ostatniej rekurencji jest $\Theta(\lg m)$ (co wykazano w~\zad{4.3-3}), to stąd mamy, że $T(n)=T(2^m)=S(m)=\Theta(\lg m)=\Theta(\lg\lg n)$.

\problem{Szukanie brakującej liczby całkowitej} %4-2
Liczby z~zakresu $0\twodots n$ reprezentowane są binarnie za pomocą $\lfloor\lg n\rfloor+1$ bitów. Można dla wygody przyjąć, że $n$ jest potęgą~2 pomniejszoną o~1. W~przeciwnym przypadku wystarczy zwiększyć $n$, aby było o~1 mniejsze od najbliższej potęgi~2 większej od $n$. Jednocześnie rozszerzamy tablicę $A$, umieszczając w~niej nowe liczby naturalne aż do nowej wartości $n$. Ta modyfikacja sprawi, że wszystkie liczby w~$A$ będą reprezentowane tą samą ilością bitów, a~rozmiar problemu urośnie co najwyżej dwukrotnie.

Badając najmniej znaczące bity liczb z~tablicy $A$, sprawdzamy ich parzystość. W~zakresie $0\twodots n$ jest $n/2$ liczb parzystych i~tyle samo nieparzystych. Jeśli wśród pobranych bitów jest więcej jedynek, to brakuje liczby parzystej, a~jeśli więcej zer, to brakująca liczba jest nieparzysta. W~zależności od przypadku odrzucamy $n/2$ liczb o~parzystości różnej od brakującej. Wsród pozostałych badamy następnie drugi najmniej znaczący bit i~analogicznie postępując, wyznaczamy $n/4$ kolejnych liczb do wyeliminowania. Po wykonaniu opisanych czynności aż do odrzucenia wszystkich liczb z~tablicy poznamy tę, której brakuje.

Czas działania zaprezentowanego tutaj algorytmu można zapisać w~postaci rekurencji $T(n)=T(n/2)+n$, której rozwiązaniem jest $O(n)$, co można łatwo pokazać przy użyciu twierdzenia~4.1. Widać teraz, że modyfikacja oryginalnego problemu (z~dowolnym $n$) wprowadziła tylko stały czynnik do czasu działania algorytmu.

\problem{Koszty przekazywania parametrów} %4-3

\subproblem %4-3(a)
Dla pierwszej strategii rekurencja przyjmuje postać z~\zad{2.3-5}, której rozwiązaniem jest $T(n)=\Theta(\lg n)$. Po przyjęciu $n=N$ dostajemy $T(N)=\Theta(\lg N)$.

W~przypadku drugiej strategii na każdym poziomie rekursji należy dodać składnik $\Theta(N)$ odpowiedzialny za przekazywanie tablicy do wywołań rekurencyjnych. Otrzymujemy zatem
\[
	T(n) = \begin{cases}
		\Theta(1), & \text{jeśli $n\le1$}, \\
		T(\lfloor n/2\rfloor)+\Theta(N), & \text{jeśli $n>1$}.
	\end{cases}
\]
Ponieważ $\Theta(N)$ jest stałe ze względu na rozmiar podproblemu $n$, to stąd rozwiązaniem powyższej rekurencji jest $T(n)=\Theta(N\lg n)$, a~więc $T(N)=\Theta(N\lg N)$.

W~ostatnim przypadku przekazujemy podtablicę o~rozmiarze równym rozmiarowi podproblemu, co prowadzi do następującej rekurencji:
\[
	T(n) = \begin{cases}
		\Theta(1), & \text{jeśli $n\le1$}, \\
		T(\lfloor n/2\rfloor)+\Theta(\lfloor n/2\rfloor), & \text{jeśli $n>1$},
	\end{cases}
\]
którą można rozwiązać przy użyciu twierdzenia o~rekurencji uniwersalnej po zignorowaniu podłóg. Otrzymujemy wynik $T(n)=\Theta(n)$, a~stąd $T(N)=\Theta(N)$.

\subproblem %4-3(b)
W~przypadku zwykłego przekazywania wskaźnika mamy oryginalną postać rekurencji, której rozwiązaniem dla $n=N$ jest $T(N)=\Theta(N\lg N)$.

Rekurencja dla drugiej strategii przedstawia się następująco:
\[
	T(n) = \begin{cases}
		\Theta(1), & \text{jeśli $n=1$}, \\
		2T(\lfloor n/2\rfloor)+\Theta(n)+2\Theta(N), & \text{jeśli $n>1$},
	\end{cases}
\]
ponieważ należy przekazać całą tablicę do obu wywołań rekurencyjnych. Na każdym poziomie dodajemy składnik rzędu $\Theta(N)$, zatem rozwiązaniem tej rekurencji jest iloczyn tego składnika i~rozwiązania rekurencji z~pierwszego przypadku, czyli $T(n)=\Theta(Nn\lg n)$, a~stąd mamy $T(N)=\Theta(N^2\lg N)$.

Ostatni przypadek wprowadza narzut w~postaci przekazywania podtablicy o~rozmiarze podproblemu do każdego wywołania rekurencyjnego, jednak czas ten jest pochłaniany przez składnik liniowy odpowiadający za czas przeznaczony na procedurę \proc{Merge}, przez co rozwiązaniem jest identyczny wynik jak w~pierwszej strategii, $T(N)=\Theta(N\lg N)$.

\problem{Więcej przykładów rekurencji} %4-4

\subproblem %4-4(a)
Wykorzystując twierdzenie o~rekurencji uniwersalnej, mamy
\[
	n^{\log_ba} = n^{\lg3} \quad\text{oraz}\quad f(n) = n\lg n = O(n^{\lg3-\epsilon}), \quad\text{dla $0<\epsilon<\lg3-1$,}
\]
a~stąd $T(n)=\Theta(n^{\lg3})$.

\subproblem %4-4(b)
Z~twierdzenia o~rekurencji uniwersalnej obliczamy
\[
	n^{\log_ba} = n^{\log_55} = n,
\]
jednak dla żadnego $\epsilon>0$ nie jest prawdą, że
\[
	f(n) = \frac{n}{\lg n} = O(n^{1-\epsilon}),
\]
ponieważ dla pewnej stałej $c>0$ i~dowolnie dużych $n$ musiałoby zachodzić
\[
	\frac{n^\epsilon}{\lg n} \le c,
\]
a~ponieważ $n^\epsilon=\omega(\lg n)$, to niezależnie od wyboru $\epsilon$ dla dużych wartości $n$ licznik będzie dowolnie większy od mianownika i~ułamka nie da się z~tego powodu ograniczyć stałą.

Skorzystajmy zatem z~innego sposobu na obliczenie $T(n)$, rozważając rodzinę rekurencji postaci
\[
	T_a(n) = \begin{cases}
		\Theta(1), & \text{jeśli $1\le n<a$}, \\
		aT_a(n/a)+n/\!\lg n, & \text{jeśli $n\ge a$},
	\end{cases}
\]
dla pewnego całkowitego $a\ge2$. Skorzystamy teraz z~techniki zamiany zmiennych, podstawiając $m=\log_an$, skąd $n=a^m$ i~otrzymując
\[
	T_a(a^m) = aT_a(a^{m-1})+\frac{a^m}{m\lg a}.
\]
Możemy teraz podstawić $S_a(m)=T_a(a^m)$, otrzymując nową rekurencję
\[
	S_a(m) = aS_a(m-1)+\frac{a^m}{m\lg a},
\]
którą rozwiązujemy następująco (po przyjęciu $S_a(0)=T_a(1)=d$ dla pewnej stałej $d>0$):
\begin{align*}
	S_a(m) &= \frac{1}{\lg a}\left(\frac{a^m}{m}+a\cdot\frac{a^{m-1}}{m-1}+a^2\cdot\frac{a^{m-2}}{m-2}+\cdots+a^{m-1}\cdot\frac{a^1}{1}+a^md\right) \\[1mm]
	&= \frac{1}{\lg a}\biggl(\sum_{k=1}^m\frac{a^m}{k}+a^md\biggr) \\[1mm]
	&= \frac{a^m(H_m+d)}{\lg a} \\[1mm]
	&= \Theta(a^m\lg m).
\end{align*}
Zamieniając z~powrotem $S_a(m)$ na $T_a(n)$, otrzymujemy rozwiązanie
\[
	T_a(n) = T_a(a^m) = S_a(m) = \Theta(a^m\lg m) = \Theta(n\lg\log_a n) = \Theta(n\lg\lg n).
\]

Stosując znalezione oszacowanie do rekurencji $T(n)\equiv T_5(n)$ z~treści zadania, dostajemy oczywiście $T(n)=\Theta(n\lg\lg n)$.

\subproblem %4-4(c)
Z~twierdzenia o~rekurencji uniwersalnej,
\[
	n^{\log_ba} = n^{\lg4} = n^2 \quad\text{oraz}\quad f(n) = n^{5/2} = \Omega(n^{2+\epsilon}), \quad\text{dla $0<\epsilon\le1/2$,}
\]
Badamy warunek regularności:
\begin{align*}
	4f(n/2) &\le cf(n) \\
	\frac{4n^{5/2}}{2^{5/2}} &\le cn^{5/2} \\
	c &\ge \frac{1}{\sqrt{2}}
\end{align*}
i~stwierdzamy, że $T(n)=\Theta(n^{5/2})$.

\subproblem %4-4(d)
Wykażemy, że stała~5 w~argumencie $T$ nie wpływa na postać rozwiązania -- rozważając rekurencję $T'(n)=3T'(n/3)+n/2$ i~rozwiązując ją za pomocą twierdzenia o~rekurencji uniwersalnej, dostajemy $T'(n)=\Theta(n\lg n)$. Udowodnimy teraz metodą podstawiania, że identyczny wynik jest rozwiązaniem rekurencji $T(n)$.

Wykorzystując założenie
\[
	T(n/3+5) \le c_1(n/3+5)\lg(n/3+5)
\]
dla pewnej stałej $c_1>0$, otrzymujemy:
\begin{align*}
	T(n) &\le 3c_1(n/3+5)\lg(n/3+5)+n/2 \\
	&\le c_1(n+15)\lg(2n/5)+n/2 \\
	&< c_1n\lg n+c_1n\lg(2/5)+15c_1\!\lg n+n/2 \\
	&\le c_1n\lg n
\end{align*}
co zachodzi, o~ile $n/3+5\le2n/5$, skąd $n\ge75$ oraz
\[
	c_1n\lg(2/5)+15c_1\!\lg n+n/2 \le 0.
\]
Przeprowadzając podobną analizę jak w~\zad{4.1-5} dostajemy, że wybór dowolnego $c_1\ge7$ spełnia nierówność dla $n\ge75$.

Analogicznie dla dolnego oszacowania przyjmując, że
\[
	T(n/3+5) \ge c_2(n/3+5)\lg(n/3+5),
\]
gdzie $c_2>0$ jest pewną stałą, dostajemy
\begin{align*}
	T(n) &\ge 3c_2(n/3+5)\lg(n/3+5)+n/2 \\
	&> 3c_2(n/3)\lg(n/3)+n/2 \\
	&= c_2n\lg n-c_2n\lg3+n/2 \\
	&\ge c_2n\lg n,
\end{align*}
gdzie ostatnia nierówność zachodzi, o~ile
\[
	-c_2n\lg3+n/2 \ge 0,
\]
co spełniamy poprzez przyjęcie $c_2\le0{,}3$.

Dowód asymptotycznie dokładnego oszacowania dla $T(n)$ kończymy, wybierając odpowiednie wartości dla podstaw obu indukcji. Zauważmy, że obliczanie wartości rekurencji z~wzoru $T(n)=3T(n/3+5)+n/2$ dla $n\le7$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n\le7$ będzie przypadkiem brzegowym rekurencji. Dowód górnego oszacowania zakładał $n\ge75$, więc podstawą obu indukcji uczyńmy $T(i)$, gdzie $30\le i\le 74$, od których bezpośrednio zależą wyrazy rekursji dla tego zakresu $n$. Oszacowania weryfikujemy programem komputerowym, uzasadniając poprawny dobór stałych $c_1$ i~$c_2$. A~zatem $T(n)=\Theta(n\lg n)$.

\subproblem %4-4(e)
Mamy do czynienia z~rekurencją $T_a(n)$ dla $a=2$, którą rozważaliśmy w~punkcie~(b). Zgodnie z~przedstawionym tam rozumowaniem wnioskujemy, że $T(n)=\Theta(n\lg\lg n)$.

\subproblem %4-4(f)
W~celu rozwiązania rekurencji wykorzystamy metodę drzewa rekursji do odgadnięcia rozwiązania, które następnie udowodnimy. Drzewo zostało przedstawione na rys.~\ref{fig:4-4f}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.5}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n/2)+T(n/4)+T(n/8)+n$} \label{fig:4-4f}
\end{figure}

Zauważmy, że najszybciej maleją argumenty na skrajnie prawej gałęzi, więc na pewnym poziomie $h$ gałąź ta posiada liścia. Ponieważ koszt węzła z~\twoparts{$i$}{tego} poziomu tej gałęzi wynosi $n/8^i$ oraz $T(1)=\Theta(1)$, to $h=\Theta(\log_8n)$. Kosztem \twoparts{$i$}{tego} poziomu jest $(7/8)^in$, więc sumując je od korzenia aż do poziomu \twoparts{$h$}{tego}, otrzymujemy przybliżone oszacowanie rekurencji od dołu:
\[
	T(n) \ge \sum_{i=0}^{\log_8n}\left(\frac{7}{8}\right)^in = n\cdot\frac{1-(7/8)^{\log_8n+1}}{1-7/8} = 8n(1-7/8\cdot n^{\log_8(7/8)}) \ge 8n(1-7/8) = \Omega(n).
\]

Zbadajmy teraz górne oszacowanie rekurencji $T(n)$ poprzez dokonanie obserwacji, że najwolniej malejącymi węzłami drzewa są węzły ze skrajnie lewej gałęzi, które wnoszą koszt równy $n/2^i$ na \twoparts{$i$}{tym} poziomie, więc liść znajduje się na poziomie $H=\Theta(\lg n)$. Mamy
\[
	T(n) \le \sum_{i=0}^{\lg n}\left(\frac{7}{8}\right)^in < \sum_{i=0}^\infty\left(\frac{7}{8}\right)^in = \frac{n}{1-\frac{7}{8}} = O(n).
\]
co pozwala przypuszczać, że oszacowaniem dokładnym na $T(n)$ jest $\Theta(n)$.

Przeprowadźmy teraz dowód tego wyniku metodą przez podstawianie. Załóżmy, że
\begin{gather*}
	c_1(n/2) \le T(n/2) \le c_2(n/2), \\
	c_1(n/4) \le T(n/4) \le c_2(n/4), \\
	c_1(n/8) \le T(n/8) \le c_2(n/8),
\end{gather*}
gdzie $c_1$, $c_2>0$ to pewne stałe. Mamy zatem
\[
	T(n) \ge c_1n/2+c_1n/4+c_1n/8+n = 7c_1n/8+n \ge c_1n,
\]
przy czym $c_1\le8$. Górne oszacowanie dowodzi się analogicznie, zmieniając kierunek znaku nierówności i~zakładając, że $c_2\ge8$. Przyjęcie warunku brzegowego rekurencji $T(1)=1$ na przypadek bazowy indukcji wystarcza w~obu indukcjach. A~zatem udowodniliśmy, że dokładnym rozwiązaniem rekurencji jest $T(n)=\Theta(n)$.

\subproblem %4-4(g)
Rozwijając rekurencję przy założeniu, że $T(1)=1$, otrzymujemy
\[
	T(n) = \frac{1}{n}+\frac{1}{n-1}+\cdots+\frac{1}{2}+\frac{1}{1} = H_n,
\]
a~zatem $T(n)=\Theta(\lg n)$.

\subproblem %4-4(h)
Przy założeniu, że $T(1)=0$, zachodzi
\[
	T(n) = \lg n+\lg(n-1)+\cdots+\lg2+\lg 1 = \lg\biggl(\prod_{i=1}^ni\biggr) = \lg(n!)
\]
i~z~wzoru~(3.18) dostajemy $T(n)=\Theta(n\lg n)$.

\subproblem %4-4(i)
Przyjmijmy $T(2)=2$ i~rozważmy przypadek, gdy $n$ jest parzyste. Rozwijamy rekurencję, otrzymując
\[
	T(n) = 2\lg n+2\lg(n-2)+\cdots+2\lg4+2 = 2\lg\biggl(\prod_{i=1}^{n/2}2i\biggr) = 2\bigl(\lg((n/2)!)+n/2\bigr).
\]
Wykorzystując wzór~(3.18), dostajemy
\[
	T(n) = 2\Theta((n/2)\lg (n/2))+n = \Theta(n\lg n).
\]

Dla $n$ nieparzystego, po przyjęciu $T(1)=0$, sprowadzamy rekurencję do sumy
\[
	T(n) = 2\lg n+2\lg(n-2)+\cdots+2\lg3+0 = 2\lg\biggl(\prod_{i=1}^{(n-1)/2}(2i-1)\biggr),
\]
którą można ograniczyć od góry przez $2\lg\Bigl(\prod_{i=1}^{n/2}2i\Bigr)$, a~z~dołu przez $2\lg\Bigl(\prod_{i=1}^{(n-1)/2-1}2i\Bigr)$. Obie wartości można z~wzoru~(3.18) sprowadzić do postaci $\Theta(n\lg n)$, a~zatem również w~przypadku nieparzystego argumentu $T(n)$ jest klasy $\Theta(n\lg n)$.

\subproblem %4-4(j)
Po podzieleniu równania rekurencji $T(n)$ przez $n$ dostajemy
\[
	\frac{T(n)}{n} = \frac{T(\!\sqrt{n})}{\sqrt{n}}+1.
\]
Podstawmy teraz $S(n)=T(n)/n$, otrzymując nową rekurencję
\[
	S(n) = S(\!\sqrt{n})+1.
\]
Następnie potraktujmy $n$ jako $2^m$, skąd $m=\lg n$ i~podstawmy $R(m)=S(2^m)$:
\[
	R(m) = R(m/2)+1.
\]
Rozwiązanie ostatniej rekurencji zostało wyznaczone w~\zad{4.3-3} i~wynosi $R(m)=\Theta(\lg m)$. Powracamy do oryginalnej rekurencji $T(n)$, dostając ostatecznie
\[
	T(n) = nS(n) = nR(\lg n) = n\cdot\Theta(\lg\lg n) = \Theta(n\lg\lg n).
\]

\problem{Liczby Fibonacciego} %4-5

\subproblem %4-5(a)
Wprost z~definicji $\mathcal{F}(z)$ mamy:
\begin{align*}
	\mathcal{F}(z) &= \sum_{i=0}^\infty F_iz^i \\
	&= F_0+zF_1+\sum_{i=2}^\infty (F_{i-1}+F_{i-2})z^i \\
	&= z+\sum_{i=2}^\infty F_{i-1}z^i+\sum_{i=2}^\infty F_{i-2}z^i \\
	&= z+\sum_{i=1}^\infty F_iz^{i+1}+\sum_{i=0}^\infty F_iz^{i+2} \\[2mm]
	&= z+z\mathcal{F}(z)+z^2\mathcal{F}(z),
\end{align*}
a~zatem tożsamość zachodzi.

\subproblem %4-5(b)
Z~wzoru z~poprzedniego punktu wynika pierwsza równość:
\begin{align*}
	\mathcal{F}(z) &= z+z\mathcal{F}(z)+z^2\mathcal{F}(z) \\
	(1-z-z^2)\mathcal{F}(z) &= z \\
	\mathcal{F}(z) &= \frac{z}{1-z-z^2}. \tag{$*$}\label{eq:4-5b_1}
\end{align*}

Mianownik prawej strony~(\ref{eq:4-5b_1}) jest trójmianem kwadratowym, który można zapisać w~równoważnej postaci:
\[
	1-z-z^2 \equiv -(z+\phi)\bigl(z+\widehat\phi\bigr). \tag{$*$}\label{eq:4-5b_2}
\]
Trójmian~(\ref{eq:4-5b_2}) przyjmuje wartość~0 dla $z=-\phi$ lub $z=-\widehat\phi$. Ponieważ zachodzi ciekawa własność $\phi\cdot\widehat\phi=-1$, zatem można zapisać trójmian w~postaci $(1-\phi z)\bigl(1-\widehat\phi z\bigr)$, skąd wynika druga równość.

Ostatnią z~nich dowodzimy zauważając, że:
\[
	\frac{1}{1-\phi z}-\frac{1}{1-\widehat\phi z} = \frac{1-\widehat\phi z-1+\phi z}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{z\bigl(\phi-\widehat\phi\bigr)}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{z\sqrt{5}}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)},
\]
a~stąd mamy
\[
	\frac{z}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{1}{\sqrt{5}}\cdot\frac{z\sqrt{5}}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{1}{\sqrt{5}}\left(\frac{1}{1-\phi z}-\frac{1}{1-\widehat\phi z}\right).
\]

\subproblem %4-5(c)
Tezę otrzymujemy natychmiast, jeśli w~definicji $\mathcal{F}(z)$ podstawimy $F_i=\bigl(\phi^i-\widehat\phi^i\bigr)/\sqrt{5}$, co wykazano w~\zad{3.2-6}.

\subproblem %4-5(d)
Ponieważ $\bigl|\widehat\phi\bigr|<1$, to prawdą jest, że $\bigl|\widehat\phi^i\bigr|<1$ dla $i>0$ oraz $\bigl|\widehat\phi^i\bigr|/\sqrt{5}<1/\sqrt{5}<1/2$. Mamy
\[
	F_i = \frac{\phi^i-\widehat\phi^i}{\sqrt{5}} = \frac{\phi^i}{\sqrt{5}}-\frac{\widehat\phi^i}{\sqrt{5}},
\]
skąd
\[
	\frac{\phi^i}{\sqrt{5}}-\frac{1}{2} < F_i < \frac{\phi^i}{\sqrt{5}}+\frac{1}{2},
\]
a~zatem $F_i$ jest równe liczbie całkowitej najbliższej $\phi^i/\sqrt{5}$.

\subproblem %4-5(e)
Tożsamość została udowodniona w~\zad{3.2-7}.

\problem{Testowanie układów VLSI} %4-6

\subproblem %4-6(a)
Niech $D$ i~$Z$ będą zbiorami, odpowiednio, układów dobrych i~układów złych. Podczas testowania każdy zły układ może twierdzić, że każdy inny układ ze zbioru $Z$ jest dobry, a~każdy układ ze zbioru $D$ jest zły. Z~kolei dobry układ będzie orzekał o~każdym układzie z~$Z$, że jest zły, natomiast o~każdym innym z~$D$, że jest dobry. Inaczej ujmując, zbiór $Z$ wskazuje, że sam jest zbiorem układów dobrych, a~zbiór $D$ złych i~symetrycznie dla zbioru $D$. W~ogólności, $Z$ może składać się z~podzbiorów, które o~sobie samych będą twierdzić, że składają się z~dobrych układów, a~pozostałe zbiory ze złych. Nie da się natomiast rozdzielić w~taki sposób zbioru $D$, ponieważ jego układy zawsze orzekają prawdziwie. Musi przez to być $|D|>|Z|$, wtedy bowiem niezależnie od utworzonego w~wyniku testowania podziału zbioru $Z$, zbiór $D$ będzie wyznaczony jednoznacznie.

\subproblem %4-6(b)
Potraktujmy wynik każdego testu dwóch układów jako parę $(r_1,r_2)\in\{{\scriptstyle\rm D},{\scriptstyle\rm Z}\}^2$. Pierwszy element pary jest stwierdzeniem pierwszego układu o~drugim, a~drugi element -- drugiego o~pierwszym, przy czym ${\scriptstyle\rm D}$ oznacza pozytywny wynik testu, a~${\scriptstyle\rm Z}$ -- negatywny. Możliwe jest uzyskanie jednego z~czterech wyników:
\begin{itemize}
	\item $({\scriptstyle\rm D},{\scriptstyle\rm D})$ -- implikuje, że oba układy są dobre albo oba są złe,
	\item $({\scriptstyle\rm D},{\scriptstyle\rm Z})$ -- zachodzi tylko wtedy, gdy pierwszy z~układów jest zły,
	\item $({\scriptstyle\rm Z},{\scriptstyle\rm D})$ -- zachodzi tylko wtedy, gdy drugi z~układów jest zły,
	\item $({\scriptstyle\rm Z},{\scriptstyle\rm Z})$ -- co najmniej jeden z~układów jest zły.
\end{itemize}

Podzielmy zbiór układów na pary i~przetestujmy wzajemnie układy w~każdej takiej parze, wykonując przy tym $\lfloor n/2\rfloor$ testów. Zauważmy, że otrzymując dla pewnej pary wynik różny niż $({\scriptstyle\rm D},{\scriptstyle\rm D})$, możemy ją odrzucić, gdyż co najmniej jeden układ ją tworzący jest zły, ale w~wśród nieodrzuconych układów nadal pozostanie więcej dobrych niż złych. Otrzymamy w~wyniku od jednej do $\lfloor n/2\rfloor$ par o~tej własności, że w~każdej z~nich oba układy są dobre albo oba są złe. Odrzucając zatem po jednym układzie z~każdej pozostawionej pary, nadal zachowujemy własność o~większej liczbie dobrych układów w~pozostawionym zbiorze układów, który ma rozmiar co najwyżej $\lfloor n/2\rfloor$.

Powyżej opisany proces przeprowadzamy rekurencyjnie na otrzymywanych podproblemach, dostając w~końcu zbiór jednoelementowy, który na mocy założenia zawiera dobry układ.

\subproblem %4-6(c)
Wykorzystując wynik poprzedniego punktu, dostajemy następującą rekurencję opisującą liczbę testów koniecznych do znalezienia jednego dobrego układu w~pesymistycznym przypadku (każda para zwraca wynik $({\scriptstyle\rm D},{\scriptstyle\rm D})$):
\[
	T(n) =
	\begin{cases}
		\Theta(1), & \text{jeśli $n=1$}, \\
		T(\lfloor n/2\rfloor) + \lfloor n/2\rfloor, & \text{jeśli $n>1$}.
	\end{cases}
\]
Ignorując podłogi i~stosując twierdzenie o~rekurencji uniwersalnej, dostajemy jej rozwiązanie: $T(n)=\Theta(n)$. Wynik ten jest prawdziwy także w~przypadku optymistycznym -- tylko jedna para zwraca $({\scriptstyle\rm D},{\scriptstyle\rm D})$, a~więc dobry układ znajdziemy w~jednym zejściu rekurencyjnym, jednak wcześniej należało wykonać $\Theta(n)$ testów.

Ponieważ w~poprzednim punkcie znaleźliśmy dobry układ $u$, to wykorzystajmy go do znalezienia kolejnych. Testujemy tenże układ z~pozostałymi $n-1$. Wynikiem testu $u$ z~pewnym innym układem $v$ nie może być $({\scriptstyle\rm D},{\scriptstyle\rm Z})$, a~więc możliwe są trzy sytuacje. Jeśli otrzymamy $({\scriptstyle\rm D},{\scriptstyle\rm D})$, to oznacza to, że oba układy są tak samo dobre, a~więc $v$ również jest dobry. Uzyskując wynik $({\scriptstyle\rm Z},{\scriptstyle\rm D})$, mamy natychmiast, że $v$ jest zły, podobnie w~wypadku, gdy wynikiem testu będzie $({\scriptstyle\rm Z},{\scriptstyle\rm Z})$ -- wtedy co najmniej jeden z~testowanych układów jest zły, ale nie może nim być $u$. Wynika stąd, że sprawdzając $u$ z~$n-1$ innymi układami, wykonamy $n-1$ testów, a~ponieważ stwierdziliśmy, że $u$ jest dobre za pomocą $\Theta(n)$ testów, to znalezienie wszystkich dobrych układów można wykonać, przeprowadzając również $\Theta(n)$ testów.

\problem{Tablice Monge'a} %4-7

\subproblem %4-7(a)
\noindent\emph{Dowód $\Rightarrow$.} Tablica Monge'a $A$ spełnia nierówność
\[
	A[i,j]+A[k,l] \le A[i,l]+A[k,j], \quad\text{dla $1\le i<k\le m$ oraz $1\le j<l\le n$}.
\]
W~szczególności zaś może być $k=i+1$ oraz $l=j+1$, zatem implikacja zachodzi.
\bigskip

\noindent\emph{Dowód $\Leftarrow$.} Dowodzimy przez indukcję względem liczby wierszy $m$. Zauważmy, że warunek tablicy Monge'a nie ma większego sensu dla tablic o~jednej kolumnie lub jednym wierszu, zatem przyjmijmy $m=2$ za podstawę indukcji. Wtedy $i=1$ oraz $k=2$ i~przyjmując $l=j+1$, mamy
\[
	A[1,j]+A[2,j+1] \le A[1,j+1]+A[2,j], \tag{$*$}\label{eq:4-7a}
\]
dla $1\le j<n$. Dodajmy teraz powyższą nierówność dla pewnego $j<n-1$ (przy założeniu, że $n>2$) do niej samej ale z~$l=j+1$ w~miejscu $j$. Po zredukowaniu zbędnych składników dostajemy
\[
	A[1,j]+A[2,j+2] \le A[1,j+2]+A[2,j].
\]
Do ostatniej nierówności można ponownie dodawać~(\ref{eq:4-7a}), podstawiając w~miejsce $j$ coraz większe $l<n$ i~otrzymując dowolną nierówność stanowiącą warunek tablicy Monge'a.

Niech teraz $m>2$. Dowód wykorzystuje ten sam pomysł z~pierwszego kroku indukcji z~tym, że teraz $i$ może przyjmować każdą dopuszczalną wartość. Przyjmujemy ponadto założenie indukcyjne, że tablica $A$ pozbawiona ostatniego wiersza stanowi tablicę Monge'a. Pozostaje zatem wykazać, że zachodzą wszystkie nierówności z~definicji tablicy Monge'a dla $k=m$. Mamy
\[
	A[i,j]+A[i+1,j+1] \le A[i,j+1]+A[i+1,j], \quad\text{dla $1\le i<m-1$ oraz $1\le j<n$}.
\]
Dodajemy tę nierówność do niej samej po uprzednim podstawieniu w~ostatniej $l=j+1<n$ w~miejsce $j$. Dzięki temu otrzymamy
\[
	A[i,j]+A[i+1,j+2] \le A[i,j+2]+A[i+1,j].
\]
Podobnie jak wcześniej możemy tak dodawać żądaną ilość razy, przyjmując coraz większe wartości $l<n$ zamiast $j$ i~dostając wszystkie wymagane nierówności.

Widać zatem, że implikacja jest prawdziwa dla tablic o~pewnej ustalonej liczbie kolumn. Dowód dla zmiennej liczby kolumn przeprowadza się analogicznie przez indukcję po $n\ge2$, pokazując tym samym, że twierdzenie zachodzi dla tablic o~dowolnych wymiarach.

\subproblem %4-7(b)
Korzystając z~poprzedniego punktu, można pokazać, że nierówność
\[
	A[1,2]+A[2,3] \le A[1,3]+A[2,2]
\]
jest fałszywa, co zaburza właściwość tablicy Monge'a. By przywrócić własność, można zamienić $A[1,3]$ na~24.

\subproblem %4-7(c)
Korzystając z~poniższej nierówności prawdziwej dla tablicy Monge'a $A$:
\[
	A[i,j]+A[i+1,j+r] \le A[i,j+r]+A[i+1,j], \tag{$*$}\label{eq:4-7c}
\]
dla $0<r\le n-j$, wnioskujemy w~następujący sposób. Znajdujemy w~pierwszym wierszu tablicy $A$ pierwsze minimum z~lewej strony, które oznaczymy przez $\mu$. Indeksem $\mu$ jest oczywiście $f(1)$. Stwierdzamy teraz, że dla $1\le j<f(1)$ spełnione jest~(\ref{eq:4-7c}), czyli
\[
	A[1,j]+A[2,f(1)] \le \mu+A[2,j].
\]
Z~drugiej strony $\mu<A[1,j]$ dla każdego $1\le j<f(1)$. Łącząc oba fakty, otrzymujemy $A[2,f(1)]<A[2,j]$, a~to oznacza, że pierwsze z~lewej strony minimum wiersza~2 występuje w~nim na indeksie nie mniejszym niż $f(1)$, skąd $f(1)\le f(2)$.

Dowód kolejnych nierówności przebiega analogicznie, skąd dostajemy tezę.

\subproblem %4-7(d)
Korzystając z~twierdzenia z~poprzedniego punktu, szukając minimum wiersza \twoparts{$i$}{tego}, będziemy sprawdzać indeksy minimów wierszy \twoparts{$(i-1)$}{szego} oraz \twoparts{$(i+1)$}{szego}. Szukane minimum znajduje się pomiędzy nimi. Oczywiście nie istnieje wiersz zerowy, dlatego przetwarzając pierwszy wiersz, nie szukamy minimum poprzedniego, ale przyjmujemy dla uproszczenia procedury, że $f(0)=1$. Podobny przypadek może się zdarzyć dla ostatniego nieparzystego wiersza, jeśli jest on ostatnim wierszem tablicy, wtedy wystarczy przyjąć wartość $f(m+1)=n$.

Po wyznaczeniu $f(i-1)$ oraz $f(i+1)$ sprawdzamy $f(i+1)-f(i-1)+1$ komórek wiersza $i$ w~poszukiwaniu jego minimum. W~ciągu całej procedury sprawdzimy w~pesymistycznym przypadku
\begin{align*}
	\sum_{\begin{subarray}{l}1\le i\le m\\2\,\nmid\,i\end{subarray}}\bigl(f(i+1)-f(i-1)+1\bigr) &= \sum_{k=0}^{\lceil m/2\rceil-1}\bigl(f(2k+2)-f(2k)+1\bigr) \\
	&= \lceil m/2\rceil+\sum_{k=0}^{\lceil m/2\rceil-1}\bigl(f(2k+2)-f(2k)) \\[1mm]
	&= \lceil m/2\rceil+f(2\lceil m/2\rceil)-f(0) \\[2mm]
	&= \lceil m/2\rceil+n-1
\end{align*}
komórek, która to liczba jest rzędu $O(m+n)$.

\subproblem %4-7(e)
Na podstawie oszacowania z~poprzedniego punktu oraz z~tego, że na ostatnim poziomie rekursji wyznaczenie minimum jednego wiersza tablicy wymaga sprawdzenia co najwyżej $O(n)$ komórek, formułujemy następującą rekurencję:
\[
	T(m,n) =
	\begin{cases}
		O(n), & \text{jeśli $m=1$}, \\
		T(\lfloor m/2\rfloor,n)+O(m+n), & \text{jeśli $m>1$}.
	\end{cases}
\]
Na \twoparts{$i$}{tym} poziomie rekurencja wprowadza koszt równy $O(m/2^i+n)$. Łatwo zauważyć, że jest $\lfloor\lg m\rfloor+1$ poziomów, a~zatem całkowity koszt wynosi
\begin{align*}
	T(n) &= \sum_{i=0}^{\lfloor\lg m\rfloor-1}O\biggl(\frac{m}{2^i}+n\biggr)+O(n) \\
	&= O\biggl(\sum_{i=0}^{\lfloor\lg m\rfloor-1}\frac{m}{2^i}\biggr)+O(n\lg m) \\
	&= O\biggl(m\sum_{i=0}^{\lfloor\lg m\rfloor-1}\frac{1}{2^i}\biggr)+O(n\lg m) \\
	&= O(m+n\lg m),
\end{align*}
ponieważ suma w~przedostatniej linijce jest ograniczona od góry przez stałą.

\endinput
