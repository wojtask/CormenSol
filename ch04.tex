\chapter{Rekurencje}

\subchapter{Metoda podstawiania}

\exercise{} %4-1.1
Niech $c>0$ będzie stałą. Przyjmujemy następujące założenie:
\[
	T(\lceil n/2\rceil) \le c\lg(\lceil n/2\rceil).
\]
Na jego podstawie oraz z wzoru (3.3) otrzymujemy:
\[
	T(n) \le c\lg(\lceil n/2\rceil)+1 < c\lg (n/2)+2 = c\lg n-c\lg 2+2 \le c\lg n,
\]
o ile $c\ge2$. Niech $T(1)=1$. Ale wtedy otrzymujemy sprzeczność, bo $T(1)\le c\lg1=0$. Ponieważ dla $n>2$ rekurencja nie zależy bezpośrednio od $T(1)$, to przyjmijmy, że $T(2)=2$ stanowi przypadek brzegowy indukcji, dla którego już zachodzi $T(2)\le c\lg2$.

\exercise{} %4-1.2
Przyjmijmy założenie, że
\[
	T(\lfloor n/2\rfloor) \ge c\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)
\]
dla pewnej dodatniej stałej $c$. Korzystając z wzoru~(3.3) mamy:
\begin{align*}
	T(n) &\ge 2c\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)+n \\
	&> 2c(n/2-1)\lg(n/4)+n \\
	&= 2c((n/2)\lg n-\lg n-n+2)+n \\
	&= cn\lg n-2c\lg n-2cn+4c+n \\
	&> cn\lg n-2c\lg n+n(1-2c) \\
	&\ge cn\lg n,
\end{align*}
Ostatni krok uzasadniamy, rozwiązując nierówność $n(1-2c)-2c\lg n\ge0$ ze względu na $c$:
\[
	c \le \frac{n}{2(n+\lg n)} \le \frac{n}{2n} = \frac{1}{2},
\]
a zatem wybierając dowolne $0<c\le1/2$ spełniamy nierówność. Można przyjąć $T(1)=1$ za przypadek brzegowy indukcji, bo $T(1)\ge c\lg1=0$. Wykazaliśmy, że $T(n)=\Omega(n\lg n)$. Skoro rozwiązanie rekurencji jest klasy $O(n\lg n)$ oraz $\Omega(n\lg n)$, to na mocy tw.~3.1, jest również w $\Theta(n\lg n)$.

\exercise{} %4-1.3
Przyjmijmy założenie, że $T(\lfloor n/2\rfloor)\le c\lfloor n/2\rfloor^2$ dla pewnej stałej $c>0$, czyli chcemy udowodnić, że $T(n)=O(n^2)$. Mamy zatem
\[
	T(n) \le 2c\lfloor n/2\rfloor^2+n \le 2cn^2\!/4 + n = cn^2\!/2+n \le cn^2,
\]
co jest prawdą, jeśli przyjmiemy $c\ge2$. Widać teraz, że z mocniejszym założeniem przypadek brzegowy $T(1)=1$ jest spełniony.

\exercise{} %4-1.4
Rekurencję $T(n)$ można przedstawić w następujący sposób:
\[
	T(n) =
	\begin{cases}
		c_1, & \text{dla $n=1$}, \\
		T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+c_2n, & \text{dla $n>1$},
	\end{cases}
\]
dla pewnych stałych $c_1$,~$c_2>0$. Przyjmując założenia
\[
	T(\lfloor n/2\rfloor) = a_1\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)-b_1\lfloor n/2\rfloor \quad\text{oraz}\quad T(\lceil n/2\rceil) = a_2\lceil n/2\rceil\lg(\lceil n/2\rceil)-b_2\lceil n/2\rceil,
\]
(odejmując składnik niższego rzędu uzyskujemy nieco mocniejsze warunki, konieczne do przeprowadzenia niniejszego dowodu) dla pewnych dodatnich stałych $a_1$, $b_1$, $a_2$,~$b_2$, otrzymujemy:
\begin{align*}
	T(n) &= T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+c_2n \\
	&\ge 2T(\lfloor n/2\rfloor)+c_2n \\
	&\ge 2a_1\lfloor n/2\rfloor\lg(\lfloor n/2\rfloor)-2b_1\lfloor n/2\rfloor+c_2n \\
	&> 2a_1(n/2-1)\lg\frac{n\lfloor n/2\rfloor}{n}-2b_1(n/2-1)+c_2n \\
	&> 2a_1(n/2)\lg n-2b_1(n/2)+c_2n-2a_1\lg(\lfloor n/2\rfloor)+a_1n\lg\frac{\lfloor n/2\rfloor}{n} \\
	&\ge a_1n\lg n-b_1n,
\end{align*}
ponieważ można tak dobrać stałe, aby zachodziła ostatnia nierówność, a zatem $T(n)=\Omega(n\lg n)$. W powyższym wyprowadzeniu wykorzystaliśmy zależność $\lfloor n/2\rfloor>n/2-1$. Analogicznie dowodzimy górnego oszacowania:
\begin{align*}
	T(n) &= T(\lceil n/2\rceil)+T(\lfloor n/2\rfloor)+c_2n \\
	&\le 2T(\lceil n/2\rceil)+c_2n \\
	&\le 2a_2\lceil n/2\rceil\lg(\lceil n/2\rceil)-2b_2\lceil n/2\rceil+c_2n \\
	&< 2a_2(n/2)\lg n-2b_2(n/2)+c_2n+2a_2\lg(\lceil n/2\rceil)+a_2n\lg\frac{\lceil n/2\rceil}{n} \\
	&\le a_2n\lg n-b_2n.
\end{align*}
Przedostatnia nierówność zachodzi dzięki zależności $\lceil n/2\rceil<n/2+1$. Rozwiązaniem rekurencji $T(n)$ jest $\Theta(n\lg n)$.

\exercise{} %4-1.5
Wykorzystując założenie
\[
	T(\lfloor n/2\rfloor+17) \le c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)
\]
dla pewnej stałej $c>0$, otrzymujemy:
\begin{align*}
	T(n) &\le 2c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)+n \\
	&\le 2c(n/2+17)\lg(\lfloor n/2\rfloor+\lceil n/2\rceil)+n \\
	&= 2c(n/2+17)\lg n+n \\
	&= cn\lg n+34c\lg n+n,
\end{align*}
co zachodzi, o ile $17\le\lceil n/2\rceil$, skąd $n>32$. Niestety wyrażenie $34c\lg n+n$ jest nieujemne, a więc nie udowodnimy tezy. Przyjmijmy zatem, że zachodzi mocniejsze założenie:
\[
	T(\lfloor n/2\rfloor+17) \le c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)-b(\lfloor n/2\rfloor+17),
\]
dla stałych $b$,~$c>0$. Mamy teraz:
\begin{align*}
	T(n) &\le 2c(\lfloor n/2\rfloor+17)\lg(\lfloor n/2\rfloor+17)-2b(\lfloor n/2\rfloor+17)+n \\
	&\le 2c(n/2+17)\lg(\lfloor n/2\rfloor+\lceil n/2\rceil)-2b(\lfloor n/2\rfloor+\lceil n/2\rceil)+n \\
	&= 2c(n/2+17)\lg n-2bn+n \\
	&= cn\lg n-bn+34c\lg n-(b-1)n \\
	&\le cn\lg n-bn,
\end{align*}
gdy $c=1$ i $b$ jest dostatecznie duże, bo składnik $(b-1)n$ rośnie szybciej od $34c\lg n$. Także w tym przypadku założyliśmy, że $n>32$, więc dla $c=1$, możemy przyjąć $b\ge7$. Ograniczenie dolne dowodzimy w analogiczny sposób, przy wykorzystaniu mocniejszego założenia. Otrzymaliśmy żądane ograniczenie $T(n)$, pozostaje jedynie zbadać zachowanie rekurencji dla przypadków brzegowych.

Zauważmy, że stosowanie równania $T(n)=2T(\lfloor n/2\rfloor+17)+n$ dla $n\le35$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n\le35$ i niech stanowi to przypadek brzegowy rekurencji. Jednak aby zachodziła tożsamość, należałoby szukać bardzo dużego $n$, a wszystkie niższe wyrazy rekurencji przyjąć za przypadek brzegowy indukcji. Okazuje się, że można tę trudność przezwyciężyć, przyjmując większe $c$, np. $c=100$. Dla takiej wartości, $b\ge533$ i wtedy można zauważyć, że od $T(43)$ zależność zachodzi.

\exercise{} %4-1.6
Przyjmijmy, że $n=2^m$, skąd $m=\lg n$. Rekurencja przyjmuje teraz postać
\[
	T(2^m) = 2T(2^{m/2})+1.
\]
Z kolei podstawiając $S(m)$ za $T(2^m)$ dostajemy
\[
	S(m) = 2S(m/2)+1,
\]
której rozwiązaniem jest $O(\lg m)$ (\zad{4.1-1}). Zgodnie ze wskazówką, nie dbamy o to, czy $m/2$ jest całkowite.

By uzyskać oszacowanie dokładne, pozostaje udowodnić, że $S(m)=\Omega(\lg m)$. Przyjmujemy zatem założenie, że $S(m/2)\ge c\lg(m/2)$ dla $c>0$. Na jego podstawie otrzymujemy:
\[
	S(m) \ge 2c\lg(m/2)+1 = 2c\lg m-2c+1 \ge 2c\lg m,
\]
co oczywiście jest prawdą dla $c\le1/2$. Przyjęcie $S(1)=1$ na podstawę indukcji wystarcza, bo $S(1)\ge2c\lg1=0$, a zatem $S(m)=\Omega(\lg m)$.

Ponieważ $S(m)=\Theta(\lg m)$, więc wracając do oryginalnej rekurencji i starej zmiennej, mamy $T(n)=T(2^m)=S(m)=\Theta(\lg m)=\Theta(\lg\lg n)$.

\subchapter{Metoda drzewa rekursji}

\exercise{} %4-2.1
Ponieważ podłogi i sufity nie mają większego znaczenia, to spróbujemy znaleźć oszacowanie rekurencji $T(n)=3T(n/2)+n$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.1}
	\end{center}
	\caption{Drzewo rekursji $T(n)=3T(n/2)+n$} \label{fig:4.2-1}
\end{figure}
W drzewie z rys.~\ref{fig:4.2-1} jest $\lg n+1$ poziomów, na \twoparts{$i$}{tym} z nich znajduje się $3^i$ węzłów, zatem jest $n^{\lg3}$ liści. Koszt węzła na poziomie $i$ wynosi $n/2^i$, skąd wynika, że łączny koszt wszystkich węzłów na \twoparts{$i$}{tej} głębokości jest równy $(3/2)^in$. Ponieważ liście wnoszą stały koszt, czyli $T(1)=\Theta(1)$, to ostatni poziom ma wartość $\Theta(n^{\lg3})$. Na podstawie tych wartości rozwiązujemy rekurencję:
\begin{align*}
	T(n) &= n+\frac{3}{2}n+\left(\frac{3}{2}\right)^2n+\cdots+\left(\frac{3}{2}\right)^{\lg n-1}n+\Theta(n^{\lg 3}) \\
	&= \sum_{i=0}^{\lg n-1}\left(\frac{3}{2}\right)^in+\Theta(n^{\lg 3}) \\
	&= \frac{\left(\frac{3}{2}\right)^{\lg n}-1}{\frac{3}{2}-1}+\Theta(n^{\lg 3}) \\
	&= 2(n^{\lg 3-1}-1)+\Theta(n^{\lg 3}) \\
	&= O(n^{\lg 3}).
\end{align*}

Wykorzystując otrzymany wynik i dla oryginalnej rekurencji przyjmując założenie
\[
	T(\lfloor n/2\rfloor)n\le c(\lfloor n/2\rfloor)^{\lg 3},
\]
dowodzimy metodą przez podstawianie, otrzymując
\begin{align*}
	T(n) &= 3T(\lfloor n/2\rfloor)+n \\
	&\le 3c(\lfloor n/2\rfloor)^{\lg 3}+n \\
	&\le 3c(n/2)^{\lg 3}+n \\
	&= cn^{\lg 3}+n.
\end{align*}
Nie możemy jednak na podstawie otrzymanego wyniku wywnioskować szukanego oszacowania. Wzmocnijmy zatem nasze założenie, niech
\[
	T(\lfloor n/2\rfloor) \le c(\lfloor n/2\rfloor)^{\lg 3}-b\lfloor n/2\rfloor,
\]
dla pewnego $b>0$. Mamy teraz
\begin{align*}
	T(n) &\le 3c(\lfloor n/2\rfloor)^{\lg 3}-3b\lfloor n/2\rfloor+n \\
	&\le 3c(n/2)^{\lg 3}-3b(n/2)+n \\
	&= cn^{\lg 3}-3b(n/2)+n \\
	&\le cn^{\lg 3}-bn,
\end{align*}
co zachodzi dla $b\ge2$, a więc dowiedliśmy, że oszacowaniem górnym rekurencji $T(n)$ jest $O(n^{\lg3})$.

\exercise{} %4-2.2
Drzewo rekursji $T(n)$ nie jest pełnym drzewem binarnym. Najkrótszą ścieżką od korzenia do liścia jest $n\to n/3\to n/9\to\dots\to n/3^i\to\dots\to1$. Liść tej gałęzi jest na poziomie $i=\log_3n$. Ponieważ pełne drzewo binarne o~wysokości $\log_3n+1$ wnosi niewiększy koszt niż drzewo rekurencji $T(n)$, to zachodzi $T(n)\ge cn\log_3n$ dla pewnego $c>0$, a stąd $T(n)=\Omega(n\lg n)$.

\exercise{} %4-2.3
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.2}
	\end{center}
	\caption{Drzewo rekursji $T(n)=4T(n/2)+cn$} \label{fig:4.2-3}
\end{figure}

Dla uproszczenia pomijamy branie części całkowitych. W drzewie rekursji z rys.~\ref{fig:4.2-3}, na \twoparts{$i$}{tym} poziomie jest $4^i$ węzłów, z których każdy wnosi koszt równy $cn/2^i$. Stąd, kosztem całego poziomu jest $2^icn$. Współczynnik przy $n$ w koszcie węzła maleje dwukrotnie wraz ze wzrostem poziomu, więc wysokością drzewa jest $\lg n+1$. Wnioskujemy zatem, że liczbą liści w tym drzewie jest $4^{\lg n}=n^2$ i że koszt ostatniego poziomu wynosi $\Theta(n^2)$. Sumując koszty z każdego poziomu, otrzymujemy:
\begin{align*}
	T(n) &= cn+2cn+2^2cn+\cdots+2^{\lg n-1}cn+\Theta(n^2) \\
	&= \sum_{i=0}^{\lg n-1}2^icn+\Theta(n^2) \\
	&= (2^{\lg n}-1)cn+\Theta(n^2) \\
	&= (n-1)cn+\Theta(n^2) \\
	&= \Theta(n^2).
\end{align*}

Sprawdzamy otrzymany wynik wykorzystując do tego celu metodę podstawiania. Badamy najpierw oszacowanie dolne $T(n)$, przyjmując założenie
\[
	T(n/2) \ge d_1(n/2)^2,
\]
dla pewnej stałej $d_1>0$. Stąd:
\[
	T(n) \ge d_1n^2+cn \ge d_1n^2, 
\]
bo $c>0$, a więc prawdą jest, że $T(n)=\Omega(n^2)$.

By udowodnić dodatkowo, że $T(n)=O(n^2)$, możemy przyjąć takie samo założenie indukcyjne ale z przeciwnym znakiem nierówności, jednak nie uzyskamy szukanego ograniczenia górnego na $T(n)$. Przyjmijmy zatem, że dla stałych $d_2$,~$d_3>0$ zachodzi
\[
	T(n/2) \le d_2(n/2)^2-d_3(n/2).
\]
Dowodzimy:
\[
	T(n) \le 4(d_2n^2\!/4-d_3n/2)+cn = d_2n^2-2d_3n+cn \le d_2n^2-d_3n,
\]
co jest prawdą, o ile $d_3\ge c$.

Dzięki metodzie podstawiania wykazaliśmy, że $T(n)=\Theta(n^2)$.

\exercise{} %4-2.4
Załóżmy, że w przypadku, gdy $n\le a$, to $T(n)=\Theta(1)$ i wartość taką zwracamy bezpośrednio (bez użycia rekurencji).
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.3}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n-a)+T(a)+cn$} \label{fig:4.2-4}
\end{figure}
Wysokość drzewa z rys.~\ref{fig:4.2-4} wynosi $\lfloor n/a\rfloor$. \twoparts{$i$}{ty} poziom (oprócz zerowego i ostatniego) wnosi koszt równy $c(n-a(i-1))$, a ostatni -- $\Theta(1)$. Obliczamy koszt całego drzewa:
\begin{align*}
	T(n) &= cn+\sum_{i=1}^{\lfloor n/a\rfloor-1}c(n-a(i-1))+\Theta(1) \\
	&= cn+c\sum_{i=0}^{\lfloor n/a\rfloor-2}(n-ai)+\Theta(1) \\
	&= cn+cn\sum_{i=0}^{\lfloor n/a\rfloor-2}1-ca\sum_{i=0}^{\lfloor n/a\rfloor-2}i+\Theta(1) \\
	&= cn+cn(\lfloor n/a\rfloor-1)-ca\frac{(\lfloor n/a\rfloor-2)(\lfloor n/a\rfloor-1)}{2}+\Theta(1) \\[2mm]
	&= \Theta(n^2).
\end{align*}

\exercise{} %4-2.5
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.4}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(\alpha n)+T((1-\alpha)n)+cn$} \label{fig:4.2-5}
\end{figure}

Zauważmy, że drzewo rekurencji $T(n)$ na rys.~\ref{fig:4.2-5} dla parametru $\alpha=k$ jest symetryczne do drzewa $T(n)$ przy parametrze $\alpha=1-k$, przyjmijmy więc, że $0<\alpha\le1/2$.

Wyznaczmy najpierw oszacowanie górne rekurencji. Na \twoparts{$i$}{tym} poziomie drzewa najmniejszy koszt wnoszą węzły o~wartościach $c\alpha^in$, a więc elementy ze skrajnie lewej gałęzi. Sprawdzając kiedy osiągną one wartość stałą $d>0$, wyznaczamy ilość poziomów tego drzewa. Na pewnej wysokości $h$, będzie $c\alpha^hn=d$, skąd otrzymujemy $h=\log_{1/\alpha}(cn/d)$ i liczba poziomów wynosi $h+1$. Ponieważ $\alpha$ jest stałe, to $h=\Theta(\lg n)$. Każdy poziom drzewa wnosi koszt $cn$, więc oszacowaniem górnym rekurencji jest $T(n)=O(cn(h+1))=O(n\lg n)$.

Badając teraz skrajnie prawą gałąź, której elementy wnoszą największy koszt na każdym poziomie, możemy dojść do oszacowania dolnego dla $T(n)$. Na wysokości $h'$ mamy $c(1-\alpha)^{h'}n=d$, skąd $h'=\log_{1/(1-\alpha)}(cn/d)$. Poziom na wysokości $h'$ jest ostatnim, który ma komplet węzłów; niższe poziomy są coraz mniej liczne, zatem obliczając koszt drzewa $T(n)$ od korzenia do wysokości $h'$, uzyskujemy oszacowanie dolne rekurencji. Także w tym przypadku mamy $h'=\Theta(\lg n)$, a więc $T(n)=\Omega(cn(h'+1))=\Omega(n\lg n)$, skąd asymptotycznie dokładnym rozwiązaniem rekurencji jest $\Theta(n\lg n)$.

\subchapter{Metoda rekurencji uniwersalnej}

\exercise{} %4-3.1

\subexercise{}
W równaniu~(4.5) przyjmujemy $a=4$ i $b=2$ oraz $f(n)=n$. Ponieważ $f(n)=O(n^{2-\epsilon})$ dla $0<\epsilon\le1$, to z tw.~o rekurencji uniwersalnej mamy $T(n)=\Theta(n^2)$.

\subexercise{}
Postępując analogicznie jak w poprzednim punkcie, mamy te same wartości $a$ i $b$, ale teraz $f(n)=n^2$. Z tego, że $f(n)=\Theta(n^2)$ dostajemy $T(n)=\Theta(n^2\lg n)$.

\subexercise{}
Dla tych samych $a$ i $b$ ale $f(n)=n^3$, mamy $f(n)=\Omega(n^{2+\epsilon})$ dla $0<\epsilon\le1$ oraz
\[
	4f(n/2) = 4n^3\!/8 = n^3\!/2 = f(n)/2,
\]
czyli warunek regularności jest spełniony dla stałej $c=1/2$, a zatem $T(n)=\Theta(n^3)$.

\exercise{} %4-3.2
Rozwiążmy rekurencję $T(n)$. Ponieważ $n^{\log_ba}=n^{\lg7}$ oraz $f(n)=n^2=O(n^{\lg7-\epsilon})$ dla $0<\epsilon\le\lg7-2$, to z tw.~4.1 zachodzi $T(n)=\Theta(n^{\lg7})$.

Pozostaje teraz zbadanie nierówności $T'(n)<T(n)$ w zależności od wartości $a$, bo w rekurencji $T'(n)$ jest $n^{\log_ba}=n^{\log_4a}$ oraz $f(n)=n^2$. Załóżmy, że $f(n)=O(n^{\log_4a-\epsilon})$, co jest prawdą dla $a>16$ i wtedy $T'(n)=\Theta(n^{\log_4a})$. Algorytm $A'$ jest efektywniejszy od algorytmu $A$, gdy $\log_4a<\lg7$, skąd $16<a<49$. Pozostałe przypadki tw.~4.1 można stosować, o ile $a\le16$, zatem pomińmy ich sprawdzanie.

Największą wartością $a$, dla której algorytm $A'$ jest bardziej efektywny od algorytmu $A$, jest~$48$.

\exercise{} %4-3.3
Ponieważ $a=1$ oraz $b=2$, to $n^{\log_ba}=n^0=1$ jest funkcją stałą. W rekurencji tej $f(n)$ także jest stałe, a więc $f(n)=\Theta(n^{\log_ba})$ oraz $T(n)=\Theta(n^{\log_ba}\lg n)=\Theta(\lg n)$.

\exercise{} %4-3.4
Dla rekurencji $T(n)$ mamy $a=4$, $b=2$ oraz $f(n)=n^2\lg n$, a więc $n^{\log_ba}=n^2$, ale nie istnieje takie $\epsilon>0$, że $f(n)=\Omega(n^{2+\epsilon})$. Nie można zatem zastosować w rozwiązaniu twierdzenia o rekurencji uniwersalnej, zatem znajdziemy dla niej asymptotyczne górne oszacowanie zgadując rozwiązanie, a następnie dowodząc jego poprawność metodą podstawiania.

Po pierwszym wywołaniu, rekurencja wnosi koszt równy $n^2\lg n$. Następnie, 4 razy wywołujemy $T(n/2)$, co daje koszt
\[
	4\left(\frac{n^2}{4}\lg n-\frac{n^2}{4}\right) = n^2\lg n-n^2.
\]
Kolejne poziomy wywołań kosztują
\begin{gather*}
	8\left(\frac{n^2}{16}\lg n-\frac{n^2}{16}\right) = \frac{n^2\lg n}{2}-\frac{n^2}{2}, \qquad\phantom{itd.} \\
	16\left(\frac{n^2}{64}\lg n-\frac{n^2}{64}\right) = \frac{n^2\lg n}{4}-\frac{3n^2}{64}, \qquad\text{itd.}
\end{gather*}

Najbardziej znaczący wyraz na kolejnych poziomach wywołań jest prawdopodobnie równy $(n^2\lg n)/2^i$ dla \twoparts{$i$}{tego} poziomu. Ponieważ na poziomie mniej więcej $\lg n$ mamy liście, które wnoszą stały koszt, to otrzymujemy:
\[
	\sum_{i=1}^{\lg n}\frac{n^2\lg n}{2^i} = n^2\lg n\sum_{i=1}^{\lg n}\frac{1}{2^i} = n^2\lg n\left(2-\frac{2}{n}\right) = O(n^2\lg n).
\]
Zgadujemy więc, że rozwiązaniem $T(n)$ jest $O(n^2\lg n)$. Przyjmijmy założenie
\[
	T(n/2) \le c(n/2)^2\lg(n/2),
\]
dla pewnej stałej $c>0$. Otrzymujemy:
\begin{align*}
	T(n) &= 4T(n/2)+n^2\lg n \\
	&\le 4c(n/2)^2\lg(n/2)+n^2\lg n \\
	&= cn^2(\lg n-1)+n^2\lg n \\
	&= cn^2\lg n+n^2(\lg n-c) \\
	&\le cn^2\lg n,
\end{align*}
co zachodzi dla $c\le\lg n$, ale zakładając, że badaliśmy rekurencję począwszy od $n=2$, możemy uważać $c$ za stałą nie przekraczającą~1. Przypadkiem brzegowym jest $T(2)=1$, dla którego nierówność istotnie zachodzi. Rozwiązaniem rekurencji $T(n)$ jest zatem $O(n^2\lg n)$.

\exercise{} %4-3.5
Przyjmując $a=4$, $b=2$ oraz $f(n)=n^2\lg n$ mamy sytuację z poprzedniego zadania.

\subchapter{Dowód twierdzenia o rekurencji uniwersalnej}

\exercise{} %4-4.1
Wykażemy metodą indukcji, że $n_j=\left\lceil n/b^j\right\rceil$. Z definicji~(4.12) bezpośrednio wynika prawdziwość tego wzoru dla $j=0$. Przyjmijmy zatem, że dla $j>0$ zachodzi $n_{j-1}=\left\lceil n/b^{j-1}\right\rceil$. Wykorzystując tożsamość~(3.4) otrzymujemy
\[
	n_j = \lceil n_{j-1}/b\rceil = \left\lceil\left\lceil n/b^{j-1}\right\rceil\!/b\right\rceil = \left\lceil n/b^j\right\rceil,
\]
co należało pokazać.

\exercise{} %4-4.2
Zastąpmy drugi przypadek tw.~4.1 ogólniejszym warunkiem, tzn. jeśli $f(n)=\Theta(n^{\log_ba}\lg^kn)$, to zachodzi $T(n)=\Theta(n^{\log_ba}\lg^{k+1}n)$, dla $k\ge0$. Dla tak zmodyfikowanego twierdzenia należy przeprowadzić dowód analogicznie zmodyfikowanych lematów~4.3 i~4.4.

\begin{proof}[Dowód lematu~4.3]
	Przy założeniu, że $f(n)=\Theta(n^{\log_ba}\lg^kn)$ otrzymujemy, że
	\[
		f(n/b^j)=\Theta\bigl((n/b^j)^{\log_ba}\lg^k(n/b^j)\bigr).
	\]
	Po podstawieniu do wzoru na $g(n)$:
	\[
		g(n) = \Theta\biggl(\sum_{j=0}^{\log_bn-1}a^j\left(\frac{n}{b^j}\right)^{\log_ba}\lg^k\frac{n}{b^j}\biggr),
	\]
	mamy dalej:
	\begin{align*}
		\sum_{j=0}^{\log_bn-1}a^j\left(\frac{n}{b^j}\right)^{\log_ba}\lg^k\frac{n}{b^j} &= n^{\log_ba}\sum_{j=0}^{\log_bn-1}\left(\frac{a}{b^{\log_ba}}\right)^j\lg^k\frac{n}{b^j} \\
		&= n^{\log_ba}\sum_{j=0}^{\log_bn-1}(\lg n-j\lg b)^k \\
		&= n^{\log_ba}\cdot\Theta(\lg^{k+1}n) \\
		&= \Theta(n^{\log_ba}\lg^{k+1}n).
	\end{align*}
	Skorzystano z tego, że $(\lg n-j\lg b)^k=\Theta(\lg^kn)$ na podstawie \zad{3.1-2}, a~następnie zauważając, że
	\[
		\sum_{j=0}^{\log_bn-1}\Theta(\lg^kn) = \log_bn\cdot\Theta(\lg^kn) = \Theta(\lg^{k+1}n).
	\]
\end{proof}

\begin{proof}[Dowód lematu~4.4]
	Wystarczy wykazać jedynie drugi przypadek, ponieważ $f(n)=\Theta(\lg^{k+1}n)$.
	\[
		T(n) = \Theta(n^{\log_ba})+\Theta(n^{\log_ba}\lg^{k+1}n) = \Theta(n^{\log_ba}\lg^{k+1}n),
	\]
	co kończy dowód i jednocześnie pokazuje prawdziwość głównego twierdzenia.
\end{proof}

\exercise{} %4-4.3
Warunek $af(n/b)\le cf(n)$ implikuje
\[
	f(n) \ge (a/c)f(n/b),
\]
a zatem iterując powyższe dostajemy
\[
	f(n) \ge (a/c)f(n/b) \ge (a/c)^2f\bigl(n/b^2\bigr) \ge \dots \ge (a/c)^if\bigl(n/b^i\bigr).
\]
Niech $i=\lceil\log_bn\rceil$ i wtedy zachodzi
\[
	f(n) \ge (a/c)^{\lceil\log_bn\rceil}f\bigl(n/b^{\lceil\log_bn\rceil}\bigr).
\]
Na mocy nierówności~(3.3), $\lceil\log_bn\rceil\le\log_bn+1$, a zatem
\[
	f(n) \ge \frac{a^{\lceil\log_bn\rceil}}{c^{\lceil\log_bn\rceil}}f\bigl(n/(nb)\bigr) \ge \frac{a^{\log_bn-1}}{c^{\log_bn+1}}f(b) \ge \frac{a^{-1}n^{\log_ba}}{cn^{\log_bc}}f(b) \ge \frac{f(b)}{ac}\cdot\frac{n^{\log_ba}}{n^{\log_bc}}.
\]
Ponieważ $c<1$ oraz $b>1$, to $\log_bc<0$, przyjmijmy więc $\epsilon=-\log_bc$, skąd
\[
	f(n) \ge \frac{f(b)}{ac}\cdot\frac{n^{\log_ba}}{n^\epsilon} = \frac{f(b)}{ac}n^{\log_ba+\epsilon},
\]
a zatem $f(n)=\Omega(n^{\log_ba+\epsilon})$, co należało wykazać.

\problems

\exercise{Przykłady rekurencji} %4-1
W punktach (a)\nobreakdash--(f) skorzystano z twierdzenia o rekurencji uniwersalnej.

\subexercise{} %4-1(a)
\[
	n^{\log_ba} = n^{\log_22} = n \quad\text{oraz}\quad f(n) = n^3 = \Omega(n^{1+\epsilon}) \quad\text{dla $0<\epsilon\le2$}
\]
Ponieważ warunek regularności jest spełniony:
\begin{align*}
	2f(n/2) &\le cf(n) \\
	2n^3\!/8 &\le cn^3 \\
	c &\ge 1/4,
\end{align*}
to stąd wnioskujemy, że $T(n)=\Theta(n^3)$.

\subexercise{} %4-1(b)
\[
	n^{\log_ba} = n^{\log_{10/9}1} = 1 \quad\text{oraz}\quad f(n) = n = \Omega(n^\epsilon) \quad\text{dla $0<\epsilon\le1$}
\]
Badamy warunek regularności:
\begin{align*}
	f(9n/10) &\le cf(n) \\
	9n/10 &\le cn \\
	c &\ge 9/10
\end{align*}
i stwierdzamy, że $T(n)=\Theta(n)$.

\subexercise{} %4-1(c)
\[
	n^{\log_ba} = n^{\log_416} = n^2 \quad\text{oraz}\quad f(n) = n^2 = \Theta(n^2),
\]
a stąd $T(n)=\Theta(n^2\lg n)$.

\subexercise{} %4-1(d)
\[
	n^{\log_ba} = n^{\log_37} \quad\text{oraz}\quad f(n) = n^2 = \Omega(n^{\log_37+\epsilon}) \quad\text{dla $0<\epsilon\le2-\log_37$}
\]
Warunek regularności zachodzi:
\begin{align*}
	7f(n/3) &\le cf(n) \\
	7n^2\!/9 &\le cn^2 \\
	c &\ge 7/9,
\end{align*}
a zatem $T(n)=\Theta(n^2)$.

\subexercise{} %4-1(e)
\[
	n^{\log_ba} = n^{\lg7} \quad\text{oraz}\quad f(n) = n^2 = O(n^{\lg7-\epsilon}) \quad\text{dla $0<\epsilon\le\lg7-2$},
\]
a stąd $T(n)=\Theta(n^{\lg7})$.

\subexercise{} %4-1(f)
\[
	n^{\log_ba} = n^{\log_42} = n^{1/2} \quad\text{oraz}\quad f(n) = \sqrt{n} = \Theta(n^{1/2}),
\]
a stąd $T(n)=\Theta\bigl(\!\sqrt{n}\lg n\bigr)$.

\subexercise{} %4-1(g)
Zauważmy, że rekurencja rozwija się następująco:
\begin{align*}
	T(n) &= T(n-1)+n = T(n-2)+(n-1)+n = \cdots \\
	&= 1+2+\cdots+(n-1)+n \\
	&= \sum_{i=1}^ni = \frac{n(n+1)}{2},
\end{align*}
a stąd otrzymujemy, że $T(n)=\Theta(n^2)$.

\subexercise{} %4-1(h)
Niech $n=2^m$, skąd $m=\lg n$. Rekurencja przyjmuje teraz postać
\[
	T(2^m) = T(2^{m/2})+1.
\]
Podstawiając $S(m)$ za $T(2^m)$, otrzymujemy
\[
	S(m) = S(m/2)+1.
\]
Ponieważ rozwiązaniem ostatniej rekurencji jest $\Theta(\lg m)$ (co wykazano w~\zad{4.3-3}), to stąd mamy, że $T(n)=T(2^m)=S(m)=\Theta(\lg m)=\Theta(\lg\lg n)$.

\exercise{Szukanie brakującej liczby całkowitej} %4-2
Liczby z zakresu $0\twodots n$ reprezentowane są binarnie za pomocą $\lfloor\lg n\rfloor+1$ bitów. Można dla wygody przyjąć, że $n$ jest potęgą~2 pomniejszoną o~1. W przeciwnym przypadku rozszerzamy tablicę $A$, umieszczając w niej kolejne liczby naturalne większe od starego rozmiaru $A$ tak, by $n$ było o~1 mniejsze od pewnej potęgi~2. Ta modyfikacja sprawi, że wszystkie liczby w $A$ będą mieć tyle samo bitów, a rozmiar problemu urośnie co najwyżej dwukrotnie.

Badając najmniej znaczące bity liczb z tablicy $A$, sprawdzamy ich parzystość. W zakresie $0\twodots n$ jest $n/2$ liczb parzystych i tyle samo nieparzystych. Jeśli wsród pobranych bitów jest więcej jedynek, to brakuje liczby parzystej, a~jeśli więcej zer, to brakująca liczba jest nieparzysta. W zależności od przypadku, odrzucamy $n/2$ liczb o parzystości różnej od brakującej. Wsród pozostałych badamy następnie drugi najmniej znaczący bit i analogicznie postępując wyznaczamy $n/4$ kolejnych liczb do wyeliminowania. Powtarzając opisane czynności aż do odrzucenia wszystkich liczb z tablicy, poznamy tę, której brakuje.

Czas działania zaprezentowanego tutaj algorytmu można zapisać w postaci rekurencji $T(n)=T(n/2)+n$, której rozwiązaniem jest $O(n)$, co można łatwo pokazać przy użyciu twierdzenia~4.1. Widać teraz, że oryginalny problem (z~dowolnym $n$) wprowadził tylko stały czynnik do czasu działania algorytmu.

\exercise{Koszty przekazywania parametrów} %4-3

\subexercise{} %4-3(a)
W pierwszym przypadku dostajemy rekurencję
\[
	T(N) = \begin{cases}
		\Theta(1), & \text{dla $N=1$,} \\
		T(N/2)+\Theta(1), & \text{dla $N>1$,}
	\end{cases}
\]
która posiada rozwiązanie $T(N)=O(\lg N)$, co zostało pokazane w~\zad{4.3-3}.

\medskip
\noindent Rekurencje ostatnich dwóch strategii mają identyczną postać
\[
	T(N) = \begin{cases}
		\Theta(1), & \text{dla $N=1$} \\
		T(N/2)+\Theta(N), & \text{dla $N>1$.}
	\end{cases}
\]
Jej rozwiązanie jest identyczne z rozwiązaniem rekurencji~(4.4) i wynosi $T(N)=O(N\lg N)$.

\subexercise{} %4-3(b)
W każdym z trzech przypadków, rekurencja sprowadza się do postaci
\[
	T(N) = \begin{cases}
		\Theta(1), & \text{dla $N=1$,} \\
		2T(N/2)+\Theta(N), & \text{dla $N>1$,}
	\end{cases}
\]
której rozwiązaniem jest $T(N)=O(N\lg N)$, co można pokazać wykorzystując twierdzenie~4.1.

\exercise{Więcej przykładów rekurencji} %4-4

\subexercise{} %4-4(a)
Wykorzystując twierdzenie o rekurencji uniwersalnej, mamy
\[
	n^{\log_ba} = n^{\lg3} \quad\text{oraz}\quad f(n) = n\lg n = O(n^{\lg3-\epsilon}), \quad\text{dla $0<\epsilon<\lg3-1$,}
\]
a stąd $T(n)=\Theta(n^{\lg3})$.

\subexercise{} %4-4(b)
Z twierdzenia o rekurencji uniwersalnej obliczamy
\[
	n^{\log_ba} = n^{\log_55} = n,
\]
jednak dla żadnego $\epsilon>0$ nie jest prawdą, że
\[
	f(n) = \frac{n}{\lg n} = O(n^{1-\epsilon}),
\]
ponieważ dla pewnej stałej $c>0$ i dowolnie dużych $n$ musiałoby zachodzić
\[
	\frac{n^\epsilon}{\lg n} \le c,
\]
a ponieważ $n^\epsilon=\omega(\lg n)$, to niezależnie od wyboru $\epsilon$, dla dużych wartości $n$ licznik będzie dowolnie większy od mianownika i ułamka nie da się z tego powodu ograniczyć stałą.

Skorzystajmy zatem z innego sposobu na obliczenie $T(n)$, rozważając ogólną rekurencję
\[
	T_a(n) = \begin{cases}
		\Theta(1), & \text{dla $1\le n<a$,} \\
		aT_a(n/a)+n/\!\lg n, & \text{dla $n\ge a$,}
	\end{cases}
\]
dla pewnego całkowitego $a\ge2$, której drzewo przedstawia rys.~\ref{fig:4-4b}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.5}
	\end{center}
	\caption{Drzewo rekursji $T_a(n)=aT_a(n/a)+n/\!\lg n$} \label{fig:4-4b}
\end{figure}

Na \twoparts{$i$}{tym} poziomie tego drzewa $a^i$ węzłów wnosi koszt równy $n/(a^i\lg(n/a^i))$, a cały poziom -- $n/(\lg n-i\lg a)$. Ponieważ drzewo to posiada $\log_an+1$ poziomów, to kosztem ostatniego poziomu jest $\Theta(a^{\log_an})=\Theta(n)$, skąd dostajemy
\begin{align*}
	T_a(n) &= \sum_{i=0}^{\log_an-1}\frac{n}{\lg n-i\lg a}+\Theta(n) \\
	&= \frac{n}{\lg a}\sum_{i=0}^{\log_an-1}\frac{1}{\log_an-i}+\Theta(n) \\
	&= \frac{n}{\lg a}\sum_{i=1}^{\log_an}\frac{1}{i}+\Theta(n) \\
	&= \frac{nH_{\log_an}}{\lg a}+\Theta(n) \\
	&= \Theta(n\lg\lg n),
\end{align*}
przy czym ostatnia równość wynika z wzoru~(A.7).

Wykażemy teraz otrzymane oszacowanie przy pomocy metody podstawiania. Jednak przyjęcie narzucającego się oszacowania przysparza wielu kłopotów w samym dowodzie w postaci skomplikowanych przekształceń algebraicznych. Zamiast tego wykażemy, że $T_a(n)\le n(1+H_{\lfloor\log_an\rfloor})$ oraz $T_a(n)\ge nH_{\lceil\log_an\rceil}$, przy czym dla uproszczenia dowodu definiujemy dodatkowo $H_0=0$. Ponieważ $H_k=\Theta(\lg k)$, to zachodzi $H_{\lfloor\log_an\rfloor}=\Theta(\lg\lfloor\log_an\rfloor)=\Theta(\lg\lg n)$ oraz $H_{\lceil\log_an\rceil}=\Theta(\lg\lceil\log_an\rceil)=\Theta(\lg\lg n)$, a więc nasz dowód rzeczywiście wykaże, że $T_a(n)=\Theta(n\lg\lg n)$.
\begin{align*}
	T_a(n) &= aT_a(n/a)+\frac{n}{\lg n} \\
	&\le a(n/a)(1+H_{\lfloor\log_a(n/a)\rfloor})+\frac{n\log_a2}{\log_an} \\
	&\le n(1+H_{\lfloor\log_an-1\rfloor})+\frac{n}{\log_an} \\
	&= n\left(1+H_{\lfloor\log_an\rfloor-1}+\frac{1}{\log_an}\right) \\
	&\le n\left(1+H_{\lfloor\log_an\rfloor-1}+\frac{1}{\lfloor\log_an\rfloor}\right) \\
	&= n(1+H_{\lfloor\log_an\rfloor})
\end{align*}
W dowodzie dolnego oszacowania, mamy
\begin{align*}
	T_a(n) &= aT_a(n/a)+\frac{n}{\lg n} \\
	&\ge a(n/a)H_{\lceil\log_a(n/a)\rceil}+\frac{n\log_a2}{\log_an} \\
	&\ge nH_{\lceil\log_an-1\rceil}+\frac{n}{\log_an} \\
	&= n\left(H_{\lceil\log_an\rceil-1}+\frac{1}{\log_an}\right) \\
	&\ge n\left(H_{\lceil\log_an\rceil-1}+\frac{1}{\lceil\log_an\rceil}\right) \\
	&= nH_{\lceil\log_an\rceil}.
\end{align*}

Za podstawę indukcji możemy przyjąć warunek brzegowy rekurencji $T_a(1)=1$, gdyż wtedy $\log_a1=0$ i zachodzą $T_a(1)\le 1+H_0$ oraz $T_a(1)\ge H_0$, skąd $T_a(n)=\Theta(n\lg\lg n)$.

% Dla górnego oszacowania przyjmijmy założenie
% \[
% 	T_a(n/a) \le c_1(n/a)\lg\lg(n/a).
% \]
% Mamy zatem
% \begin{align*}
% 	T_a(n) &= aT_a(n/a)+\frac{n}{\lg n} \\
% 	&\le ac_1(n/a)\lg\lg(n/a)+\frac{n}{\lg n} \\
% 	&= c_1n\lg\lg n+c_1n\lg\frac{\lg(n/a)}{\lg n}+\frac{n}{\lg n} \\
% 	&\le c_1n\lg\lg n,
% \end{align*}
% gdzie ostatnia nierówność zachodzi, o ile
% \[
% 	c_1n\lg\frac{\lg(n/a)}{\lg n}+\frac{n}{\lg n} \le 0,
% \]
% skąd
% \[
% 	c_1 \ge -\frac{1}{\lg n\lg(1-\log_na)} > 0, %zle
% \]
% dla każdego $n>a$, a więc $T_a(n)=O(n\lg\lg n)$.
% 
% W dowodzie dolnego oszacowania skorzystajmy z
% \[
% 	T_a(n/a) \ge c_2(n/a)\lg\lg(n/a)-b\lg(n/a),
% \]
% i po podstawieniu, mamy
% \begin{align*}
% 	T_a(n) &= aT_a(n/a)+\frac{n}{\lg n} \\
% 	&\ge c_2(n/a)\lg\lg(n/a)-ab\lg(n/a)+\frac{n}{\lg n} \\
% 	&\ge c_2n\lg\lg n+c_2n\lg\frac{\lg(n/a)}{\lg n}-ab\lg n+ab\lg a+\frac{n}{\lg n} \\
% 	&\ge c_2n\lg\lg n-b\lg n,
% \end{align*}
% co jest prawdą dla
% \[
% 	c_2n\lg\frac{\lg(n/a)}{\lg n}-(a-1)b\lg n+ab\lg a+\frac{n}{\lg n} \ge 0,
% \]
% czyli
% \[
% 	c_2 \le \frac{(a-1)b\lg n-ab\lg a-\frac{n}{\lg n}}{n\lg(1-\log_na)}, %wtf
% \]
% skąd mamy, że $T_a(n)=\Omega(n\lg\lg n)$ i oszacowanie dokładne na $T_a(n)$ zostało ostatecznie wykazane.

Stosując wykazane oszacowanie do rekurencji $T(n)\equiv T_5(n)$ z treści zadania, dostajemy oczywiście $T(n)=\Theta(n\lg\lg n)$.

\subexercise{} %4-4(c)
Z twierdzenia o rekurencji uniwersalnej,
\[
	n^{\log_ba} = n^{\lg4} = n^2 \quad\text{oraz}\quad f(n) = n^{5/2} = \Omega(n^{2+\epsilon}), \quad\text{dla $0<\epsilon\le1/2$,}
\]
Badamy warunek regularności:
\begin{align*}
	4f(n/2) &\le cf(n) \\
	\frac{4n^{5/2}}{2^{5/2}} &\le cn^{5/2} \\
	c &\ge \frac{1}{\sqrt{2}}
\end{align*}
i stwierdzamy, że $T(n)=\Theta(n^{5/2})$.

\subexercise{} %4-4(d)
Wykażemy, że stała~5 w argumencie $T$ nie wpływa na postać rozwiązania -- rozważając rekurencję $T'(n)=3T'(n/3)+n/2$ i rozwiązując ją za pomocą twierdzenia o~rekurencji uniwersalnej, dostajemy $T'(n)=\Theta(n\lg n)$. Udowodnimy teraz metodą podstawiania, że identyczny wynik jest rozwiązaniem rekurencji $T(n)$.

Wykorzystując założenie
\[
	T(n/3+5) \le c(n/3+5)\lg(n/3+5)
\]
dla pewnej stałej $c>0$, otrzymujemy:
\begin{align*}
	T(n) &\le 3c(n/3+5)\lg(n/3+5)+n/2 \\
	&\le 3c(n/3+5)\lg n+n/2 \\
	&= cn\lg n+15c\lg n+n/2,
\end{align*}
co zachodzi, o ile $n/3+5\le n$, skąd $n\ge8$. Niestety wyrażenie $15c\lg n+n/2$ jest nieujemne dla każdego $n$, a więc nie udowodnimy oszacowania. Jesteśmy zmuszeni wzmocnić nasze założenie; niech
\[
	T(n/3+5) \le c(n/3+5)\lg(n/3+5)-b(n/3+5),
\]
dla nowej stałej $b\ge0$. Mamy teraz
\begin{align*}
	T(n) &\le 3c(n/3+5)\lg(n/3+5)-3b(n/3+5)+n/2 \\
	&= cn\lg(n/3+5)+15c\lg(n/3+5)-bn-15b+n/2 \\
	&\le cn\lg(2n/3)+15c\lg n-bn-15b+n/2 \\
	&= cn\lg n-bn+cn\lg(2/3)+15c\lg n-15b+n/2 \\
	&\le cn\lg n-bn,
\end{align*}
co zachodzi, o ile $n\ge15$ oraz
\[
	-\frac{c\lg\frac{2}{3}+\frac{1}{2}}{15}\,n \ge c\lg n-b.
\]
Nierówność ta jest prawdziwa dla dostatecznie dużych $n$, jeśli przyjmiemy $c>1/(2\lg(3/2))$, wtedy współczynnik przy $n$ po lewej stronie jest dodatni, a wiadomo że zachodzi $n=\omega(\lg n)$. Można więc przyjąć $b=c=2$.

Analogicznie dla dolnego oszacowania, przyjmując, że
\[
	T(n/3+5) \ge c'(n/3+5)\lg(n/3+5)-b'(n/3+5),
\]
gdzie $c'>0$ i~$b'\ge0$ są pewnymi stałymi, dostajemy
\begin{align*}
	T(n) &\ge 3c'(n/3+5)\lg(n/3+5)-3b'(n/3+5)+n/2 \\
	&\ge 3c'(n/3)\lg(n/3)-3b'n+n/2 \\
	&= c'n\lg n-b'n-2b'n-c'n\lg3+n/2 \\
	&\ge c'n\lg n-b'n,
\end{align*}
gdzie ostatnia nierówność zachodzi, o ile $c\lg3+2b\le1/2$. Spełniamy ją poprzez przyjęcie wartościowania $b'=0$, $c'=1/4$.

Otrzymaliśmy żądane asymptotyczne oszacowanie dokładne dla $T(n)$, pozostaje jedynie zbadać zachowanie rekurencji w przypadkach brzegowych.

Zauważmy, że obliczanie wartości z wzoru $T(n)=3T(n/3+5)+n/2$ dla $n<8$ nie ma sensu, bo wtedy $T(n)$ nie zależy od niższych wyrazów. Przyjmijmy zatem, że $T(n)=1$ dla wszystkich $n<8$. Dowody oszacowań zakładały $n\ge15$, obliczmy więc $T(15)$ i niech stanowi ono przypadek brzegowy rekurencji.
\[
	T(15) = 3T(10)+7{,}5 = 3(3T(8)+5)+7{,}5 = 3\bigl(3(3T(7)+4)+5\bigr)+7{,}5 = 85{,}5,
\]
a zatem zachodzi
\[
	15c'\lg15 \le T(15) \le 15c\lg15-15b,
\]
dla stałych $b$,~$c$,~$c'$ z dowodów oszacowań. Przyjmujemy więc $T(15)$ za podstawę indukcji, co kończy dowód na oszacowanie dokładne $T(n)=\Theta(n\lg n)$.

\subexercise{} %4-4(e)
Mamy do czynienia z rekurencją $T_a(n)$ dla $a=2$, którą rozważaliśmy w punkcie~(b). Zgodnie z przedstawionym tam rozumowaniem wnioskujemy, że $T(n)=\Theta(n\lg\lg n)$.

\subexercise{} %4-4(f)
W celu rozwiązania rekurencji wykorzystamy metodę drzewa rekursji. Drzewo to zostało przedstawione na rys.~\ref{fig:4-4f}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.6}
	\end{center}
	\caption{Drzewo rekursji $T(n)=T(n/2)+T(n/4)+T(n/8)+n$} \label{fig:4-4f}
\end{figure}

Zauważmy, że najszybciej maleją argumenty na skrajnie prawej gałęzi. Koszt jej węzła na \twoparts{$i$}{tym} poziomie wynosi $n/8^i$. Dla pewnego $h$ i pewnej stałej $c>0$ zachodzi $n/8^h=c$, skąd $h=\log_8(n/c)$ i na tym poziomie gałąź ta posiada liścia. Sumując koszty poziomów drzewa od korzenia aż do \twoparts{$h$}{tego} poziomu uzyskujemy dolne oszacowanie rekurencji:
\begin{align*}
	T(n) &\ge \sum_{i=0}^{\log_8(n/c)-1}\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&= \frac{1-\left(\frac{7}{8}\right)^{\log_8(n/c)}}{1-\frac{7}{8}}n+\Theta(1) \\
	&= 8n\left(1-\left(\frac{n}{c}\right)^{\log_8(7/8)}\right)+\Theta(1) \\
	&\ge 8n\left(1-\left(\frac{n}{c}\right)\right)+\Theta(1).
\end{align*}
Oszacowaniem ostatniego wyrażenia jest $\Theta(n)$, otrzymujemy zatem, że $T(n)=\Omega(n)$.

Zbadajmy teraz górne oszacowanie rekurencji $T(n)$ poprzez dokonanie obserwacji, że najwolniej malejącymi węzłami drzewa są węzły ze skrajnie lewej gałęzi, które wnoszą koszt równy $n/2^i$ na \twoparts{$i$}{tym} poziomie, więc liść znajduje się na poziomie $h'=\lg(n/d)$ dla pewnej stałej $d>0$.
\begin{align*}
	T(n) &\le \sum_{i=0}^{\lg(n/d)-1}\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&< \sum_{i=0}^\infty\left(\frac{7}{8}\right)^in+\Theta(1) \\
	&= \frac{n}{1-\frac{7}{8}}+\Theta(1) \\
	&= 8n+\Theta(1),
\end{align*}
skąd mamy, że $T(n)=O(n)$. Asymptotycznym dokładnym oszacowaniem rekurencji jest zatem $\Theta(n)$.

\subexercise{} %4-4(g)
Rozwijając rekurencję
\[
	T(n) = \frac{1}{n}+\frac{1}{n-1}+\cdots+\frac{1}{2}+\frac{1}{1} = H_n,
\]
i korzystając z~\zad{A.2-3} mamy, że $T(n)=\Theta(\lg n)$.

\subexercise{} %4-4(h)
Ponieważ
\[
	T(n) = \lg n+\lg(n-1)+\cdots+\lg2+\lg 1 = \lg\biggl(\prod_{i=1}^ni\biggr) = \lg(n!),
\]
to z wzoru~(3.18) dostajemy $T(n)=\Theta(n\lg n)$.

\subexercise{} %4-4(i)
Rozwijamy rekurencję, otrzymując
\begin{align*}
	T(n) &= 2\lg n+2\lg(n-2)+\cdots+2\lg4+2\lg2 \\
	&= 2\lg\biggl(\prod_{i=1}^{n/2}2i\biggr) \\
	&= 2\lg\bigl(2^{n/2}(n/2)!\bigr) \\
	&= 2\bigl(\lg 2^{n/2}+\lg((n/2)!)\bigr).
\end{align*}
Wykorzystując wzór~(3.18) dostajemy
\[
	T(n) = n+2\Theta((n/2)\lg (n/2)) = \Theta(n\lg n).
\]

\subexercise{} %4-4(j)
Na \twoparts{$i$}{tym} poziomie drzewa rekursji przedstawionego na rys.~\ref{fig:4-4j} znajduje się $n^{1/2^i}$ węzłów o koszcie $n^{1/2^i}$, cały poziom wnosi zatem koszt równy $n$. Należy jeszcze zbadać, dla jakiego $i$ koszt każdego węzła na \twoparts{$i$}{tym} poziomie jest stałą:
\[
	n^{1/2^i} = c, \quad\text{skąd}\quad i = \lg\log_cn.
\]
Jest zatem w drzewie $\Theta(\lg\lg n)$ poziomów, skąd dostajemy, że rozwiązaniem rekurencji jest $T(n)=\Theta(n\lg\lg n)$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig04.7}
	\caption{Drzewo rekursji $T(n)=\sqrt{n}\;T(\!\sqrt{n})+n$} \label{fig:4-4j}
	\end{center}
\end{figure}

Udowodnimy teraz otrzymane oszacowanie wykorzystując do tego celu metodę podstawiania. Dla pewnych stałych $b$,~$c>0$ przyjmijmy, że
\[
	T(\!\sqrt{n}) \le c\sqrt{n}\lg\lg\sqrt{n}-b\sqrt{n}
\]
(odejmujemy składnik niższego rzędu, by uzyskać nieco mocniejsze założenie i uprościć rachunki). Mamy teraz
\begin{align*}
	T(n) &= \sqrt{n}\;T(\!\sqrt{n})+n \le \sqrt{n}\left(c\sqrt{n}\lg\lg\sqrt{n}-b\sqrt{n}\right)+n = cn\lg\frac{\lg n}{2}+n(1-b) \\
	&= cn(\lg\lg n-\lg2)+n(1-b) = cn\lg\lg n+n(1-b-c) \le cn\lg\lg n-bn.
\end{align*}
Ostatnia nierówność zachodzi, jeśli przyjmiemy $c\ge1$. Zauważmy, że po zmianie znaku nierówności na przeciwny, wyprowadzenie pozostanie prawdziwe dla $c\le1$. Udowodniliśmy oszacowanie górne i dolne, a zatem rozwiązanie rekurencji zostało uzasadnione.

\exercise{Liczby Fibonacciego} %4-5

\subexercise{} %4-5(a)
Wprost z definicji $\mathcal{F}(z)$ mamy:
\begin{align*}
	\mathcal{F}(z) &= \sum_{i=0}^\infty F_iz^i \\
	&= F_0+zF_1+\sum_{i=2}^\infty (F_{i-1}+F_{i-2})z^i \\
	&= z+\sum_{i=2}^\infty F_{i-1}z^i+\sum_{i=2}^\infty F_{i-2}z^i \\
	&= z+\sum_{i=1}^\infty F_iz^{i+1}+\sum_{i=0}^\infty F_iz^{i+2} \\[2mm]
	&= z+z\mathcal{F}(z)+z^2\mathcal{F}(z),
\end{align*}
a zatem wzór zachodzi.

\subexercise{} %4-5(b)
Z tożsamości z poprzedniego punktu wynika pierwsza równość:
\begin{align}
	\mathcal{F}(z) &= z+z\mathcal{F}(z)+z^2\mathcal{F}(z) \nonumber \\
	(1-z-z^2)\mathcal{F}(z) &= z \nonumber \\
	\mathcal{F}(z) &= \frac{z}{1-z-z^2}. \label{eq:4-5b_1}
\end{align}
Mianownik prawej strony~(\ref{eq:4-5b_1}) jest trójmianem kwadratowym, który można zapisać w równoważnej postaci:
\begin{equation}
	1-z-z^2 \equiv -(z+\phi)\bigl(z+\widehat\phi\bigr). \label{eq:4-5b_2}
\end{equation}
Trójmian~(\ref{eq:4-5b_2}) przyjmuje wartość~0 dla $z=-\phi$ lub $z=-\widehat\phi$. Ponieważ zachodzi ciekawa własność $\phi\cdot\widehat\phi=-1$, zatem można zapisać trójmian w postaci $(1-\phi z)\bigl(1-\widehat\phi z\bigr)$, skąd wynika druga równość.

Ostatnią z nich dowodzimy dokonując pewnych przekształceń:
\[
	\frac{1}{1-\phi z}-\frac{1}{1-\widehat\phi z} = \frac{1-\widehat\phi z-1+\phi z}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{z\bigl(\phi-\widehat\phi\bigr)}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{z\sqrt{5}}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)}
\]
i zauważając, że zachodzi
\[
	\frac{z}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{1}{\sqrt{5}}\cdot\frac{z\sqrt{5}}{(1-\phi z)\bigl(1-\widehat\phi z\bigr)} = \frac{1}{\sqrt{5}}\left(\frac{1}{1-\phi z}-\frac{1}{1-\widehat\phi z}\right).
\]

\subexercise{} %4-5(c)
Tezę otrzymujemy natychmiast, jeśli w definicji $\mathcal{F}(z)$ podstawimy $F_i=\bigl(\phi^i-\widehat\phi^i\bigr)/\sqrt{5}$, co wykazano w \zad{3.2-6}.

\subexercise{} %4-5(d)
Ponieważ $\bigl|\widehat\phi\bigr|<1$, to prawdą jest, że $\phi^i<1$ dla $i>0$ oraz $\widehat\phi^i/\sqrt{5}<1$. Stąd
\[
	F_i = \frac{\phi^i-\widehat\phi^i}{\sqrt{5}} = \frac{\phi^i}{\sqrt{5}}-\frac{\widehat\phi^i}{\sqrt{5}} < \frac{\phi^i}{\sqrt{5}}-1.
\]
Podstawiając $F_i$ za $\lceil x\rceil$ oraz $\phi^i/\sqrt{5}$ za $x$ we wzorze~(3.5), dowodzimy, że
\[
	F_i = \left\lceil\frac{\phi^i}{\sqrt{5}}\right\rceil.
\]

\subexercise{} %4-5(e)
Tożsamość została udowodniona w \zad{3.2-7}.

\exercise{Testowanie układów VLSI} %4-6

\subexercise{} %4-6(a)
Załóżmy, że w zbiorze układów jest więcej niż $n/2$ dobrych układów i potraktujmy wynik każdego testu dwóch układów jako parę $(r_1,r_2)\in\{{\scriptstyle\rm D},{\scriptstyle\rm Z}\}^2$. Pierwszy element pary jest stwierdzeniem pierwszego układu o drugim, a drugi element -- drugiego o pierwszym, przy czym ${\scriptstyle\rm D}$ oznacza pozytywny wynik testu, a~${\scriptstyle\rm Z}$ -- negatywny. Możliwe jest uzyskanie jednego z czterech wyników:
\begin{itemize}
	\item $({\scriptstyle\rm D},{\scriptstyle\rm D})$ -- implikuje, że oba układy są dobre albo oba są złe,
	\item $({\scriptstyle\rm D},{\scriptstyle\rm Z})$ -- zachodzi tylko wtedy, gdy pierwszy z układów jest zły,
	\item $({\scriptstyle\rm Z},{\scriptstyle\rm D})$ -- zachodzi tylko wtedy, gdy drugi z układów jest zły,
	\item $({\scriptstyle\rm Z},{\scriptstyle\rm Z})$ -- co najmniej jeden z układów jest zły.
\end{itemize}
Ponieważ drugi i trzeci wynik natychmiast determinują nam naturę jednego układu, to załóżmy, że podczas testowania nie uzyskaliśmy żadnego z nich, możemy bowiem odrzucić wyznaczone złe układy z dalszej analizy.

Rozpatrzmy graf $G=(V,E)$, w którym $V$ jest zbiorem układów, a $(u,v)\in E$ wtedy i tylko wtedy, gdy podczas testowania układów $u$ i $v$ otrzymano wynik $({\scriptstyle\rm D},{\scriptstyle\rm D})$. Oznacza to, że każde sąsiednie wierzchołki w tym grafie muszą być albo jednocześnie dobre, albo jednocześnie złe. Zauważmy że jeśli relacja $R$, której reprezentacją jest graf $G$ nie jest przechodnia, to możemy wtedy wskazać pewne złe układy -- co najmniej jeden z wierzchołków nie będących w relacji jest zły, a to z kolei indukuje kolejne złe, które są z nim w relacji. Niech zatem $R$ będzie przechodnia. Jest też oczywiście zwrotna i symetryczna, a jako taka dzieli zbiór $V$ na klasy abstrakcji. To prowadzi do badania grafów będących sumami podgrafów pełnych (klik), jako że każda klasa abstrakcji relacji $R$ tworzy pewną klikę. Każdy z układów dowolnej kliki jest jednocześnie dobry lub jednocześnie zły z każdym innym układem ze swojej kliki, podczas gdy między klikami nie istnieje żadna krawędź, więc co najmniej jedna z dwóch badanych klik musi zawierać wyłącznie złe układy.

Zauważmy, że możemy traktować $G$ jako hipergraf pełny $H=(V_H,E_H)$, gdzie $V_H$ jest zbiorem klik. Ponieważ dla każdej pary $(U,V)\in V_H^2$ co najmniej jedna z klik $U$ lub $V$ zawiera złe elementy, to złymi są elementy należące do klik z $V_H$ z wyjątkiem jednej. Układy z tej kliki są dobre, co gwarantuje nam założenie, że zawsze będzie istnieć w $V_H$ taka klika, która zawiera więcej niż $n/2$ układów. Pozostawiając ją jako dobrą, a oznaczając inne jako złe, będziemy mieć wyznaczone jednoznacznie wszystkie dobre układy spośród $n$ badanych. Istnienie większej ilości złych układów nie pozwoli na wyznaczenie ``największego'' elementu z $V_H$.

\subexercise{NOT COMPLETED!\\} %4-6(b)
Utwórzmy ciąg układów $u_1,u_2,\dots,u_n$ i wykonajmy $\lfloor n/2\rfloor$ testów -- między układami $u_1$ i $u_2$, $u_2$ i $u_3$, itd. aż do $u_{\lfloor n/2\rfloor}$ i $u_{\lfloor n/2\rfloor+1}$. Pozostałe układy pozostaną nieprzetestowane w danym etapie. Tak jak w poprzednim punkcie zakładamy, że nie możemy dostać wyniku $({\scriptstyle\rm D},{\scriptstyle\rm Z})$ lub $({\scriptstyle\rm Z},{\scriptstyle\rm D})$.

Rozważmy ciągi układów, dla których zaszło $({\scriptstyle\rm D},{\scriptstyle\rm D})$ między każdą parą sąsiadów. 

\subexercise{} %4-6(c)
Wykorzystując wynik poprzedniego punktu, dostajemy następującą rekurencję opisującą liczbę testów koniecznych do znalezienia jednego dobrego układu:
\[
	T(n) =
	\begin{cases}
		\Theta(1), & \text{dla $1\le n\le2$} \\
		T(\lfloor n/2\rfloor) + \lfloor n/2\rfloor, & \text{dla $n>2$}.
	\end{cases}
\]
Pomijając podłogi i stosując twierdzenie o rekurencji uniwersalnej, dostajemy jej rozwiązanie: $T(n)=\Theta(n)$.

Ponieważ w poprzednim punkcie znaleźliśmy dobry układ $u$, to wykorzystajmy go do znalezienia kolejnych. Testujemy tenże układ z pozostałymi $n-1$. Wynikiem testu $u$ z pewnym innym układem $v$, nie może być $({\scriptstyle\rm D},{\scriptstyle\rm Z})$, a więc możliwe są trzy sytuacje. Jeśli otrzymamy $({\scriptstyle\rm D},{\scriptstyle\rm D})$, to oznacza to, że oba układy są tak samo dobre, a więc $v$ również jest dobry. Uzyskując wynik $({\scriptstyle\rm Z},{\scriptstyle\rm D})$, mamy natychmiast, że $v$ jest zły, podobnie w wypadku, gdy wynikiem testu będzie $({\scriptstyle\rm Z},{\scriptstyle\rm Z})$ -- wtedy co najmniej jeden z testowanych układów jest zły, ale nie może nim być $u$. Wynika stąd, że sprawdzając $u$ z~$n-1$ innymi układami, wykonamy $n-1$ testów, a ponieważ stwierdziliśmy, że $u$ jest dobre za pomocą $\Theta(n)$ testów, to znalezienie wszystkich dobrych układów można wykonać przeprowadzając również $\Theta(n)$ testów.

\exercise{Tablice Monge'a} %4-7

\subexercise{} %4-7(a)
\noindent\emph{Dowód $\Rightarrow$.} Tablica Monge'a $A$ spełnia nierówność
\[
	A[i,j]+A[k,l] \le A[i,l]+A[k,j], \quad\text{dla $1\le i<k\le m$ oraz $1\le j<l\le n$}.
\]
W szczególności zaś może być $k=i+1$ oraz $l=j+1$, zatem implikacja zachodzi.
\bigskip

\noindent\emph{Dowód $\Leftarrow$.} Dowodzimy przez indukcję względem liczby wierszy $m$. Zauważmy, że warunek tablicy Monge'a nie ma większego sensu dla tablic jednowierszowych, zatem przyjmijmy $m=2$ za podstawę indukcji. Wtedy $i=1$ oraz $k=2$, skąd
\begin{equation}
	A[1,j]+A[2,j+1] \le A[1,j+1]+A[2,j], \quad\text{dla $1\le j<n$}. \label{eq:4-7a}
\end{equation}
Dodajmy teraz do siebie powyższą nierówność dla pewnego $j<n-1$ do siebie samej ale z $j+1$ w miejscu $j$. Po zredukowaniu zbędnych składników, dostajemy
\[
	A[1,j]+A[2,j+2] \le A[2,j]+A[1,j+2].
\]
Do ostatniej nierówności można ponownie dodawać~(\ref{eq:4-7a}) podstawiając w miejsce $j$ coraz większe $l<n$ i otrzymując dowolną nierówność stanowiącą warunek tablicy Monge'a.

Niech teraz $m>2$. Dowód wykorzystuje ten sam pomysł z pierwszego kroku indukcji, z tym, że teraz $i$ może przyjmować każdą dopuszczalną wartość. Przyjmujemy ponadto założenie indukcyjne, że dla tablica $A$ obcięta o ostatni wiersz stanowi tablicę Monge'a. Pozostaje zatem wykazać, że zachodzą wszystkie nierówności z definicji tablicy Monge'a dla $k=m$. Zachodzi zatem
\[
	A[i,j]+A[i+1,j+1] \le A[i,j+1]+A[i+1,j] \quad\text{dla $1\le i<m-1$ oraz $1\le j<n$}.
\]
Dodajemy tę nierówność do siebie samej po uprzednim podstawieniu w drugiej z nich wartości $j+1$ w miejsce $j$. Dzięki temu otrzymamy
\[
	A[i,j]+A[i+1,j+2] \le A[i+1,j]+A[i,j+2].
\]
Podobnie jak wcześniej, możemy tak dodawać żądaną ilość razy przyjmując coraz większe wartości za $j$ i dostając wszystkie wymagane nierówności.

Widać zatem, że implikacja jest prawdziwa dla tablic o pewnej ustalonej liczbie kolumn. Dowód dla zmiennej liczby kolumn przeprowadza się analogicznie przez indukcję po $n\ge2$, skąd mamy, że twierdzenie zachodzi dla tablic o dowolnych wymiarach.

\subexercise{} %4-7(b)
Korzystając z poprzedniego punktu można pokazać, że nierówność
\[
	A[1,2]+A[2,3] \le A[1,3]+A[2,2]
\]
jest fałszywa, co zaburza właściwość tablicy Monge'a. By przywrócić własność, można zamienić np. $A[1,3]$ na~25.

\subexercise{} %4-7(c)
Korzystając z nierówności
\begin{equation}
	A[i,j]+A[i+1,j+r] \le A[i,j+r]+A[i+1,j] \label{eq:4-7c}
\end{equation}
dla $0<r\le n-j$, wnioskujemy w następujący sposób. Znajdujemy w pierwszym wierszu tablicy $A$ pierwsze minimum z lewej strony, które oznaczamy przez $\mu$. Indeksem $\mu$ jest oczywiście $f(1)$. Stwierdzamy teraz, że dla $1\le j<f(1)$ spełnione jest~(\ref{eq:4-7c}), czyli $A[1,j]+A[2,f(1)]\le\mu+A[2,j]$. Z drugiej strony, $\mu<A[1,j]$ dla każdego $1\le j<f(1)$. Dodając obie nierówności stronami, otrzymujemy $A[2,f(1)]<A[2,j]$, a to oznacza, że albo $A[2,f(1)]$ jest pierwszym minimum z lewej strony wiersza 2 albo mniejszy od niego element jest w tym wierszu na pewnym indeksie $f(2)>f(1)$. W obu przypadkach zachodzi jednak $f(1)\le f(2)$.

Dowód kolejnych nierówności przebiega analogicznie, skąd dostajemy tezę.

\subexercise{} %4-7(d)
Korzystając z twierdzenia z poprzedniego punktu, szukając minimum wiersza \twoparts{$i$}{tego}, sprawdzamy indeksy minimów wierszy \twoparts{$(i-1)$}{szego} oraz \twoparts{$(i+1)$}{szego}. Szukane minimum znajduje się pomiędzy nimi. Oczywiście nie istnieje wiersz zerowy, dlatego przetwarzając pierwszy wiersz nie szukamy minimum poprzedniego, ale przyjmujemy dla uproszczenia procedury, że $f(0)=1$. Podobny przypadek może się zdarzyć dla ostatniego nieparzystego wiersza, jeśli jest on ostatnim wierszem tablicy, wtedy wystarczy przyjąć wartość $f(m+1)=n$.

Po wyznaczeniu $f(i-1)$ oraz $f(i+1)$, sprawdzamy $f(i+1)-f(i-1)+1$ komórek wiersza $i$ w poszukiwaniu jego minimum. W ciągu całej procedury sprawdzimy w pesymistycznym przypadku
\begin{align*}
	\sum_{k=0}^{\lceil m/2\rceil-1}\bigl(f(2k+2)-f(2k)+1\bigr) &= \sum_{k=0}^{\lceil m/2\rceil-1}\bigl(f(2k+2)-f(2k))+\lceil m/2\rceil \\
	&= f(2\lceil m/2\rceil)-f(0)+\lceil m/2\rceil \\[2mm]
	&= n-1+\lceil m/2\rceil
\end{align*}
komórek, co oczywiście jest rzędu $O(m+n)$.

\subexercise{} %4-7(e)
Korzystając z oszacowania z poprzedniego punktu oraz tego, że na ostatnim poziomie rekursji wyznaczenie minimum jednego wiersza tablicy wymaga sprawdzenia co najwyżej $O(n)$ komórek, formułujemy następującą rekurencję:
\[
	T(m,n) =
	\begin{cases}
		O(n), & \text{dla $m=1$}, \\
		T(\lfloor m/2\rfloor,n)+O(m+n), & \text{dla $m>1$}.
	\end{cases}
\]
Na \twoparts{$i$}{tym} poziomie, rekurencja wprowadza koszt równy $O(m/2^i+n)$. Łatwo zauważyć, że jest $\lfloor\lg m\rfloor+1$ poziomów, a zatem całkowity koszt wynosi
\begin{align*}
	T(n) &= \sum_{i=0}^{\lfloor\lg m\rfloor-1}O\left(\frac{m}{2^i}+n\right)+O(n) \\
	&= O\biggl(\sum_{i=0}^{\lfloor\lg m\rfloor-1}\left(\frac{m}{2^i}\right)\biggr)+O(n\lg m) \\
	&= O\biggl(m\sum_{i=0}^{\lfloor\lg m\rfloor-1}\left(\frac{1}{2^i}\right)\biggr)+O(n\lg m) \\
	&= O(m+n\lg m),
\end{align*}
ponieważ suma z przedostatniej równości jest czynnikiem stałym.

\endinput
