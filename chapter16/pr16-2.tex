\problem{Szeregowanie o~minimalnym średnim czasie wykonania zadań} %16-2

\subproblem %16-2(a)
Rozważmy dowolne uszeregowanie zadań stanowiące rozwiązanie przedstawionego problemu.
Załóżmy, że dla pewnych zadań $a_i$, $a_j$ w~tym uszeregowaniu, tuż po zakończeniu wykonywania zadania $a_i$ w~chwili $c_i$ komputer przerywa pracę na jakiś czas -- czyli kolejne zadanie $a_j$ rozpoczęte zostaje w~chwili $b_j$ późniejszej niż $c_i$.
Jednakże przez wyeliminowanie tej przerwy moglibyśmy przesunąć rozpoczęcie wykonywania wszystkich zadań występujących po $a_i$ o~$c_i-b_j$ jednostek czasu wcześniej.
W~rezultacie wykonywanie tych zadań zakończyłoby się wcześniej o~tyle samo jednostek czasu i~otrzymane w~ten sposób uszeregowanie miałoby niższy średni czas zakończenia.
Wnioskujemy stąd, że w~optymalnym uporządkowaniu zadania wykonywane są bezpośrednio po sobie.

Przyjmijmy teraz, że w~uszeregowaniu nie ma przerw między zadaniami i~że istnieją zadania $a_i$, $a_j$, dla których $p_i>p_j$ oraz $a_i$ wykonywane jest bezpośrednio przed $a_j$.
Suma ich czasów zakończenia wnoszona do średniego czasu zakończenia rozważanego uszeregowania wynosi $C=c_i+c_j$.
Oznaczmy przez $c_i'$, $c_j'$, odpowiednio, czasy zakończenia zadań $a_i$, $a_j$, gdyby zostały one zamienione miejscami w~tym uporządkowaniu.
Z~założenia $c_i'=c_j$ oraz $c_j'<c_i$, a~więc suma nowych czasów zakończenia wynosi $C'=c_i'+c_j'<c_j+c_i=C$, podczas gdy czasy zakończenia pozostałych zadań nie ulegają zmianie.
Wynika stąd, że w~optymalnym uszeregowaniu zadania powinny występować według ich czasów wykonywania, od najkrótszego do najdłuższego.

Na podstawie powyższej analizy wynika, że w~celu rozwiązania postawionego problemu wystarczy posortować zadania ze zbioru $S$ według ich czasów wykonywania, co daje algorytm działający w~czasie $O(n\lg n)$.

\subproblem %16-2(b)
Ponieważ wykonanie każdego zadania można dowolnie przerywać, to o~zadaniach można myśleć jak o~obiektach mających wagę równą liczbie jednostek czasu potrzebnych do ich ukończenia.
Wykonywanie zadania o~wadze $p_i$ przez $t$ jednostek czasu ($0<t\le p_i$) zmniejszałoby jego wagę o~$t$, symbolizując skrócenie pozostałego czasu do jego ukończenia.
Podobnie jak w~punkcie (a), dążymy do minimalizacji średniego czasu zakończenia, więc opłaca się priorytetyzować zadania gotowe do wykonania o~jak najniższych wagach.
Stwierdzenie to uzasadniamy jak w~rozwiązaniu powyżej -- zamiana zadań w~optymalnym rozwiązaniu tak, aby wpierw wykonane było to o~dłuższym czasie wykonywania, może tylko powiększyć sumaryczny czas zakończenia.

Do pamiętania zadań gotowych do wykonania wykorzystamy kolejkę priorytetową $Q$ typu min porządkującą zadania względem ich wag.
Załóżmy, że ciąg $\langle a_1,a_2,\dots,a_n\rangle$ stanowi uszeregowanie zadań według ich czasów pojawienia się.
Algorytm będzie kolejno przeglądał zadania z~tego ciągu i~aktualizował kolejkę $Q$.
Dla zadania $a_i$ o~czasie pojawienia się $r_i$, po dodaniu go do kolejki $Q$, czas między chwilą $r_i$ a~$r_{i+1}-1$ włącznie (dla wygody można przyjąć $r_{n+1}=\infty$) zostanie maksymalnie wykorzystany na wykonanie zadań aktualnie znajdujących się w~kolejce.
Częściowe wykonanie danego zadania polega na zmniejszeniu jego wagi, co można zrealizować operacją \proc{Decrease-Key}.
Na każde zadanie pojawiające się do wykonania, co najwyżej jedno zadanie wykona się częściowo.
Z~kolei wykonawszy zadanie w~całości, zwyczajnie usuniemy go z~kolejki.
W~trakcie działania algorytmu każde zadanie dokładnie raz zostanie wstawione i~dokładnie raz usunięte z~kolejki $Q$, więc w~kolejce znajdzie się maksymalnie $n$ elementów.
W~najgorszym przypadku algorytm wykona po $n$ operacji \proc{Insert}, \proc{Extract-Min} i~\proc{Decrease-Key}, zatem jego czasem działania algorytmu jest $O(n\lg n)$.
