\subchapter{Podstawy strategii zachłannej}

\exercise %16.2-1
Pokażemy, że w~optymalnym plecaku będącym rozwiązaniem ciągłego problemu plecakowego musi wystąpić maksymalna ilość najbardziej wartościowego przedmiotu $a_m$, nieprzekraczająca pojemności plecaka $W$.

Załóżmy, że dysponujemy rozwiązaniem problemu, w~którym przedmiot $a_m$ występuje w~wadze $u<\min(W,w_m)$ kilogramów.
Wyrzućmy teraz z~plecaka łącznie $p=\min(w_m,W)-u$ kilogramów innych przedmiotów i~na to miejsce dobierzmy $p$ kilogramów przedmiotu $a_m$.
Ponieważ wartości jednostkowe usuniętych przedmiotów nie przekraczają wartości na jednostkę masy przedmiotu $a_m$, to ubytek wartości plecaka spowodowany ich usunięciem jest niewiększy niż $pv_m$.
Jednak przyrost wartości po dodaniu $p$ kilogramów przedmiotu $a_m$ jest równy $pv_m$, więc uzyskujemy plecak niegorszy od początkowego.

\exercise %16.2-2
Niech $a_1$, $a_2$, \dots, $a_n$ będą przedmiotami, które złodziej będzie wkładał do plecaka.
Przedmioty te ważą, odpowiednio $w_1$, $w_2$, \dots, $w_n$ i~są warte, odpowiednio, $v_1$, $v_2$, \dots, $v_n$.
Niech $S_{i,j}$, dla $0\le i\le n$, $0\le j\le W$, będzie podproblemem polegającym na wybraniu do plecaka przedmiotów spośród $a_1$, \dots, $a_i$ o~sumarycznej wadze nieprzekraczającej $j$ i~możliwie największej sumarycznej wartości.
Podczas rozwiązywania podproblemu $S_{i,j}$, gdzie $i\ge1$, musimy zdecydować, czy włożyć do plecaka przedmiot $a_i$ (o~ile $w_i\le j$).
Jeśli tak, to do sumarycznej wartości konstruowanego plecaka należy dodać wartość $v_i$ wprowadzaną przez ten przedmiot, a~następnie rozwiązać podproblem $S_{i-1,j-w_i}$.
W~przeciwnym przypadku podproblem, jaki zostaje do rozpatrzenia to $S_{i-1,j}$, a~sumaryczna wartość nie zostaje powiększona.
Zdefiniujmy $K[i,j]$ jako największą sumaryczną wartość przedmiotów wchodzących w~skład rozwiązania podproblemu $S_{i,j}$.
Z~naszego rozumowania wynika zależność
\[
	K[i,j] = \begin{cases}
		0, & \text{jeśli $i=0$}, \\
		K[i-1,j], & \text{jeśli $i\ge1$, $w_i>j$}, \\
		\max(K[i-1,j],K[i-1,j-w_i]+v_i), & \text{jeśli $i\ge1$, $w_i\le j$}.
	\end{cases}
\]

Następujący algorytm oparty na programowaniu dynamicznym wylicza kolejne wartości w~tablicy $K$:
\begin{codebox}
\Procname{$\proc{0-1-Knapsack}(w,v,W)$}
\li	$n\gets\attrib{w}{length}$
\li	\For $j\gets0$ \To $W$
\li		\Do $K[0,j]\gets0$
		\End
\li	\For $i\gets1$ \To $n$
\li		\Do \For $j\gets0$ \To $W$
\li				\Do $K[i,j]\gets K[i-1,j]$
\li					\If $w_i\le j$ i~$K[i-1,j-w_i]+v_i>K[i,j]$
\li						\Then $K[i,j]\gets K[i-1,j-w_i]+v_i$
						\End
				\End
		\End
\li	\Return $K$
\end{codebox}
Nietrudno przekonać się, że wypełnienie całej tablicy $K$ wymaga czasu $\Theta(nW)$ i~pamięci tego samego rzędu.

Do wypisania optymalnego zbioru przedmiotów, jakie należy umieścić w~plecaku, służy poniższa procedura.
W~trakcie przeglądania tablicy $K$, w~zależności od podjętej decyzji w~algorytmie \proc{Knapsack}, wypisywany jest odpowiedni przedmiot.
\begin{codebox}
\Procname{$\proc{Print-Knapsack}(K,w,i,j)$}
\li	\If $i\ge1$
\li		\Then \If $K[i,j]=K[i-1,j]$
\li				\Then $\proc{Print-Knapsack}(K,w,i-1,j)$
\li				\Else $\proc{Print-Knapsack}(K,w,i-1,j-w_i)$
\li					wypisz $a_i$
				\End
		\End
\end{codebox}
W~celu wypisania rozwiązania całego problemu, czyli $S_{n,W}$, procedura powinna zostać wywołana jako $\proc{Print-Knapsack}(K,w,n,W)$, co zajmuje czas $\Theta(n)$.

\exercise %16.2-3
Załóżmy, że przedmioty $a_1$, $a_2$, \dots, $a_n$ posortowane są według niemalejących wag, czyli $w_1\le w_2\le\dots\le w_n$.
Z~założenia mamy też, że kolejne wartości tych przedmiotów tworzą ciąg nierosnący: $v_1\ge v_2\ge\dots\ge v_n$.
Przez $A_W$ oznaczmy optymalny podzbiór przedmiotów będący rozwiązaniem dyskretnego problemu plecakowego, gdzie $W$ jest pojemnością plecaka.

Niech $1\le i<j\le n$.
Udowodnimy, że jeśli $a_j\in A_W$, to $a_i\in A_W$, co jest równoważne temu, że istnieje $0\le k\le n$, że $A_W=\{a_1,a_2,\dots,a_k\}$.
Ustalmy $i$, $j$, takie że $1\le i<j\le n$ i~załóżmy nie-wprost, że $a_j\in A_W$, ale $a_i\not\in A_W$.
Rozważmy zbiór $A_W'=A_W\setminus\{a_j\}\cup\{a_i\}$.
Ponieważ $w_i\le w_j$, to elementy $A_W'$ mieszczą się w~plecaku o~pojemności $W$, toteż $A_W'$ może stanowić rozwiązanie problemu.
Jednak suma wartości przedmiotów wchodzących w~skład $A_W'$ jest większa od sumarycznej wartości przedmiotów z~$A_W$ o~$v_i-v_j\ge0$.
Oznacza to, że $A_W'$ jest rozwiązaniem rozważanego problemu plecakowego o~niemniejszej wartości, co stoi w~sprzeczności z~definicją $A_W$.

Udowodniona obserwacja pozwala nam na skonstruowanie rozwiązania za pomocą algorytmu zachłannego.
Wystarczy przeglądać przedmioty od najlżejszych do najcięższych (czyli równoważnie, od najbardziej do najmniej wartościowych) i~włączać aktualny przedmiot do rozwiązania, o~ile tylko wraz z~poprzednio wybranymi przedmiotami nie przekracza pojemności plecaka.

\exercise %16.2-4
Załóżmy, że na trasie znajduje się $m$ stacji benzynowych i~że żadne kolejne stacje nie są oddalone od siebie o~więcej niż $n$ kilometrów.
Ponumerujmy je kolejnymi liczbami naturalnymi od 1 do $m$ wzdłuż trasy pokonywanej przez profesora.
Pokażemy, że problem ma własność optymalnej podstruktury.
Rozważmy optymalne rozwiązanie zawierające $s$ stacji, przy czym pierwszy przystanek znajduje się na \singledash{$k$}{tej} stacji.
Wówczas rozwiązanie dla podproblemu z~pozostałymi $m-k$ stacjami musi być optymalne; w~przeciwnym wypadku bowiem moglibyśmy zastąpić je lepszym, tzn.\ takim, w~którym występuje mniej niż $s-1$ stacji, uzyskując tym samym dla głównego problemu rozwiązanie o~mniej niż $s$ stacjach.

Problem cechuje także własność wyboru zachłannego.
Załóżmy, że na trasie w~odległości co najwyżej $n$ kilometrów od startu znajduje się dokładnie $k$ stacji benzynowych.
Profesor nie może wybrać na pierwszy przystanek stacji o~numerze większym niż $k$, gdyż nie jest możliwe dojechanie do niej bez tankowania po drodze.
W~optymalnym rozwiązaniu nie opłaca się też wybierać jako pierwszej stacji o~numerze $j<k$.
Jest tak dlatego, że gdyby wybrana została stacja $j$, to później, w~momencie przejeżdżania obok stacji $k$, w~baku pozostałoby mniej paliwa niż wtedy, gdy profesor opuszczałby stację $k$ po zatankowaniu na niej.
Innymi słowy, wybór stacji $k$ pozwala na dojechanie dalej, niż gdyby wybór padł na stację $j$.

Na podstawie tych własności możemy podać prosty algorytm zachłanny, który wyznacza optymalny ciąg tankowań w~czasie $O(m)$.

\exercise %16.2-5
Oznaczmy przez $X$ zbiór punktów wejściowych, a~przez $k$ prostą, na której leżą punkty z~$X$.
Niech $x\in X$ będzie takim punktem, który wszystkie pozostałe punkty z~$X$ ma po tej samej stronie na prostej $k$.
Odcinek jednostkowy leżący na prostej $k$ zawierający $x$ można umieścić w~taki sposób, aby jeden z~jego końców pokrywał się z~$x$, a~drugi sięgał w~kierunku innych punktów z~$X$.
Żadne inne ustawienie tego odcinka nie prowadzi do lepszego rozwiązania.
Jest tak dlatego, że w~takiej pozycji odcinek pokrywa największą możliwą liczbę innych punktów z~$X$ -- wszystkie te, których odległość od $x$ nie przekracza 1.
Wybór tego położenia jest więc zachłanny i~pozostawia on tylko jeden podproblem do rozwiązania -- taki, w~którym danymi wejściowymi jest podzbiór $X$ składający się z~punktów odległych od $x$ o~więcej niż 1.
Algorytm zachłanny rozwiązujący ten problem może więc znajdować punkt $x$ na prostej $k$, a~następnie usuwać wszystkie punkty z~$X$ odległe od $x$ o~nie więcej niż 1, po czym rozwiązywać pozostały podproblem.

\exercise %16.2-6
Załóżmy, że przedmioty $a_1$, $a_2$, \dots, $a_n$ posortowane są według nierosnących wartości na jednostkę masy, tzn.\ $v_1/w_1\ge v_2/w_2\ge\dots\ge v_n/w_n$.
W~optymalnym plecaku stanowiącym rozwiązanie ciągłego problemu plecakowego istnieje takie $1\le k\le n$, że przedmioty $a_{k'}$ dla $1\le k'<k$ znajdują się w~plecaku w~całości, a~przedmiotów $a_{k''}$ dla $k<k''\le n$ nie ma w~plecaku w~ogóle.
A~zatem problem ten tak naprawdę sprowadza się do znalezienia odpowiedniego $k$ oraz udziału przedmiotu $a_k$ w~plecaku.

Pokażemy, jak zrobić to w~czasie $O(n)$ w~sytuacji, gdy nie znamy uporządkowania przedmiotów według wartości jednostkowej.
Wykorzystując algorytm \proc{Select} z~podrozdziału 9.3, wyznaczmy medianę $m$ zbioru ilorazów $v_i/w_i$ i~zdefiniujmy zbiory
\[
	G = \{\,a_i:v_i/w_i>m\,\}, \quad E = \{\,a_i:v_i/w_i=m\,\}, \quad L = \{\,a_i:v_i/w_i<m\,\}
\]
oraz sumy
\[
	w_G = \sum_{a_i\in G}w_i, \quad w_E = \sum_{a_i\in E}w_i, \quad w_L = \sum_{a_i\in L}w_i.
\]
Jeśli $w_G>W$, to w~plecaku nie możemy umieścić w~całości wszystkich przedmiotów ze zbioru $G$, więc wywołujemy nasz algorytm rekurencyjnie dla tych przedmiotów i~zwracamy wynik tego wywołania jako wynik oryginalnego problemu.
W~przeciwnym przypadku $w_G\le W$, więc zbiór $G$ można włączyć do rozwiązania, a~następnie dobrać maksymalną ilość przedmiotów z~$E$ (pamiętajmy, że możemy brać części ułamkowe), która zmieści się w~pozostałej pojemności $W-w_G$.
Nierówność $w_G+w_E\ge W$ oznacza, że w~plecaku nie zostało już wolnego miejsca po wybraniu w~całości wszystkich przedmiotów z~$G$ i~$E$, i~jeśli ona zachodzi, to można zakończyć algorytm.
W~przeciwnym wypadku wystarczy wywołać go rekurencyjnie dla przedmiotów z~$L$ oraz plecaka o~pojemności $W-w_G-w_E$ i~dołączyć jego wynik do konstruowanego rozwiązania.

Wyznaczenie mediany $m$ wymaga czasu co najwyżej $O(n)$.
Zauważmy, że na każde wywołanie algorytmu przypada $\Theta(n)$ operacji plus co najwyżej jedno wywołanie rekurencyjne.
Wybór mediany na ,,element rozdzielający'' jest optymalne w~tym sensie, że kolejne wywołanie rekurencyjne dostaje na wejściu zbiór przedmiotów o~rozmiarze nieprzekraczającym połowy rozmiaru bieżącego zbioru przedmiotów.
Otrzymujemy stąd zależność opisującą czas wymagany przez algorytm, $T(n)\le T(n/2)+\Theta(n)$, której rozwiązaniem jest $T(n)=O(n)$.

\exercise %16.2-7
Posortujmy zbiór $A$ i~zbiór $B$ niemalejąco.
Niech $1\le i<j\le n$.
Zachodzi wtedy $a_i\le a_j$ oraz $b_i\le b_j$, skąd
\[
	\frac{a_i^{b_i}a_j^{b_j}}{a_i^{b_j}a_j^{b_i}} = \frac{a_j^{b_j-b_i}}{a_i^{b_j-b_i}} = \biggl(\frac{a_j}{a_i}\biggr)^{b_j-b_i} \ge 1.
\]
Ostatnia nierówność zachodzi, ponieważ $a_j/a_i\ge1$ i~$b_j-b_i\ge0$.
Wynika z~tego, że w~iloczynie będącym zyskiem z~uporządkowania bardziej opłaca się mieć czynniki będące potęgami $a^b$, w~których podstawa $a$ jest tą samą statystyką pozycyjną w~zbiorze $A$, co wykładnik $b$ w~zbiorze $B$.
Jednym z~uporządkowań maksymalizujących zysk jest więc porządek niemalejący obu zbiorów, lub porządek nierosnący obu zbiorów.
Algorytm rozwiązujący ten problem może zatem jedynie sortować niemalejąco oba zbiory, co wymaga czasu $\Theta(n\lg n)$.
