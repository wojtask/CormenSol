\subchapter{Podstawy strategii zachłannej}

\exercise %16.2-1
\exercise %16.2-2
Niech $a_1$, $a_2$, \dots, $a_n$ będą przedmiotami, które złodziej będzie wkładał do plecaka.
Przedmioty te ważą, odpowiednio $w_1$, $w_2$, \dots, $w_n$ i~są warte, odpowiednio, $v_1$, $v_2$, \dots, $v_n$.
Niech $S_{i,j}$, dla $0\le i\le n$, $0\le j\le W$, będzie podproblemem polegającym na wybraniu do plecaka przedmiotów spośród $a_1$, \dots, $a_i$ o~sumarycznej wadze nieprzekraczającej $j$ i~możliwie największej sumarycznej wartości.
Podczas rozwiązywania podproblemu $S_{i,j}$, gdzie $i\ge1$, musimy zdecydować, czy włożyć do plecaka przedmiot $a_i$ (o~ile $w_i\le j$).
Jeśli tak, to do sumarycznej wartości konstruowanego plecaka należy dodać wartość $v_i$ wprowadzaną przez ten przedmiot, a~następnie rozwiązać podproblem $S_{i-1,j-w_i}$.
W~przeciwnym przypadku podproblem, jaki zostaje do rozpatrzenia to $S_{i-1,j}$, a~sumaryczna wartość nie zostaje powiększona.
Zdefiniujmy $K[i,j]$ jako największą sumaryczną wartość przedmiotów wchodzących w~skład rozwiązania podproblemu $S_{i,j}$.
Z~naszego rozumowania wynika zależność
\[
	K[i,j] = \begin{cases}
		0, & \text{jeśli $i=0$}, \\
		K[i-1,j], & \text{jeśli $i\ge1$, $w_i>j$}, \\
		\max(K[i-1,j],K[i-1,j-w_i]+v_i), & \text{jeśli $i\ge1$, $w_i\le j$}.
	\end{cases}
\]

Następujący algorytm oparty na programowaniu dynamicznym wylicza kolejne wartości w~tablicy $K$:
\begin{codebox}
\Procname{$\proc{0-1-Knapsack}(w,v,W)$}
\li	$n\gets\attrib{w}{length}$
\li	\For $j\gets0$ \To $W$
\li		\Do $K[0,j]\gets0$
		\End
\li	\For $i\gets1$ \To $n$
\li		\Do \For $j\gets0$ \To $W$
\li				\Do $K[i,j]\gets K[i-1,j]$
\li					\If $w_i\le j$ i~$K[i-1,j-w_i]+v_i>K[i,j]$
\li						\Then $K[i,j]\gets K[i-1,j-w_i]+v_i$
						\End
				\End
		\End
\li	\Return $K$
\end{codebox}
Nietrudno przekonać się, że wypełnienie całej tablicy $K$ wymaga czasu $\Theta(nW)$ i~pamięci tego samego rzędu.

Do wypisania optymalnego zbioru przedmiotów, jakie należy umieścić w~plecaku, służy poniższa procedura.
W~trakcie przeglądania tablicy $K$, w~zależności od podjętej decyzji w~algorytmie \proc{Knapsack}, wypisywany jest odpowiedni przedmiot.
\begin{codebox}
\Procname{$\proc{Print-Knapsack}(K,w,i,j)$}
\li	\If $i\ge1$
\li		\Then \If $K[i,j]=K[i-1,j]$
\li				\Then $\proc{Print-Knapsack}(K,w,i-1,j)$
\li				\Else $\proc{Print-Knapsack}(K,w,i-1,j-w_i)$
\li					wypisz $a_i$
				\End
		\End
\end{codebox}
W~celu wypisania rozwiązania całego problemu, czyli $S_{n,W}$, procedura powinna zostać wywołana jako $\proc{Print-Knapsack}(K,w,n,W)$, co zajmuje czas $\Theta(n)$.

\exercise %16.2-3
Załóżmy, że przedmioty $a_1$, $a_2$, \dots, $a_n$ posortowane są według niemalejących wag, czyli $w_1\le w_2\le\dots\le w_n$.
Z~założenia mamy też, że kolejne wartości tych przedmiotów tworzą ciąg nierosnący: $v_1\ge v_2\ge\dots\ge v_n$.
Przez $A_W$ oznaczmy optymalny podzbiór przedmiotów będący rozwiązaniem dyskretnego problemu plecakowego, gdzie $W$ jest pojemnością plecaka.

Niech $1\le i<j\le n$.
Udowodnimy, że jeśli $a_j\in A_W$, to $a_i\in A_W$, co jest równoważne temu, że istnieje $0\le k\le n$, że $A_W=\{a_1,a_2,\dots,a_k\}$.
Ustalmy $i$, $j$, takie że $1\le i<j\le n$ i~załóżmy nie-wprost, że $a_j\in A_W$, ale $a_i\not\in A_W$.
Rozważmy zbiór $A_W'=A_W\setminus\{a_j\}\cup\{a_i\}$.
Ponieważ $w_i\le w_j$, to elementy $A_W'$ mieszczą się w~plecaku o~pojemności $W$, toteż $A_W'$ może stanowić rozwiązanie problemu.
Jednak suma wartości przedmiotów wchodzących w~skład $A_W'$ jest większa od sumarycznej wartości przedmiotów z~$A_W$ o~$v_i-v_j\ge0$.
Oznacza to, że $A_W'$ jest rozwiązaniem rozważanego problemu plecakowego o~niemniejszej wartości, co stoi w~sprzeczności z~definicją $A_W$.

Udowodniona obserwacja pozwala nam na skonstruowanie rozwiązania za pomocą algorytmu zachłannego.
Wystarczy przeglądać przedmioty od najlżejszych do najcięższych (czyli równoważnie, od najbardziej do najmniej wartościowych) i~włączać aktualny przedmiot do rozwiązania, o~ile tylko wraz z~poprzednio wybranymi przedmiotami nie przekracza pojemności plecaka.

\exercise %16.2-4
\exercise %16.2-5
Oznaczmy przez $X$ zbiór punktów wejściowych, a~przez $k$ prostą, na której leżą punkty z~$X$.
Niech $x\in X$ będzie takim punktem, który wszystkie pozostałe punkty z~$X$ ma po tej samej stronie na prostej $k$.
Odcinek jednostkowy leżący na prostej $k$ zawierający $x$ można umieścić w~taki sposób, aby jeden z~jego końców pokrywał się z~$x$, a~drugi sięgał w~kierunku innych punktów z~$X$.
Żadne inne ustawienie tego odcinka nie prowadzi do lepszego rozwiązania.
Jest tak dlatego, że w~takiej pozycji odcinek pokrywa największą możliwą liczbę innych punktów z~$X$ -- wszystkie te, których odległość od $x$ nie przekracza 1.
Wybór tego położenia jest więc zachłanny i~pozostawia on tylko jeden podproblem do rozwiązania -- taki, w~którym danymi wejściowymi jest podzbiór $X$ składający się z~punktów odległych od $x$ o~więcej niż 1.
Algorytm zachłanny rozwiązujący ten problem może więc znajdować punkt $x$ na prostej $k$, a~następnie usuwać wszystkie punkty z~$X$ odległe od $x$ o~nie więcej niż 1, po czym rozwiązywać pozostały podproblem.

\exercise %16.2-6
\exercise %16.2-7
Posortujmy zbiór $A$ i~zbiór $B$ niemalejąco.
Niech $1\le i<j\le n$.
Zachodzi wtedy $a_i\le a_j$ oraz $b_i\le b_j$, skąd
\[
	\frac{a_i^{b_i}a_j^{b_j}}{a_i^{b_j}a_j^{b_i}} = \frac{a_j^{b_j-b_i}}{a_i^{b_j-b_i}} = \biggl(\frac{a_j}{a_i}\biggr)^{b_j-b_i} \ge 1.
\]
Ostatnia nierówność zachodzi, ponieważ $a_j/a_i\ge1$ i~$b_j-b_i\ge0$.
Wynika z~tego, że w~iloczynie będącym zyskiem z~uporządkowania bardziej opłaca się mieć czynniki będące potęgami $a^b$, w~których podstawa $a$ jest tą samą statystyką pozycyjną w~zbiorze $A$, co wykładnik $b$ w~zbiorze $B$.
Jednym z~uporządkowań maksymalizujących zysk jest więc porządek niemalejący obu zbiorów, lub porządek nierosnący obu zbiorów.
Algorytm rozwiązujący ten problem może zatem jedynie sortować niemalejąco oba zbiory, co wymaga czasu $\Theta(n\lg n)$.
