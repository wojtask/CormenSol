\chapter{Analiza probabilistyczna i~algorytmy randomizowane}

\subchapter{Problem zatrudnienia sekretarki}

\exercise %5.1-1
Stwierdzenie w~wierszu~4 algorytmu \proc{Hire-Assistant}, która kandydatka jest lepsza spośród dwóch testowanych, jest równoważne rozstrzygnięciu czy $\id{rank}(\id{best})\le\id{rank}(i)$ dla każdego $i=1$, 2,~\dots,~$n$. Ponieważ każda permutacja kandydatek może pojawić się na wejściu algorytmu, to jesteśmy w~stanie przetestować każdą parę kandydatek, a~zatem znamy relację $R$ określoną na zbiorze rang kandydatek taką, że zachodzi $aRb$ albo $bRa$ dla dowolnych rang $a$ i~$b$. $R$ jest więc porządkiem liniowym.

\exercise %5.1-2
\begin{codebox}
\Procname{$\proc{Random}(a,b)$}
\li	\If $a=b$
\li		\Then
			\Return $a$
		\End
\li	$\id{mid}\gets\lfloor(a+b)/2\rfloor$
\li	\If $\proc{Random}(0,1)=0$
\li		\Then
			\Return $\proc{Random}(a,\id{mid})$
\li		\Else
			\Return $\proc{Random}(\id{mid}+\,1,b)$
		\End
\end{codebox}
Niech $n=b-a+1$ będzie długością zakresu losowania. Czas działania powyższej procedury jest opisany za pomocą rekurencji
\[
    T(n) =
	\begin{cases}
		\Theta(1) & \text{jeśli $n=1$}, \\
		T(\lfloor n/2\rfloor)+\Theta(1) & \text{jeśli $n>1$},
    \end{cases}
\]
gdyż jej działanie jest analogiczne do wyszukiwania binarnego w~\twoparts{$n$}{elementowej} tablicy -- w~każdym wywołaniu rekurencyjnym odrzuca połowę tablicy z~dalszej analizy. Rozwiązaniem rekurencji jest $T(n)=\Theta(\lg n)$, a~więc czasem działania procedury \proc{Random} w~zależności od $a$ i~$b$ jest $\Theta(\lg(b/a))$.

\exercise %5.1-3
Rozważmy następujący algorytm:
\begin{codebox}
\Procname{$\proc{Unbiased-Random}$}
\li	\Repeat
		$x\gets\proc{Biased-Random}$
\li		$y\gets\proc{Biased-Random}$
\li	\Until $x\ne y$ \label{li:unbiased-repeat-end}
\li \Return $x$
\end{codebox}
Zauważmy, że prawdopodobieństwo zwrócenia wyniku równego~0 wynosi
\[
	\Pr(x=0\;\;\text{i}\;\;y=1) = (1-p)p,
\]
a~zwrócenia 1,
\[
	\Pr(x=1\;\;\text{i}\;\;y=0) = p(1-p).
\]
Wykorzystano tutaj fakt, że kolejne wywołania procedury \proc{Biased-Random} zwracają wynik niezależnie od poprzednich wywołań. Ponieważ są to jedyne wartości, jakie algorytm może zwrócić, to wnioskujemy, że każde z~nich będzie zwrócone z~prawdopodobieństwem równym $1/2$.

Załóżmy, że każda iteracja pętli algorytmu odbywa się w~czasie stałym. Algorytm kończy działanie, gdy prawdziwy stanie się warunek z~wiersza~\ref{li:unbiased-repeat-end}, co zachodzi z~prawdopodobieństwem $2p(1-p)$. Iteracje pętli tworzą ciąg prób Bernoulliego o~rozkładzie geometrycznym, a~zatem liczba prób aż do osiągnięcia sukcesu jest zadana tożsamością~(C.31). Stąd wnioskujemy, że oczekiwanym czasem działania algorytmu jest $\Theta\bigl(1/(2p(1-p))\bigr)$.

\subchapter{Zmienne losowe wskaźnikowe}

\exercise %5.2-1
Zatrudnienie tylko jednej kandydatki jest równoważne przyjęciu pierwszej z~nich i~tylko jej. Zauważmy, że pierwszą kandydatkę przyjmiemy w~każdym przypadku. Jeśli ma ona być jedyną zatrudnioną osobą, to powinna być najbardziej wykwalifikowaną w~zbiorze wszystkich kandydatek (czyli mieć największą wartość \id{rank}). Najlepsza kandydatka może znajdować się na każdym z~$n$ miejsc w~ciągu wejściowym, zatem prawdopodobieństwo tego, że zatrudnimy dokładnie jedną jest równe $1/n$.

By dokonać zatrudnienia wszystkich $n$ kandydatek, musimy przesłuchiwać je w kolejności rosnących rang. Jest tylko jedna taka permutacja wejściowa, zatem prawdopodobieństwo tego zdarzenia wynosi $1/n!$.

\exercise %5.2-2
Zauważmy, że zarówno kandydatka z~pierwszej pozycji w~ciągu wejściowym, jak również ta o~najwyższej randze, są zatrudniane w~każdym przypadku. Jeśli procedura \proc{Hire-Assistant} ma dokonać dokładnie dwóch zatrudnień, to kandydatka z~numerem~1 powinna mieć rangę $i\le n-1$, a~wszystkie kandydatki o~rangach $i+1$, $i+2$,~\dots,~$n-1$ powinny występować w~ciągu po kandydatce z~rangą równą $n$.

Oznaczmy przez $E_i$ zdarzenie, że pierwsza kandydatka ma rangę równą $i$. Zachodzi oczywiście $\Pr(E_i)=1/n$ dla każdego $i=1$, 2,~\dots,~$n$. Przyjmując, że $j$ jest pozycją najlepszej kandydatki w~ciągu, niech $F$ będzie zdarzeniem polegającym na tym, że kandydatki o~numerach 2, 3,~\dots,~$j-1$ posiadają rangi mniejsze od kandydatki o~numerze~1. Jeśli zachodzi $E_i$, to $F$ zachodzi tylko wtedy, gdy najlepsza kandydatka jest pierwszą przesłuchiwaną spośród pozostałych $n-i$, których rangi wynoszą kolejno $i+1$, $i+2$,~\dots,~$n$. Stąd mamy $\Pr(F\mid E_i)=1/(n-i)$. Niech w~końcu $A$ oznacza zdarzenie, że procedura \proc{Hire-Assistant} zatrudnia dokładnie dwie osoby. Ponieważ zdarzenia $E_1$, $E_2$,~\dots,~$E_n$ są rozłączne, to zachodzi
\[
	A = F\cap(E_1\cup E_2\cup\cdots\cup E_{n-1}) = (F\cap E_1)\cup(F\cap E_2)\cup\cdots\cup(F\cap E_{n-1})
\]
oraz
\[
	\Pr(A) = \sum_{i=1}^{n-1}\Pr(F\cap E_i).
\]
Z tożsamości~(C.14),
\[
	\Pr(F\cap E_i) = \Pr(F\mid E_i)\Pr(E_i) = \frac{1}{n-i}\cdot\frac{1}{n},
\]
a~zatem
\[
	\Pr(A) = \sum_{i=1}^{n-1}\frac{1}{n-i}\cdot\frac{1}{n} = \frac{1}{n}\sum_{i=1}^{n-1}\frac{1}{n-i} = \frac{1}{n}\sum_{i=1}^{n-1}\frac{1}{i} = \frac{H_{n-1}}{n}.
\]

\exercise %5.2-3
Obliczmy wartość oczekiwaną liczby oczek w~jednym rzucie kostką. Definiując zmienną losową $X_i$ jako liczbę oczek na \twoparts{$i$}{tej} kostce ($1\le i\le n$), obliczamy $\E(X_i)$ przyjmując, że zmienne $X_i$ posiadają rozkład jednostajny (prawdopodobieństwo każdego wyniku jest równe $1/6$):
\[
	\E(X_i) = \sum_xx\Pr(X_i=x) = \frac{1+2+3+4+5+6}{6} = 3{,}5.
\]
Niech teraz zmienna losowa $X$ oznacza sumę oczek na $n$ kostkach. Mamy $X=X_1+X_2+\cdots+X_n$, więc z~liniowości wartości oczekiwanej:
\[
	\E(X) = \E\biggl(\sum_{i=1}^nX_i\biggr) = \sum_{i=1}^n\E(X_i) = 3{,}5n.
\]

\exercise %5.2-4
Niech $S_i$ będzie zdarzeniem oznaczającym, że \twoparts{$i$}{ta} osoba otrzymała swój kapelusz ($1\le i\le n$). Definiujemy teraz zmienne losowe $X_i=I(S_i)$ oraz $X=X_1+X_2+\cdots+X_n$, przy czym $X$ oznacza liczbę osób, którym zwrócono właściwe kapelusze. Mamy
\[
	\E(X) = \E\biggl(\sum_{i=1}^nX_i\biggr) = \sum_{i=1}^n\E(X_i) = \sum_{i=1}^n\Pr(X_i=1) = \sum_{i=1}^n\frac{1}{n} = 1,
\]
a~zatem swój kapelusz otrzyma średnio tylko jedna osoba.

\exercise %5.2-5
Dla wszystkich $i$,~$j$ takich, że $1\le i<j\le n$ zdefiniujmy zdarzenia $S_{ij}$ -- w~tablicy $A$ występuje inwersja $(i,j)$. Szanse, aby elementy na pozycjach $i$ oraz $j$ tworzyły inwersję, są równe $1/2$. Definiujemy zmienne losowe $X_{ij}=I(S_{ij})$ oraz $X=\sum_{i=1}^{n-1}\sum_{j=i+1}^nX_{ij}$, przy czym zmienna $X$ oznacza łączną liczbę inwersji tablicy $A$. Jej wartością oczekiwaną jest
\begin{align*}
	\E(X) &= \E\biggl(\sum_{i=1}^{n-1}\sum_{j=i+1}^nX_{ij}\biggr) = \sum_{i=1}^{n-1}\sum_{j=i+1}^n\E(X_{ij}) = \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Pr(X_{ij}=1) \\[1mm]
	&= \sum_{i=1}^{n-1}\sum_{j=i+1}^n\frac{1}{2} = \sum_{i=1}^{n-1}\frac{n-i}{2} = \frac{1}{2}\sum_{i=1}^{n-1}i = \frac{n(n-1)}{4}.
\end{align*}

\subchapter{Algorytmy randomizowane}

\exercise %5.3-1
Oto zmodyfikowana procedura \proc{Randomize-In-Place}:
\begin{codebox}
\Procname{$\proc{Randomize-In-Place'}(A)$}
\li	$n\gets\id{length}[A]$
\li	zamień $A[1]\leftrightarrow A[\proc{Random}(1,n)]$
\li	\For $i\gets2$ \To $n$
\li		\Do
			zamień $A[i]\leftrightarrow A[\proc{Random}(i,n)]$
		\End
\end{codebox}
Treść niezmiennika pozostaje niezmieniona (z~wyjątkiem fragmentu podającym linie kodu zawierającego ciało pętli), modyfikujemy jedynie dowód inicjowania pętli.
\begin{quote}
	Gdy $i=2$, niezmiennik pętli mówi, że dla każdej \twoparts{1}{permutacji}, fragment tablicy $A[1\twodots1]\equiv A[1]$ zawiera tę permutację z~prawdopodobieństwem $(n-1)!/n!=1/n$, co jest prawdą, gdyż spośród $n$ elementów tablicy prawdopodobieństwo tego, że w~$A[1]$ znajdzie się pewien ustalony, wynosi $1/n$.
\end{quote}

\exercise %5.3-2
\note{Przedstawiony w~treści zadania algorytm jest podany niepoprawnie. Pętla \kw{for} tej procedury powinna przebiegać po wszystkich\/ $i$ od\/ $1$ do\/ $n-1$. Kiedy jednak\/ $i$ osiąga wartość\/ $n$, następuje wywołanie\/ $\proc{Random}(n+1,n)$, które da niezdefiniowany wynik. Błąd występuje zarówno w~tłumaczeniu, jak i~w~oryginale.}

\noindent Algorytm ten nie działa zgodnie z~zamierzeniem. Jako przykład, weźmy dowolną tablicę o~$n=3$ elementach. Istnieje $n!-1=5$ permutacji tej tablicy różnych niż identycznościowa. Pętla \kw{for} w~pierwszym obiegu wybiera jedną z~dwóch wartości i~zamienia ją z~pierwszym elementem tablicy. W~drugim obiegu może zostać wybrana tylko jedna wartość na drugi element. Przy pomocy tej procedury jesteśmy w~stanie utworzyć tylko dwie permutacje, a~więc mniej niż potrzebujemy. Różnica ta powiększa się wraz ze wzrostem rozmiaru tablicy.

\exercise %5.3-3
Rozważmy permutację identycznościową $\pi_0$ i~zdefiniujmy zdarzenia $S_i$ -- element na pozycji $i$ w~tablicy $A$ ($1\le i\le n$) pozostanie na swoim miejscu po wykonaniu procedury. Na mocy \zad{C.2-6} prawdopodobieństwo uzyskania permutacji $\pi_0$ wynosi
\[
	\Pr\biggl(\bigcap_{i=1}^nS_i\biggr) = \Pr(S_1)\Pr(S_2\mid S_1)\Pr(S_3\mid S_1\cap S_2)\dots\Pr\biggl(S_n\biggm|\bigcap_{i=1}^{n-1}S_i\biggr) \tag{$*$}\label{eq:5.3-3}
\]
Zachodzi oczywiście $\Pr(S_1)=1/n$. Dalej, $\Pr(S_2\mid S_1)=1/n$, ponieważ jeśli wiemy, że element $A[1]$ został na swoim miejscu, to prawdopodobieństwo tego, że $A[2]$ również nie zostanie przeniesiony, jest równe $1/n$. Ogólnie, widać, że każdy czynnik we wzorze (\ref{eq:5.3-3}) jest równy $1/n$, a~stąd mamy
\[
	\Pr\biggl(\bigcap_{i=1}^nS_i\biggr) = \left(\frac{1}{n}\right)^n = \frac{1}{n^n}.
\]
Permutację identycznościową $\pi_0$ otrzymujemy więc z~prawdopodobieństwem mniejszym od $1/n!$, co oznacza, że procedura \proc{Permute-With-All} nie generuje permutacji losowych zgodnych z~rozkładem jednostajnym.

\exercise %5.3-4
Na początku działania procedury losowana jest liczba \id{offset}, o~jaką będą przesunięte elementy tablicy $A$ cyklicznie w~prawo. Element z~pozycji $i$ znajdzie się w~wyniku tego przesunięcia na pozycji $\id{dest}=(i+\id{offset})\bmod n$. Ponieważ istnieje $n$ możliwych wartości zmiennej \id{offset}, to szanse, że element $A[i]$ znajdzie się na pewnej ustalonej pozycji w~$A$, są równe $1/n$.

Ponieważ nie jest zmieniana wzajemna kolejność elementów, to nie każdą permutację można otrzymać w~wyniku działania tej procedury, nie dostaniemy np.\ permutacji będącej odwróceniem tablicy wejściowej, o~ile jej rozmiar jest większy niż~2.

\exercise %5.3-5
Zauważmy, że dla $n=1$ stwierdzenie trywialnie zachodzi, zatem załóżmy, że $n>1$. Mamy wykazać prawdziwość nierówności
\[
	\E\biggl(\sum_{i=1}^n\sum_{j=i+1}^nI_{ij}\biggr) \ge 1-\frac{1}{n},
\]
gdzie $I_{ij}$ jest zmienną losową wskaźnikową zdarzenia $A$ oznaczającego, że elementy na pozycjach $i$ oraz $j$ w~tablicy $P$ są różne. Nierówność przyjmuje postać
\[
	\sum_{i=1}^n\sum_{j=i+1}^n\Pr(A) \ge 1-\frac{1}{n},
\]
dzięki liniowości wartości oczekiwanej i~własności zmiennych losowych wskaźnikowych. Zauważmy, że prawdopodobieństwo tego, by elementy $i$ oraz $j$ były równe, wynosi $1/n^3$, a~więc $A$, czyli zdarzenie przeciwne do niego, zachodzi z~prawdopodobieństwem $1-1/n^3$. Mamy stąd
\begin{align*}
	\sum_{i=1}^n\sum_{j=i+1}^n\left(1-\frac{1}{n^3}\right) &\ge 1-\frac{1}{n} \\
	\left(1-\frac{1}{n^3}\right)\sum_{i=1}^n\sum_{j=i+1}^nj &\ge 1-\frac{1}{n} \\
	\left(1-\frac{1}{n^3}\right)\sum_{i=1}^{n}(n-i) &\ge 1-\frac{1}{n} \\
	\left(1-\frac{1}{n^3}\right)\sum_{i=0}^{n-1}i &\ge 1-\frac{1}{n} \\
	\left(1-\frac{1}{n^3}\right)\left(\frac{n^2-n}{2}\right) &\ge 1-\frac{1}{n}.
\end{align*}
Po przekształceniach dostajemy $n^3-2n-1\ge0$, co zachodzi dla $n\ge\phi$, gdzie symbol $\phi$ oznacza złotą proporcję, a~więc jest prawdą także dla $n\ge2$, co spełnia założenie i~kończy dowód nierówności.

\exercise %5.3-6
Jednym ze sposobów poradzenia sobie z identycznymi priorytetami jest użycie takiego algorytmu ich sortowania, który generuje tablicę, w której ciąg równych sobie priorytetów może być dowolną permutacją. Dokładniej, jeśli w tablicy wejściowej istnieje $k$ priorytetów o wartości $p$, to algorytm powinien generować tablicę posortowaną z każdą możliwą permutacją tych priorytetów na pozycjach $i$, $i+1$,~\dots,~$i+k$, gdzie $i$ jest najmniejszym indeksem tablicy posortowanej, w którym może znaleźć się $p$. Każda taka tablica powinna mieć jednakowe szanse na pojawienie się na wyjściu algorytmu.

Powyższą strategię można zaimplementować w procedurze \proc{Permute-By-Sorting} poprzez dokonanie odpowiedniej zmiany w algorytmie sortującym. Jeśli stosujemy np.\ algorytm sortowania przez scalanie, to podczas scalania, w procedurze \proc{Merge} jeśli elementy $L[i]$ i $R[j]$ są sobie równe, to do wynikowej tablicy $A$ zapisujemy jeden losowo wybrany; każdy z nich ma jednakową szansę być wybrany w danym kroku. Taka modyfikacja sprawi, że na każdym poziomie rekursji ciąg równych elementów będzie tworzył wszystkie możliwe permutacje z równym prawdopodobieństwem ich występowania.

\subchapter{Analiza probabilistyczna i~dalsze zastosowania zmiennych losowych wskaźnikowych}

\exercise %5.4-1
Dla $i=1$, 2,~\dots,~$k$ niech $b_i$ będzie dniem w~roku, w~którym przypadają urodziny osoby $i$, gdzie $1\le b_i\le n$ i~niech $r$ będzie dniem moich urodzin. Prawdopodobieństwo tego, że osoba $i$ ma urodziny tego samego dnia, co ja wynosi
\[
	\Pr(b_i=r) = \frac{1}{n}.
\]

Analogicznie jak w~analizie paradoksu dnia urodzin, zdefiniujmy zdarzenie polegające na tym, że $k$ osób ma urodziny w~inny dzień niż ja,
\[
	B_k = \bigcap_{i=1}^kA_i,
\]
gdzie $A_i$ jest zdarzeniem polegającym na tym, że osoba $i$ ma urodziny w~inny dzień niż ja. Ponieważ zdarzenia $A_1$, $A_2$,~\dots,~$A_k$ są niezależne oraz $\Pr(A_i)=(n-1)/n$ dla każdego $i=1$, 2,~\dots,~$k$, to mamy
\[
	\Pr(B_k) = \Pr\biggl(\bigcap_{i=1}^kA_i\biggr) = \prod_{i=1}^k\Pr(A_i) = \prod_{i=1}^k\frac{n-1}{n} = \left(\frac{n-1}{n}\right)^k.
\]

Aby prawdopodobieństwo tego, że wśród $k$ osób jest przynajmniej jedna, która ma urodziny tego samego dnia co ja, nie było mniejsze niż $1/2$, musi zachodzić
\[
	\left(\frac{n-1}{n}\right)^k \le \frac{1}{2}.
\]
Po rozwiązaniu nierówności ze względu na $k$ mamy
\[
	k \ge \log_{(n-1)/n}\frac{1}{2}
\]
i~po przyjęciu $n=365$ otrzymujemy $k\ge253$.

W drugiej części zadania przyjmijmy, że $r$ oznacza dzień 3~maja a~$b_i$ dla $i=1$, 2,~\dots,~$n$ mają to samo znaczenie, co wcześniej. Zachodzi
\[
	\Pr(b_i=r\;\;\text{i}\;\;b_j=r) = \Pr(b_i=r)\Pr(b_j=r) = \frac{1}{n^2}.
\]

Niech teraz $B_k$ będzie zdarzeniem polegającym na tym, że wśród $k$ osób co najwyżej jedna ma urodziny w~dniu $r$ oraz $A_i$ dla $i=1$, 2,~\dots,~$k$ niech będzie zdarzeniem, że osoba $i$ ma urodziny w~inny dzień niż $r$. Zachodzi
\[
	B_k = \bigcap_{i=1}^kA_i\cup\bigcup_{i=1}^kC_i,
\]
gdzie
\[
	C_i = \overline{A_i}\cap\bigcap_{\substack{j=1\\j\ne i}}^kA_j
\]
dla $i=1$, 2,~\dots,~$k$ jest zdarzeniem polegającym na tym, że wśród $k$ osób, tylko \twoparts{$i$}{ta} obchodzi urodziny dnia $r$. Obliczmy szanse zajścia ostatniego z nich:
\[
	\Pr(C_i) = (1-\Pr(A_i))\cdot\prod_{\substack{j=1\\j\ne i}}^k\Pr(A_j) = \frac{1}{n}\cdot\prod_{\substack{j=1\\j\ne i}}^k\frac{n-1}{n} = \frac{1}{n}\left(\frac{n-1}{n}\right)^{k-1}.
\]
Podobnie jak wcześniej, zachodzi $\Pr(A_i)=(n-1)/n$, a~zatem dostajemy
\begin{align*}
	\Pr(B_k) &= \Pr\biggl(\bigcap_{i=1}^kA_i\biggr)+\Pr\biggl(\bigcup_{i=1}^kC_i\biggr) \\
	&= \prod_{i=1}^k\Pr(A_i)+\sum_{i=1}^k\Pr(C_i) \\
	&= \left(\frac{n-1}{n}\right)^k+\frac{k}{n}\left(\frac{n-1}{n}\right)^{k-1} \\
	&= \left(\frac{n-1}{n}\right)^{k-1}\left(\frac{n+k-1}{n}\right)
\end{align*}
To czego poszukujemy, to najmniejsze $k$ takie, że $\Pr(B_k)<1/2$. Analiza powyższego wyrażenia jest dość skomplikowana, łatwiej będzie więc przyjąć $n=365$ i~obliczać wartości dla kolejnych $k$ aż do wyznaczenia szukanego. Otrzymano przybliżone wyniki:
\begin{align*}
    \Pr(B_{612}) &\approx 0{,}500221,\\
	\Pr(B_{613}) &\approx 0{,}499362,
\end{align*}
a~więc widać, że potrzeba $k=613$ osób.

\exercise %5.4-2
Niech $X$ oznacza liczbę potrzebnych rzutów zanim w pewnej urnie znajdą się dwie kule. Załóżmy, że po $k-1$ rzutach ($2\le k\le b+1$) nie było urny z więcej niż jedną kulą i obliczmy szanse, że również po \twoparts{$k$}{tym} rzucie nie będzie kolizji. Ponieważ jest zajętych $k-1$ urn, to \twoparts{$k$}{ta} kula wpada do pustej urny z prawdopodobieństwem równym
\[
    \Pr(X>k\mid X>k-1) = \frac{b-k+1}{b}.
\]
Zachodzi
\[
    \Pr(X>k) = \prod_{i=2}^k\Pr(X>i\mid X>i-1) = \frac{(b-1)(b-2)\dots(b-k+1)}{b^{k-1}},
\]
a ponieważ $\Pr(X>1)=1$, to mamy
\[
    \Pr(X=k) = \Pr(X>k-1)-\Pr(X>k) = \frac{b(b-1)\dots(b-k+2)(k-1)}{b^k}.
\]
Można teraz obliczyć wartość oczekiwaną zmiennej losowej $X$:
\[
    \E(X) = \sum_{k=2}^{b+1}k\Pr(X=k) = \sum_{k=1}^b\frac{b(b-1)\dots(b-k+1)(k+1)k}{b^{k+1}}.
\]
W pozycji \cite{taocp1frag} wyprowadzone jest oszacowanie na powyższą sumę, które wynosi $\sqrt{b\pi/2}$.

\exercise %5.4-3
Podczas rozważania paradoksu dnia urodzin w~pewnym momencie obliczamy prawdopodobieństwo tego, że dwie osoby urodziły się w~pewnym wybranym dniu i~wykorzystując założenie o~tym, że zdarzenia $b_i=r$ oraz $b_j=r$ dla $i\ne j$ są niezależne, dostajemy wynik. W~klasycznym problemie wystarczy zatem, żeby poszczególne zdarzenia były parami niezależne, jednak uogólniając problem celem wyznaczenia potrzebnej liczby osób do tego, aby co najmniej $l$ z~nich miało urodziny tego samego dnia wymagamy, aby każdy \twoparts{$l$}{elementowy} zbiór zdarzeń był niezależny. Jeśli $l=k$, to warunek sprowadza się do tego, że zdarzenia te muszą być wzajemnie niezależne.

\exercise %5.4-4
Oznaczmy przez $Q_1(k,n)$ prawdopodobieństwo tego, że wszystkie osoby z~grupy \twoparts{$k$}{osobowej} mają urodziny w~różne dni, gdzie $n$ jest liczbą dni w~roku, a~$Q_2(k,n)$ przy tych samych oznaczeniach niech oznacza prawdopodobieństwo tego, że pewnego dnia w~roku urodziły się dokładnie dwie osoby. Szanse na to, aby wśród tych $k$ osób co najmniej troje miało urodziny tego samego dnia, są równe
\[
    P(k,n) = 1-\bigl(Q_1(k,n)+Q_2(k,n)\bigr).
\]
Pierwsza wartość została obliczona w~klasycznym problemie i~wynosi
\[
    Q_1(k,n) = \frac{n!}{(n-k)!\,n^k} = \frac{k!}{n^k}\binom{n}{k},
\]
pozostaje zatem wyznaczyć $Q_2(k,n)$.

Spośród $n$ dni w~roku wybierzmy jeden, w~którym urodziły się pewne dwie i~tylko dwie osoby. Pozostałe $k-2$ osób możemy rozdzielić między $n-1$ dni oznaczających ich urodziny. Ponieważ rozróżniamy osoby, to liczbę sposobów takiego wyboru należy pomnożyć przez liczbę ich permutacji $k!$ i~podzielić przez~2 z~racji tego, że zmiana kolejności dwóch osób wybranych do tego samego dnia w~roku nie jest odrębnym przypadkiem.

Ale takich par może być więcej. Można tak naprawdę wyróżnić $i<\lfloor k/2\rfloor$ różnych dni, którym przypiszemy pary osób wtedy urodzonych -- liczba możliwości wynosi $\binom{n}{i}$. Pozostałe osoby rozdzielamy między pozostałe dni w~roku tak, aby każdej przypadł inny dzień, co da się wykonać na $\binom{n-i}{k-2i}$ sposobów. Podobnie jak wcześniej, rozróżnianie osób wprowadza czynnik $\frac{k!}{2^i}$, kolejność w~parze w~ramach tego samego dnia jest bowiem nieistotna.

Ponieważ liczba możliwości przypisania $k$ osób do $n$ różnych dni wynosi $n^k$, to ostatecznie otrzymujemy wzór
\[
    Q_2(k,n) = \frac{k!}{n^k}\sum_{i=1}^{\lfloor k/2\rfloor}\frac{1}{2^i}\binom{n}{i}\binom{n-i}{k-2i}.
\]

Aby wyznaczyć najmniejszą wartość $k$, dla której $P(k,n)\ge1/2$, można posłużyć się skomplikowanymi przekształceniami algebraicznymi, jednak prostszym sposobem jest obliczenie każdej wartości $P(k,n)$ dla $1\le k\le n$, po uprzednim przyjęciu $n=365$. Okazuje się, że
\begin{align*}
	P(87,365) &\approx 0{,}499455, \\
    P(88,365) &\approx 0{,}511065,
\end{align*}
a~zatem liczba $k=88$ jest odpowiedzią na postawione pytanie.

\exercise %5.4-5
Wszystkich możliwych \twoparts{$k$}{słów} nad zbiorem \twoparts{$n$}{elementowym} jest $n^k$. Aby słowo to tworzyło \twoparts{$k$}{permutację}, na pierwszy z~jego elementów należałoby wybrać jeden z~$n$ elementów zbioru, następnie drugim elementem mógłby być jeden z~$n-1$ dotychczas nie wybranych, itd. Istnieje zatem $n(n-1)\dots(n-k+1)$ możliwych \twoparts{$k$}{permutacji}, więc prawdopodobieństwo, że dane \twoparts{$k$}{słowo} będzie jedną z~nich wynosi
\[
	\frac{\prod_{i=0}^{k-1}(n-i)}{n^k} = \left(1-\frac{1}{n}\right)\left(1-\frac{2}{n}\right)\dots\left(1-\frac{k-1}{n}\right).
\]

Problem jest analogiczny do pytania o~prawdopodobieństwo zdarzenia, że wśród $k$ osób nie ma dwóch takich, które urodziły się tego samego dnia roku, gdzie $n$ jest liczbą dni w~roku.

\exercise %5.4-6
Obliczmy najpierw oczekiwaną liczbę pustych urn. Niech $S_i$ dla $i=1$, 2,~\dots,~$n$ będzie zdarzeniem, że \twoparts{$i$}{ta} urna jest pusta i~zdefiniujmy zmienną losową $X_i=I(S_i)$ oraz $X=\sum_{i=1}^nX_i$ oznaczającą liczbę pustych urn. Wtedy
\[
	\E(X) = \E\biggl(\sum_{i=1}^nX_i\biggr) = \sum_{i=1}^n\E(X_i) = \sum_{i=1}^n\Pr(S_i).
\]

Rozważmy pewną urnę, powiedzmy \twoparts{$i$}{tą} i~potraktujmy każdy rzut jako próbę Bernoulliego, gdzie sukcesem jest nie trafienie w~\twoparts{$i$}{tą} urnę. Mamy zatem $n$ niezależnych prób Bernoulliego, każda z~prawdopodobieństwem sukcesu równym $1-1/n$. Aby \twoparts{$i$}{ta} urna pozostała pusta, musimy osiągnąć $n$ sukcesów, a~zatem korzystając z~rozkładu dwumianowego, jest
\[
	\Pr(S_i) = b\Bigl(n;n,1-\frac{1}{n}\Bigr) = \binom{n}{n}\left(1-\frac{1}{n}\right)^n\left(\frac{1}{n}\right)^0 = \left(1-\frac{1}{n}\right)^n
\]
oraz
\[
	\E(X) = \sum_{i=1}^n\left(1-\frac{1}{n}\right)^n = n\left(1-\frac{1}{n}\right)^n.
\]
Korzystając z~tego, że
\[
	\lim_{n\to\infty}\left(1-\frac{1}{n}\right)^n = \frac{1}{e},
\]
mamy, że przy $n$ dowolnie bliskim $\infty$, liczba pustych urn jest bliska $n/e$.

Wyznaczmy teraz oczekiwaną liczbę urn z~dokładnie jedną kulą. W~tym celu, podobnie jak poprzednio, dla $i=1$, 2,~\dots,~$n$ zdefiniujemy zdarzenia $S_i$, że \twoparts{$i$}{ta} urna po wykonaniu rzutów, zawiera dokładnie jedną kulę. Definicje zmiennych losowych $X_i$ oraz $X$ pozostają bez zmian i~tak jak wcześniej, zachodzi
\[
	\E(X) = \sum_{i=1}^n\Pr(S_i).
\]
Dla analogicznej serii prób Bernoulliego stwierdzamy, że aby \twoparts{$i$}{ta} urna zawierała dokładnie jedną kulę, potrzebnych jest $n-1$ sukcesów, skąd
\[
	\Pr(S_i) = b\Bigl(n-1;n,1-\frac{1}{n}\Bigr) = \binom{n}{n-1}\left(1-\frac{1}{n}\right)^{n-1}\left(\frac{1}{n}\right)^1 = \left(1-\frac{1}{n}\right)^{n-1}
\]
oraz
\[
	\E(X) = \sum_{i=1}^n\left(1-\frac{1}{n}\right)^{n-1} = n\left(1-\frac{1}{n}\right)^{n-1}.
\]
Zauważając, że
\[
	n\left(1-\frac{1}{n}\right)^{n-1} = \frac{n\left(1-\frac{1}{n}\right)^n}{1-\frac{1}{n}},
\]
otrzymujemy, że przy $n$ dążącym do $\infty$ oczekiwana liczba urn z~tylko jedną kulą dąży do
\[
	\frac{\frac{n}{e}}{1-\frac{1}{n}} = \frac{n^2}{e(n-1)}.
\]

\exercise %5.4-7
W zadaniu przyjmujemy, że $n>16$, ponieważ wtedy wyrażenie $\lg n-2\lg\lg n$ jest dodatnie. Ponadto nie dbamy o~to, czy pewne wielkości są całkowite.

Korzystając z~przedstawionego w~książce wyprowadzenia, dla tych samych zdarzeń $A_{ik}$ mamy, że prawdopodobieństwo tego, że ciąg orłów długości co najmniej $\lg n-2\lg\lg n$ rozpoczyna się na pozycji $i$ jest równe
\[
	\Pr(A_{i,\,\lg n-2\lg\lg n}) = \frac{1}{2^{\lg n-2\lg\lg n}} = \frac{2^{2\lg\lg n}}{2^{\lg n}} = \frac{\lg^2n}{n},
\]
a~zatem prawdopodobieństwo, że ciąg orłów o~długości co najmniej $\lg n-2\lg\lg n$ nie rozpoczyna się na pozycji $i$ wynosi
\[
	1-\frac{\lg^2n}{n}.
\]

Podzielmy ciąg $n$ rzutów monetą na $n/(\lg n-2\lg\lg n)$ grup po $\lg n-2\lg\lg n$ rzutów. Grupy te złożone są z~różnych i~wzajemnie niezależnych rzutów, a~zatem prawdopodobieństwo, że każda z~tych grup nie będzie ciągiem orłów o~długości $\lg n-2\lg\lg n$ wynosi
\begin{align*}
	\left(1-\frac{\lg^2n}{n}\right)^{n/(\lg n-2\lg\lg n)} &\le \bigl(e^{-\lg^2n/n}\bigr)^{n/(\lg n-2\lg\lg n)} \\
	&= e^{-\lg^2n/(\lg n-2\lg\lg n)} \\
	&< e^{-\lg n} \\
	&\le 1/n.
\end{align*}
Skorzystaliśmy tutaj z~nierówności~(3.11) oraz z~tego, że dla $n>16$ zachodzi
\[
	\frac{\lg^2n}{\lg n-2\lg\lg n} > \lg n.
\]

\problems

\problem{Zliczanie probabilistyczne} %5-1

\subproblem %5-1(a)
Zdefiniujmy następujące zmienne losowe:
\begin{itemize}
	\item $X_j$ -- liczba, o~jaką zwiększy się wartość reprezentowana przez licznik po \twoparts{$j$}{tym} wykonaniu operacji \proc{Increment}, dla $1\le j\le n$,
	\item $X$ -- wartość reprezentowana przez licznik po wykonaniu $n$ operacji \proc{Increment}.
\end{itemize}
Zachodzi $X=\sum_{j=1}^nX_j$ oraz, ze względu na liniowość wartości oczekiwanej,
\[
	\E(X) = \E\biggl(\sum_{j=1}^nX_j\biggr) = \sum_{j=1}^n\E(X_j).
\]

Załóżmy teraz, że przed wykonaniem \twoparts{$j$}{tej} operacji \proc{Increment}, licznik przechowuje wartość $i$, co stanowi reprezentację $n_i$. Jeśli inkrementacja powiedzie się, co zdarzy się z~prawdopodobieństwem równym $1/(n_{i+1}-n_i)$, to wartość reprezentowana na liczniku zwiększy się o~$n_{i+1}-n_i$. Mamy zatem
\[
	\E(X_j) = 0\cdot\left(1-\frac{1}{n_{i+1}-n_i}\right)+(n_{i+1}-n_i)\cdot\left(\frac{1}{n_{i+1}-n_i}\right) = 1,
\]
dla każdego $j=1$,~2,~\dots,~$n$, a~więc
\[
	\E(X) = \sum_{j=1}^n\E(X_j) = n,
\]
co należało wykazać.

\subproblem %5-1(b)
Dla zmiennych losowych $X_j$ oraz $X$ zdefiniowanych w~poprzednim punkcie, mamy
\[
	\Var(X) = \Var\biggl(\sum_{j=1}^nX_j\biggr) = \sum_{j=1}^n\Var(X_j),
\]
co zachodzi na mocy wzoru~(C.28), ponieważ zmienne $X_j$ dla $j=1$,~2,~\dots,~$n$ są parami niezależne. Ponieważ $n_i=100i$, to zwiększenie wartości reprezentowanej przez licznik o~$n_{i+1}-n_i=100$ odbędzie się z~prawdopodobieństwem $1/(n_{i+1}-n_i)=1/100$. Z~wzoru~(C.26) otrzymujemy
\[
	\Var(X_j) = \E(X_j^2)-\E^2(X_j) = 0^2\cdot\left(1-\frac{1}{100}\right)+100^2\cdot\frac{1}{100}-1^2 = 99,
\]
dla każdego $j=1$,~2,~\dots,~$n$, skąd
\[
	\Var(X) = \sum_{j=1}^n\Var(X_j) = 99n.
\]

\problem{Wyszukiwanie w~nieposortowanej tablicy} %5-2

\subproblem %5-2(a)
\begin{codebox}
\Procname{$\proc{Random-Search}(A,x)$}
\li	\For $k\gets1$ \To $n$
\li		\Do
			$B[k]\gets\const{false}$
		\End
\li	$\id{checked}\gets0$
\li	\While $\id{checked}<n$ \label{li:random-search-while-begin}
\li		\Do
			$i\gets\proc{Random}(1,n)$
\li			\If $A[i]=x$
\li				\Then
					\Return $i$
\li				\ElseIf $B[i]=\const{false}$
\li					\Then
						$B[i]\gets\const{true}$
\li						$\id{checked}\gets\id{checked}+\,1$
				\End
		\End
\li	\Return \const{nil}
\end{codebox}
Przedstawiony algorytm korzysta z~pomocniczego wektora bitowego $B$, który na pozycji $i$ przechowuje informację o~tym, czy wybrany był \twoparts{$i$}{ty} indeks tablicy $A$. Ponadto zmienna \id{checked} przechowuje liczbę wybranych dotychczas indeksów, co łatwo kontrolować w~warunku pętli \kw{while} w~wierszu~\ref{li:random-search-while-begin}. Jeśli w~kolejnym obiegu pętli, element $x$ nie zostanie odnaleziony, a~komórka tablicy $A$, w~której szukano nie była jeszcze wybrana, to odpowiedni indeks wektora $B$ zostaje oznaczony, a~zmienna \id{checked} jest inkrementowana. W~przypadku, gdy elementu $x$ nie ma w~tablicy $A$, po zakończeniu wykonywania pętli \kw{while}, algorytm zwraca wartość \const{nil}.

\subproblem %5-2(b)
Niech $X$ będzie zmienną losową oznaczającą ilość wybranych indeksów tablicy $A$ zanim odnaleziono $x$. Szukanie $x$ realizowane przez procedurę \proc{Random-Search} jest serią prób Bernoulliego o~rozkładzie geometrycznym z~prawdopodobieństwiem sukcesu równym $p=1/n$. Stosując wzór~(C.31), otrzymujemy, że zostanie wybranych średnio $\E(X)=1/p=n$ indeksów tablicy $A$.

\subproblem %5-2(c)
W~tym przypadku mamy do czynienia ze zmienną losową $X$ z~poprzedniego punktu, ale z~prawdopodobieństwem zajścia sukcesu $p=k/n$, skąd $\E(X)=1/p=n/k$ jest średnią liczbą wybranych indeksów przed odnalezieniem $x$.

\subproblem %5-2(d)
Niech $X$ będzie zmienną losową oznaczającą liczbę wybranych indeksów przed sprawdzeniem wszystkich elementów tablicy $A$ oraz niech zmienne losowe $X_i$ dla $i=0$, 1,~\dots,~$n-1$ oznaczają liczbę wybranych indeksów po sprawdzeniu $i$ elementów, ale przed sprawdzeniem \twoparts{$(i+1)$}{szego}. Zachodzi
\[
	X = \sum_{i=0}^{n-1}X_i \quad\text{oraz}\quad \E(X) = \E\biggl(\sum_{i=0}^{n-1}X_i\biggr) = \sum_{i=0}^{n-1}\E(X_i).
\]
Wybór indeksów tablicy $A$ jest serią prób Bernoulliego o~rozkładzie geometrycznym, w~której sukcesem jest wylosowanie niewybranego dotychczas indeksu. Na początku działania algorytmu żaden element nie został jeszcze sprawdzony, a~zatem sukces można osiągnąć z~prawdopodobieństwem równym~1. Po sprawdzeniu pierwszego elementu, prawdopodobieństwo to wynosi $(n-1)/n$. Ogólnie, po sprawdzeniu $i$ elementów, prawdopodobieństwo sukcesu wynosi $(n-i)/n$. Z~tożsamości~(C.31) zachodzi $\E(X_i)=n/(n-i)$, zatem po wykorzystaniu wzoru~(A.7) dostajemy
\[
	\E(X) = \sum_{i=0}^{n-1}\E(X_i) = 1+\frac{n}{n-1}+\frac{n}{n-2}+\dots+\frac{n}{1} = nH_n = O(n\lg n),
\]
co jest czasem działania algorytmu \proc{Random-Search} w~przypadku braku $x$ w~tablicy $A$.

\subproblem %5-2(e)
Ponieważ procedura \proc{Deterministic-Search} jest identyczna z~algorytmem wyszukiwania liniowego opisanego w~\zad{2.1-3}, to z~rozwiązania \zad{2.2-3} wynika, że zarówno oczekiwany jak i~pesymistyczny czas jej działania wynosi $O(n)$.

\subproblem %5-2(f)
W~tablicy \twoparts{$n$}{elementowej} o~przypadkowym rozkładzie elementów prawdopodobieństwo wybrania jednego z~$k$ identycznych elementów wynosi $k/n$. Zanim trafimy na jeden z nich, sprawdzimy około $n/k$ indeksów, więc oczekiwanym czasem działania jest $O(n/k)$.

Pesymistycznym przypadkiem dla procedury w~tym przypadku jest takie ustawienie $k$ elementów w~tablicy \twoparts{$n$}{elementowej}, w~którym zajmują one $k$ końcowych pozycji, kiedy to należy sprawdzić $n-k$ komórek tablicy przed odnalezieniem jednego z~jego wystąpień. Pesymistycznym czasem działania procedury jest zatem $O(n-k)$.

\subproblem %5-2(g)
Przypadek średni i~pesymistyczny są równoważne przy braku $x$ w~tablicy $A$, bowiem niezależnie od rozkładu pozostałych elementów, procedura sprawdzi wszystkie indeksy $A$, co wymaga czasu $O(n)$.

\subproblem %5-2(h)
Permutowanie losowe tablicy (np.\ procedurą \proc{Randomize-In-Place}) zajmuje czas $O(n)$, zatem niezależnie od wartości $k$, czas działania procedury \proc{Scramble-Search}, zarówno oczekiwany jak i~pesymistyczny, wynosi $O(n)$.

\subproblem %5-2(i)
Najlepszym wyborem jest algorytm \proc{Deterministic-Search}, gdyż w~pewnych przypadkach zużywa mniej czasu niż pozostałe algorytmy, szczególnie gdy w~tablicy jest wiele wystąpień szukanej wartości. Permutowanie losowe, jakie stosuje procedura \proc{Scramble-Search} nie jest konieczne, gdyż nie wpływa na obniżenie rzędu wielkości czasu oczekiwanego jak i~pesymistycznego.

\endinput
