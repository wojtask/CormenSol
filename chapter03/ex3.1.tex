\subchapter{Notacja asymptotyczna}

\exercise %3.1-1
Niech $n_0$ będzie najmniejszym $n$, dla którego $f(n)\ge0$ i~$\ge g(n)\ge0$.
Dla każdego $n\ge n_0$ mamy
\[
    \max(f(n),g(n)) \le f(n)+g(n) = O(f(n)+g(n)) \tag{dla $c=1$ w~definicji $O$}
\]
oraz
\[
    \max(f(n),g(n)) \ge \frac{f(n)+g(n)}{2} = \Omega(f(n)+g(n)). \tag{dla $c=1/2$ w~definicji $\Omega$}
\]
Na mocy tw.\ 3.1 otrzymujemy, że $\max(f(n),g(n))=\Theta(f(n)+g(n))$.

\exercise %3.1-2
Aby pokazać, że $(n+a)^b=\Theta(n^b)$, należy znaleźć stałe $c_1$, $c_2$, $n_0>0$ takie, że
\[
	0 \le c_1n^b \le (n+a)^b \le c_2n^b
\]
dla wszystkich $n\ge n_0$.
Zauważmy, że $n+a\le n+|a|\le2n$, gdy $|a|\le n$ oraz $n+a\ge n-|a|\ge n/2$, o~ile $|a|\le n/2$.
Stąd, jeśli $n\ge 2|a|$, to zachodzi
\[
	0 \le n/2 \le n+a \le 2n.
\]
Ponieważ $b>0$, to powyższe nierówności możemy podnieść do potęgi $b$:
\[
	0 \le (n/2)^b \le (n+a)^b \le (2n)^b.
\]
Widać zatem, że szukanym stałym można nadać wartości $c_1=2^{-b}$, $c_2=2^b$ oraz $n_0=2|a|$, dlatego prawdą jest, że $(n+a)^b=\Theta(n^b)$.

\exercise %3.1-3
Niech $T(n)$ będzie czasem działania algorytmu $A$.
Stwierdzenie ,,$T(n)$ wynosi co najmniej $O(n^2)$'' oznacza, że począwszy od pewnego $n$, $T(n)\ge f(n)$ dla pewnej funkcji $f(n)$ z~klasy $O(n^2)$.
Zdanie to pozostaje prawdziwe dla dowolnego $T$, wystarczy bowiem wybrać funkcję $f(n)$ tożsamościowo równą 0, która oczywiście jest w~$O(n^2)$.
Widać więc, że takie określenie nie przekazuje żadnej użytecznej informacji o~czasie działania algorytmu.

\exercise %3.1-4
Znajdziemy stałe $c$, $n_0>0$ takie, że $0\le2^{n+1}\le c2^n$ dla każdego $n\ge n_0$.
Ponieważ $2^{n+1}=2\cdot2^n$ dla każdego $n\ge1$, to można przyjąć $c=2$ oraz $n_0=1$.
A~zatem $2^{n+1}=O(2^n)$.

Spróbujmy teraz wyznaczyć te same stałe, ale spełniające zależność $0\le2^{2n}\le c2^n$ dla wszystkich $n\ge n_0$.
Mamy $2^{2n}=2^n\cdot2^n\le c2^n$, z~czego wynika, że $c\ge2^n$, co jednak uzależnia $c$ od funkcji zmiennej $n$ przyjmującej dowolnie duże wartości, a~więc $c$ nie może być stałą.
Stąd otrzymujemy, że $2^{2n}\ne O(2^n)$.

\exercise %3.1-5
Z~definicji notacji $\Theta$ mamy, że $f(n)=\Theta(g(n))$, gdy istnieją takie stałe $c_1$, $c_2$, $n_0>0$, że
\[
	0 \le c_1g(n) \le f(n) \le c_2g(n)
\]
dla wszystkich $n\ge n_0$.
Powyższe nierówności można rozdzielić na $0\le c_1g(n)\le f(n)$, co daje $f(n)=\Omega(n)$ oraz $0\le f(n)\le c_2g(n)$, czyli $f(n)=O(n)$.

Dla dowodu w~drugą stronę załóżmy, że $f(n)=\Omega(g(n))$, czyli że istnieją stałe $c_1$, $n_1>0$, że dla każdego $n\ge n_1$ zachodzi
\[
	0 \le c_1g(n) \le f(n).
\]
Podobnie załóżmy, że $f(n)=O(g(n))$, czyli że istnieją stałe $c_2$, $n_2>0$, że dla każdego $n\ge n_2$ zachodzi
\[
	0 \le f(n) \le c_2g(n).
\]
Wybierając teraz $n_0=\max(n_1,n_2)$ i~łącząc powyższe nierówności, dostajemy, że dla dowolnego $n\ge n_0$ zachodzi
\[
	0 \le c_1g(n) \le f(n) \le c_2g(n),
\]
czyli $f(n)=\Theta(g(n))$.

\exercise %3.1-6
Niech $T(n)$ będzie czasem działania algorytmu dla danych wejściowych rozmiaru $n$.
Wielkość tę można traktować jak zmienną losową przyjmującą konkretne wartości w~zależności od egzemplarza danych wejściowych.
Oznaczmy przez $T_\mathrm{min}(n)$ i~$T_\mathrm{max}(n)$, odpowiednio, minimalną i~maksymalną wartość zmiennej losowej $T(n)$, czyli optymistyczny i~pesymistyczny czas działania algorytmu dla danych rozmiaru $n$.

Załóżmy, że $T(n)=\Theta(g(n))$.
Wśród danych rozmiaru $n$ wymagających takiego czasu są w~szczególności te, które stanowią dla algorytmu przypadki optymistyczny i~pesymistyczny.
Mamy więc zarówno $T_\mathrm{min}(n)=\Theta(g(n))$, jak i~$T_\mathrm{max}(n)=\Theta(g(n))$, a~z~tw.\ 3.1 wynika w~szczególności $T_\mathrm{min}(n)=\Omega(g(n))$ i~$T_\mathrm{max}(n)=O(g(n))$.

Niech teraz $T_\mathrm{min}(n)=\Omega(g(n))$ i~$T_\mathrm{max}(n)=O(g(n))$.
Z~definicji notacji $\Omega$ i~$O$ mamy, że istnieją dodatnie stałe $c_1$, $c_2$, $n_1$, $n_2$ takie, że $0\le c_1g(n)\le T_\mathrm{min}(g(n))$ dla każdego $n\ge n_1$ oraz $0\le T_\mathrm{max}(g(n))\le c_2g(n)$ dla każdego $n\ge n_2$.
Niech $n_0=\max(n_1,n_2)$.
Wówczas dla dowolnych $n\ge n_0$ zachodzi
\[
	0 \le c_1g(n) \le T_\mathrm{min}(n) \le T(n) \le T_\mathrm{max}(n) \le c_2g(n),
\]
czyli $T(n)=\Theta(g(n))$.

\exercise %3.1-7
Załóżmy niepustość tego zbioru i~rozważmy pewne $f(n)\in o(g(n))\cap\omega(g(n))$.
Zachodzi zatem zarówno $f(n)=o(g(n))$, jak i~$f(n)=\omega(g(n))$, co oznacza, że dla każdych dodatnich stałych $c_1$ i~$c_2$ istnieje pewne dodatnie $n_0$, że
\[
	c_1g(n) < f(n) < c_2g(n)
\]
dla wszystkich $n\ge n_0$.
Dochodzimy do sprzeczności, bowiem nieprawdą jest, że każde liczby $c_1$ i~$c_2$ spełniają $c_1<c_2$.
Stąd $o(g(n))\cap\omega(g(n))=\emptyset$.

Udowodniona własność pokazuje, że nie ma potrzeby definiowania notacji $\theta$ odpowiadającej $\Theta$ i~analogicznej do $o$ i~$\omega$.

\exercise %3.1-8
\note{Notacja\/ $O$ dla funkcji dwóch zmiennych jest błędnie zdefiniowana -- warunek powinien zachodzić dla wszystkich\/ $n\ge n_0$ \textbf{lub}\/ $m\ge m_0$.}

\noindent Definicje notacji $\Omega$ i~$\Theta$ dla funkcji dwóch zmiennych:
\[
	\begin{split}
		\Omega(g(n,m)) &= \bigl\{\,f(n,m):\text{istnieją dodatnie stałe $c$, $n_0$, $m_0$ takie, że} \\
		&\qquad 0 \le cg(n,m) \le f(n,m) \text{ dla wszystkich $n \ge n_0$ lub $m \ge m_0$}\,\bigr\}, \\[2mm]
		\Theta(g(n,m)) &= \bigl\{\,f(n,m):\text{istnieją dodatnie stałe $c_1$, $c_2$, $n_0$, $m_0$ takie, że} \\
		&\qquad 0 \le c_1g(n,m) \le f(n,m) \le c_2g(n,m) \text{ dla wszystkich $n \ge n_0$ lub $m \ge m_0$}\,\bigr\}.
	\end{split}
\]
