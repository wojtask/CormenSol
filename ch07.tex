\chapter{Quicksort -- sortowanie szybkie}

\subchapter{Opis algorytmu}

\exercise %7.1-1
Rys.~\ref{fig:7.1-1} przedstawia działanie procedury \proc{Partition} dla tablicy~$A$.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig07.1}
	\end{center}
	\caption{Działanie procedury \proc{Partition} dla tablicy $A=\langle13,19,9,5,12,8,7,4,11,2,6,21\rangle$. {\sffamily\bfseries(a)} Tablica wejściowa z~zaznaczonymi początkowymi wartościami zmiennych. {\sffamily\bfseries(b)}--{\sffamily\bfseries(l)} Kolejne iteracje pętli \kw{for} w~wierszach 3--6. {\sffamily\bfseries(m)} Tablica $A$ po wykonaniu zamiany z~wiersza~7. Element rozdzielający nie zmienił swojego położenia.} \label{fig:7.1-1}
\end{figure}

\exercise %7.1-2
Zauważmy, że jeśli wszystkie elementy podtablicy $A[p\twodots r]$ mają taką samą wartość, to warunek z~wiersza~4 procedury \proc{Partition} jest spełniony w~każdej iteracji pętli \kw{for}. Oznacza to, że po wykonaniu tej pętli będzie $i=r-1$ i~procedura zwróci $q=r$.

Odpowiedniej modyfikacji procedury dokonujemy poprzez wprowadzenie licznika elementów równych elementowi rozdzielającemu w~badanej podtablicy. W~każdej iteracji pętli \kw{for} sprawdzamy dodatkowo, czy $A[j]=x$ i~jeśli tak, to licznik ten inkrementujemy. Jeśli na końcu procedury jego wartość jest równa $r-p+1$, czyli rozmiarowi podtablicy, to zwracamy $q=(p+r)/2$.

\exercise %7.1-3
Podczas przetwarzania podtablicy $A[p\twodots r]$ o~rozmiarze $n=r-p+1$ wykonywanych jest $n-1$ iteracji pętli \kw{for}, a~każda z~nich przeprowadza operacje zajmujące czas stały. Stąd czas działania procedury \proc{Partition} wynosi $\Theta(n)$.

\exercise %7.1-4
Wystarczy zamienić znak nierówności na przeciwny w~warunku z~wiersza~4 procedury \proc{Partition}.

\subchapter{Czas działania algorytmu quicksort}

\exercise %7.2-1
Niech $c_1$, $d_1>0$ będą stałymi. Korzystając z~założenia, że $T(n-1)\le c_1(n-1)^2$, dostajemy
\[
	T(n) = T(n-1)+\Theta(n) \le c_1(n-1)^2+d_1n = c_1n^2+(d_1-2c_1)n+c_1 \le c_1n^2.
\]
Ostatnia nierówność zachodzi dla każdego $n\ge1$, jeśli odpowiednio dobierzemy wartości stałych $c_1$ i~$d_1$, np.\ $c_1=d_1=1$.

Weźmy teraz inne stałe $c_2$, $d_2>0$. Dolnego oszacowania na $T(n)$ dowodzimy analogicznie, wychodząc z~założenia $T(n-1)\ge c_2(n-1)^2$:
\[
	T(n) = T(n-1)+\Theta(n) \ge c_2(n-1)^2+d_2n = c_2n^2+(d_2-2c_2)n+c_2 \ge c_2n^2.
\]
Przyjmujemy wartościowanie $c_2=1/2$, $d_2=2$, dzięki któremu ostatnia nierówność jest spełniona dla wszystkich $n\ge1$.

Przypadek brzegowy $n=1$ można przyjąć za podstawę obu powyższych indukcji dla podanych wartości stałych, co kończy dowód, że $T(n)=\Theta(n^2)$.

\exercise %7.2-2
Procedura \proc{Partition} w~takim przypadku zwraca wartość $q=r$ (\refExercise{7.1-2}), a~więc w~następnych wywołaniach rekurencyjnych procedury \proc{Quicksort} będą przetwarzane podtablice rozmiarów 0 i~$n-1$. Napotykając w~każdym wywołaniu rekurencyjnym przypadek pesymistyczny, algorytm będzie działać w~czasie opisanym przez rekurencję z~\refExercise{7.2-1}, której rozwiązaniem jest $\Theta(n^2)$.

\exercise %7.2-3
W~tym przypadku podczas każdego wywołania rekurencyjnego procedury \proc{Partition} elementem rozdzielającym jest najmniejszy element przetwarzanej podtablicy $A[p\twodots r]$. W~każdym wywołaniu jedyne elementy, które zostaną zamienione, to element rozdzielający i~$A[p]$, po czym zwrócona zostanie wartość $q=r$. Przypadek ten jest zatem analogiczny do rozważanego w~poprzednim zadaniu, a~więc czasem działania procedury \proc{Quicksort} dla tablicy posortowanej malejąco jest $\Theta(n^2)$.

\exercise %7.2-4
Prawie posortowany ciąg jest niemal najgorszym przypadkiem dla algorytmu quicksort. Wykonywane są bowiem niezrównoważone podziały, przez co czas działania sortowania zbliża się do kwadratowego względem rozmiaru tablicy. Z~kolei dla sortowania przez wstawianie ciąg taki jest przypadkiem zbliżonym do optymistycznego, ponieważ czas działania procedury \proc{Insertion-Sort} jest tego samego rzędu, co ilość inwersji w~ciągu wejściowym (punkt~(c) problemu~\refProblem{2-4}). Liczba inwersji w~ciągu prawie posortowanym jest niewielka, możemy zatem mówić o~co najwyżej liniowym czasie działania sortowania przez wstawianie dla tego przypadku.

\exercise %7.2-5
Rozważmy drzewo rekursji dla opisanego przypadku dokonywania podziałów. Najkrótsza gałąź w~tym drzewie składa się z~węzłów o~wartościach $\alpha^in$, gdzie $i$ jest poziomem węzła, zaś najdłuższa gałąź na \compound{$i$}{tym} poziomie posiada węzeł o~wartości $(1-\alpha)^in$. Niech $h$ będzie głębokością liścia najkrótszej gałęzi. Mamy wtedy $\alpha^hn=1$, skąd
\[
	h = \log_\alpha\frac{1}{n} = -\frac{\lg n}{\lg\alpha}.
\]
Jeśli przez $H$ oznaczymy głębokość liścia na gałęzi najdłuższej, to mamy $(1-\alpha)^Hn=1$, a~zatem
\[
	H = \log_{1-\alpha}\frac{1}{n} = -\frac{\lg n}{\lg(1-\alpha)}.
\]

\exercise %7.2-6
Równoważnie należy wykazać, że procedura \proc{Partition} utworzy podział mniej zrównoważony niż $1-\alpha$ do $\alpha$ z~prawdopodobieństwem około $2\alpha$. Załóżmy, że dokonano podziału w~stosunku $1-\beta$ do $\beta$, gdzie $0<\beta\le1/2$. Pozostaje obliczyć szanse na to, aby $\beta<\alpha$. Zdarzenie to można modelować za pomocą ciągłego rozkładu jednostajnego dla przedziału $(0,\alpha)$ w~przestrzeni $(0,1/2]$. Wykorzystując definicję prawdopodobieństwa o~ciągłym rozkładzie jednostajnym, dostajemy
\[
	\Pr((0,\alpha)) = \frac{\alpha}{1/2} = 2\alpha.
\]

\subchapter{Randomizowana wersja algorytmu quicksort}

\exercise %7.3-1
Randomizacja algorytmu sprawia, że szanse osiągnięcia przypadku pesymistycznego są znikome. Można więc przyjąć, że dla każdych danych wejściowych algorytm zachowuje się jak w~przypadku średnim.

\exercise %7.3-2
W~przypadku pesymistycznym generator liczb losowych za każdym razem wybiera wartości, które tworzą najbardziej niezrównoważony podział podtablicy, czyli $p$ lub $r$. W~takiej sytuacji liczba wywołań generatora jest rzędu $\Theta(n)$.

W~przypadku optymistycznym generator za każdym razem zwraca liczbę bliską $(p+r)/2$. Tworzone podziały są zatem zrównoważone i~liczba wywołań generatora w~tym przypadku wynosi $\Theta(\lg n)$.

\subchapter{Analiza algorytmu quicksort}

\exercise %7.4-1
Niech $n\ge1$. Zgadujemy, że $T(q)\ge dq^2$ dla pewnej stałej $d>0$ i~wszystkich $0\le q\le n-1$. Podstawiamy do wzoru na $T(n)$ i~na podstawie \refExercise{7.4-3} otrzymujemy:
\begin{align*}
	T(n) &\ge \max_{0\le q\le n-1}(dq^2+d(n-q-1)^2)+\Theta(n) \\
	&= d\cdot\!\!\!\max_{0\le q\le n-1}(q^2+(n-q-1)^2)+\Theta(n) \\
	&= dn^2-d(2n-1)+\Theta(n) \\
	&\ge dn^2.
\end{align*}
Ostatnia nierówność zostaje spełniona, jeśli przyjmiemy $d$ odpowiednio małe tak, aby składnik $\Theta(n)$ zdominował wyrażenie $d(2n-1)$. Przyjmijmy, że przypadkiem brzegowym rekurencji jest $T(0)=1$. Dla dowolnego $d$ zachodzi $T(0)\ge d\cdot0^2=0$, a~więc $n=0$ przyjmujemy na podstawę indukcji, co kończy dowód, że $T(n)=\Omega(n^2)$.

\exercise %7.4-2
Czas algorytmu quicksort w~przypadku optymistycznym jest opisany przez rekurencję
\[
    T(n) = \min_{0\le q\le n-1}(T(q)+T(n-q-1))+\Theta(n).
\]
Niech $c>0$ będzie stałą. Zgadujemy, że $T(q)\ge cq\lg q$ dla każdego $0\le q\le n-1$ (przyjmujemy dla wygody, że $0\lg0=0$) i~podstawiamy:
\begin{align*}
    T(n) &\ge \min_{0\le q\le n-1}(cq\lg q+c(n-q-1)\lg(n-q-1))+\Theta(n) \\
	&= c\cdot\!\!\!\min_{0\le q\le n-1}(q\lg q+(n-q-1)\lg(n-q-1))+\Theta(n).
\end{align*}

Obliczymy teraz minimum wyrażenia $q\lg q+(n-q-1)\lg(n-q-1)$, gdy $0\le q\le n-1$. Potraktujmy je jako funkcję $f$ zmiennej $q\in(0,n-1)$ i~obliczmy obie pochodne tej funkcji:
\begin{align*}
    \frac{df}{dq}(q) &= \frac{d}{dq}\biggl(\frac{q\ln q+(n-q-1)\ln(n-q-1)}{\ln2}\biggr) = \frac{\ln q-\ln(n-q-1)}{\ln2}, \\[1mm]
	\frac{d^2\!f}{dq^2}(q) &= \frac{d}{dq}\biggl(\frac{\ln q-\ln(n-q-1)}{\ln2}\biggr) = \frac{1}{\ln2}\biggl(\frac{1}{q}+\frac{1}{n-q-1}\biggr).
\end{align*}
Pierwsza pochodna zeruje się tylko wtedy, gdy $q=(n-1)/2$. Obliczamy wartość drugiej pochodnej w~tym punkcie:
\[
    \frac{d^2\!f}{dq^2}\biggl(\frac{n-1}{2}\biggr) = \frac{1}{\ln2}\biggl(\frac{2}{n-1}+\frac{2}{2n-(n-1)-2}\biggr) = \frac{4}{\ln2\cdot(n-1)}.
\]
Wartość ta jest dodatnia, o~ile $n>1$. Mamy zatem, że minimum funkcji $f$ znajduje się w~punkcie $q=(n-1)/2$ i~wynosi $(n-1)\lg((n-1)/2)$. Widać, że jeśli $q$ dąży do 0 lub, analogicznie, do $n-1$, to wartość $f(q)$ dąży do $(n-1)\lg(n-1)$, zatem badane wyrażenie osiąga najmniejszą wartość tylko dla $q=(n-1)/2$.

Powracamy do oszacowania rekurencji $T(n)$, przyjmując $n\ge2$:
\begin{align*}
    T(n) &\ge c(n-1)\lg\frac{n-1}{2}+\Theta(n) \\
	&= c(n-1)\lg(n-1)-c(n-1)+\Theta(n) \\
	&= cn\lg(n-1)-c\lg(n-1)-c(n-1)+\Theta(n) \\
	&\ge cn\lg(n/2)-c\lg(n-1)-c(n-1)+\Theta(n) \\
	&= cn\lg n-cn-c\lg(n-1)-cn+c+\Theta(n) \\
	&= cn\lg n-c(2n+\lg(n-1)-1)+\Theta(n) \\
	&\ge cn\lg n.
\end{align*}
Ostatnia nierówność zachodzi, o~ile stała $c$ jest na tyle mała, że wyrażenie $c(2n+\lg(n-1)-1)$ jest zdominowane przez składnik $\Theta(n)$. Przyjmijmy, że przypadkiem brzegowym rekurencji jest $T(1)=1$, który spełnia rozważane oszacowanie, a~zatem $T(n)=\Omega(n\lg n)$.

\exercise %7.4-3
Potraktujmy wyrażenie jako funkcję $f(q)=q^2+(n-q-1)^2$, gdzie $0\le q\le n-1$. W~celu znalezienia maksimum globalnego tej funkcji obliczmy jej pierwszą i~drugą pochodną:
\begin{align*}
    \frac{df}{dq}(q) &= 2q-2(n-q-1), \\
	\frac{d^2\!f}{dq^2}(q) &= 4.
\end{align*}
Ponieważ druga pochodna jest dodatnia, to funkcja $f$ przyjmuje maksimum w~pewnym punkcie brzegowym swojej dziedziny. Mamy $f(0)=f(n-1)=(n-1)^2$, więc maksimum jest w~punktach $q=0$ i~$q=n-1$. 

\exercise %7.4-4
Przy wyznaczaniu dolnego oszacowania na oczekiwany czas działania algorytmu quicksort korzystamy z~analizy przedstawionej w~podręczniku dla górnego oszacowania. Zauważmy, że lemat~7.1 pozostaje prawdziwy, gdyby zamiast notacji $O$ zastosować $\Omega$. Prowadząc rozumowanie analogicznie, dochodzimy w~końcu do wartości oczekiwanej zmiennej losowej $X$, którą następnie ograniczamy od dołu:
\[
	\E(X) = \sum_{i=1}^{n-1}\sum_{k=1}^{n-i}\frac{2}{k+1} \ge \sum_{i=1}^{n-1}\sum_{k=1}^{n-i}\frac{2}{2k} = \sum_{i=1}^{n-1}H_{n-i} = \sum_{i=1}^{n-1}H_i = \sum_{i=1}^{n-1}\Omega(\lg i) = \Omega(n\lg n).
\]
Skorzystaliśmy tutaj z~\refExercise{A.2-3} oraz z~punktu~(b) problemu~\refProblem{A-1} dla $s=1$, skąd otrzymaliśmy ostatnie dwie równości.

\exercise %7.4-5
W~rozważanej modyfikacji rekursja w~algorytmie quicksort zatrzymuje się dla podtablic o~długości mniejszej niż $k$, więc liczba fragmentów o~mniej niż $k$ elementach pozostawionych nieposortowanymi przez quicksort jest rzędu $O(n/k)$. Czas wykonywania tego kroku jest więc czasem działania pełnego sortowania szybkiego dla tablicy \compound{$n$}{elementowej} pomniejszonym o~czas działania wszystkich wywołań zastosowanych do tych małych podtablic. W~przypadku średnim koszt tego kroku wynosi $O(n\lg n-n/k\cdot k\lg k)=O(n\lg(n/k))$. Drugi krok polega na sortowaniu przez wstawianie wszystkich nieposortowanych fragmentów i~zajmuje czas $O(n/k\cdot k^2)=O(nk)$. Stąd całkowitym oczekiwanym czasem działania algorytmu jest $O(nk+n\lg(n/k))$.

Teoretycznie parametr $k$ powinien być rzędu co najwyżej $O(\lg n)$ -- wtedy złożoność czasowa tego algorytmu nie przewyższa złożoności czasowej sortowania szybkiego. W~praktyce jednak $k$ powinno być tak dobrane, aby sortowanie przez wstawianie tablicy o~długości $k$ było wykonywane szybciej od sortowania takiej tablicy algorytmem quicksort.

\exercise %7.4-6
Przyjmijmy dla uproszczenia, że możemy pozwolić sobie na pewną niedbałość przy wyznaczaniu indeksów tablicy. Oznaczmy fragmenty tablicy $A$: $X=A[1\twodots\alpha n]$, $Y=A[\alpha n\twodots(1-\alpha)n]$, $Z=A[(1-\alpha)n\twodots n]$ i~zauważmy, że utworzenie podziału w~najgorszym przypadku $\alpha$ do $1-\alpha$ wymaga, aby element rozdzielający, czyli mediana trzech elementów $a$, $b$,~$c$ losowo wybranych z~$A[1\twodots n]$, należał do $Y$. Możliwe są następujące przypadki (podtablice traktujemy jak zbiory ich komórek):
\begin{enumerate}
	\item $a\in X$, $b\in Y$, $c\in Z$, co zachodzi z~prawdopodobieństwem $6\alpha^2(1-2\alpha)$;
	\item $a\in X$, $b\in Y$, $c\in Y$, co zachodzi z~prawdopodobieństwem $3\alpha(1-2\alpha)^2$;
	\item $a\in Y$, $b\in Y$, $c\in Z$, co zachodzi z~prawdopodobieństwem $3\alpha(1-2\alpha)^2$;
	\item $a\in Y$, $b\in Y$, $c\in Y$, co zachodzi z~prawdopodobieństwem $(1-2\alpha)^3$.
\end{enumerate}
Sumując cząstkowe prawdopodobieństwa, otrzymujemy wynik $4\alpha^3-6\alpha^2+1$.

\problems

\problem{Poprawność algorytmu podziału Hoare'a} %7-1

\subproblem %7-1(a)
Działanie procedury \proc{Hoare-Partition} dla przykładowej tablicy $A$ zostało przedstawione na rys.~\ref{fig:7-1a}.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{fig07.2}
	\end{center}
	\caption{Działanie procedury \proc{Hoare-Partition} dla tablicy $A=\langle13,19,9,5,12,8,7,4,11,2,6,21\rangle$. Wszystkie elementy jasnoszare stanowią obszar złożony z~wartości nie większych niż $x$. Ciemnoszare elementy tworzą obszar złożony z~wartości nie mniejszych niż $x$. {\sffamily\bfseries(a)} Wejściowa tablica wraz z~początkowym ustawieniem zmiennych. {\sffamily\bfseries(b)}--{\sffamily\bfseries(d)} Tablica i~bieżące wartości zmiennych po wykonaniu, odpowiednio, jednej, dwóch i~trzech iteracji pętli \kw{while} w~wierszach~4--11.} \label{fig:7-1a}
\end{figure}

\subproblem %7-1(b)
W~pierwszej iteracji pętli \kw{while} zmienna $j$ zatrzyma się na pewnym indeksie $q\ge p$, a~zmienna $i$ pozostanie na indeksie $p$, pod którym przechowywana jest wartość $x$. Jeśli $i=j$, to procedura kończy działanie, załóżmy więc, że $i<j$. Element $A[i]=A[p]=x$ zostanie zamieniony z~$A[q]$. W~kolejnych iteracjach pętli \kw{while} zmienna $i$ może dotrzeć najdalej na indeks $q$, natomiast $j$ nie będzie nigdy mniejsze niż $p$, bo $A[p]$ zawiera teraz wartość mniejszą bądź równą $x$. Ponieważ $q>p$, to w~pewnym momencie podczas działania pętli indeksy $i$ i~$j$ miną się, czyli będzie $i\ge j$, co spowoduje przerwanie pętli w~wierszu~11.

\subproblem %7-1(c)
Fakt udowodniony w~punkcie~(b) mówi o~tym, że $p\le j\le r$. Załóżmy, że $A[r]\le x$, bowiem w~przeciwnym przypadku $j<r$ już po pierwszej iteracji pętli \kw{while}. W~pierwszej iteracji element $A[p]$ jest zamieniany z~$A[r]$, po czym w~kolejnych iteracjach indeks $j$ jest zmniejszany i~również w~tym przypadku mamy $j<r$.

\subproblem %7-1(d)
Wynika to z~warunków stopu obu pętli \kw{repeat} i~testu z~wiersza~9. Każda para elementów tablicy, która tworzyła inwersję, jest odwracana, dzięki czemu elementy, które naruszały warunek posortowania, po zamianie będą znajdować się w~odpowiednich obszarach tablicy. W~momencie, gdy indeksy $i$ i~$j$ miną się, każdy element z~podtablicy $A[p\twodots j]$ jest równy bądź mniejszy od każdego elementu z~$A[j+1\twodots r]$.

\subproblem %7-1(e)
Jedyną różnicą w~porównaniu z~procedurą \proc{Quicksort} jest to, że element rozdzielający nie znajduje się w~$A[q]$ po wykonaniu \proc{Hoare-Partition}, musimy więc sortować rekurencyjnie fragment $A[p\twodots q]$ zamiast $A[p\twodots q-1]$. Pseudokod procedury został przedstawiony poniżej.
\begin{codebox}
\Procname{$\proc{Hoare-Quicksort}(A,p,r)$}
\li	\If $p<r$
\li		\Then
			$q\gets\proc{Hoare-Partition}(A,p,r)$
\li			$\proc{Hoare-Quicksort}(A,p,q)$
\li			$\proc{Hoare-Quicksort}(A,q+1,r)$
		\End
\end{codebox}

\problem{Alternatywna analiza algorytmu quicksort} %7-2

\subproblem %7-2(a)
W~procedurze \proc{Randomized-Partition} element $A[r]$ jest zamieniany z~elementem losowo wybranym z~tablicy $A$ o~rozmiarze $n$. Stąd szanse, że pewien ustalony element tablicy $A$ zostanie elementem rozdzielającym, wynoszą $1/n$. Wobec tego wartość oczekiwana zmiennej $X_i$, gdzie $i=1$, 2,~\dots,~$n$, wynosi $\E(X_i)=\Pr(X_i=1)=1/n$.

\subproblem %7-2(b)
Wywołanie procedury \proc{Randomized-Quicksort} dla tablicy wejściowej $A$ o~rozmiarze $n$ potrzebuje czasu $\Theta(n)$ na podział tablicy. Zostaje wyznaczony pewien indeks $1\le q\le n$, po czym procedura jest wywoływana rekurencyjnie dla podtablic rozmiarów $q-1$ i~$n-q$. Zmienna losowa $X_i$ zdefiniowana w~punkcie~(a) przyjmuje wartość 1, gdy $i=q$, a~w~pozostałych przypadkach przyjmuje wartość 0. Stąd czas potrzebny na posortowanie \compound{$n$}{elementowej} tablicy wyraża się wzorem
\[
	T(n) = T(q-1)+T(n-q)+\Theta(n) = \sum_{i=1}^nX_i(T(i-1)+T(n-i)+\Theta(n)).
\]
Biorąc wartości oczekiwane skrajnych wyrażeń, otrzymujemy wzór~(7.5) na oczekiwany czas działania algorytmu quicksort.

\subproblem %7-2(c)
Wykorzystując części~(a) i~(b) oraz liniowość wartości oczekiwanej, otrzymujemy
\begin{align*}
	\E(T(n)) &= \sum_{q=1}^n\E\bigl(X_q(T(q-1)+T(n-q)+\Theta(n))\bigr) \\
	&= \sum_{q=1}^n\E(X_q)\bigl(\E(T(q-1))+\E(T(n-q))+\E(\Theta(n))\bigr) \\
	&= \sum_{q=1}^n\frac{1}{n}\bigl(\E(T(q-1))+\E(T(n-q))+\Theta(n)\bigr) \\
	&= \frac{1}{n}\sum_{q=0}^{n-1}2\E(T(q))+\frac{1}{n}\sum_{q=1}^n\Theta(n) \\
	&= \frac{2}{n}\sum_{q=0}^{n-1}\E(T(q))+\Theta(n)
\end{align*}

\subproblem %7-2(d)
Rozdzielamy sumę na dwie części:
\[
	\sum_{k=1}^{n-1}k\lg k = \sum_{k=1}^{\lceil n/2\rceil-1}k\lg k+\sum_{k=\lceil n/2\rceil}^{n-1}k\lg k,
\]
po czym zauważamy, że czynnik $\lg k$ w~pierwszej sumie po prawej stronie znaku równości możemy ograniczyć z~góry przez $\lg(n/2)=\lg n-1$, a~czynnik $\lg k$ w~drugiej sumie -- przez $\lg n$. Stąd
\begin{align*}
	\sum_{k=1}^{n-1}k\lg k &\le (\lg n-1)\sum_{k=1}^{\lceil n/2\rceil-1}k+\lg n\sum_{k=\lceil n/2\rceil}^{n-1}k \\
	&= \lg n\sum_{k=1}^{n-1}k-\sum_{k=1}^{\lceil n/2\rceil-1}k \\[2mm]
	&\le \frac{n(n-1)\lg n}{2}-\frac{n}{4}\biggl(\frac{n}{2}-1\biggr) \\[1mm]
	&\le \frac{n^2\lg n}{2}-\frac{n^2}{8},
\end{align*}
przy czym ostatnia nierówność zachodzi, gdy $n\ge2$.

\subproblem %7-2(e)
Korzystając ze wskazówki, przyjmijmy założenie indukcyjne $\E(T(q))\le aq\lg q-bq$ dla $q=1$, 2,~\dots~$n-1$ oraz pewnych stałych $a$,~$b>0$. Oczywiście $\E(T(0))=0$, bo dla pustej tablicy nie trzeba wykonywać żadnej pracy. Z~punktu~(c) mamy
\begin{align*}
	\E(T(n)) &= \frac{2}{n}\sum_{q=1}^{n-1}\E(T(q))+\Theta(n) \\
	&\le \frac{2}{n}\sum_{q=1}^{n-1}(aq\lg q-bq)+\Theta(n) \\
	&= \frac{2a}{n}\sum_{q=1}^{n-1}q\lg q-b(n-1)+\Theta(n).
\end{align*}
Wykorzystując teraz wynik z~punktu~(d), dostajemy
\begin{align*}
	\E(T(n)) &\le \frac{2a}{n}\biggl(\frac{n^2\lg n}{2}-\frac{n^2}{8}\biggr)-b(n-1)+\Theta(n) \\
	&= an\lg n-\frac{an}{4}-bn+b+\Theta(n) \\
	&\le an\lg n-bn,
\end{align*}
ponieważ możemy wybrać $a$ wystarczająco duże, by wyrażenie $an/4-b$ dominowało nad składnikiem $\Theta(n)$.

Pozostaje zbadać, czy oszacowanie to zachodzi dla podstawy indukcji. Przyjmijmy w~tym celu, że $\E(T(1))=1$. Niestety, aby oszacowanie było spełnione dla $\E(T(1))$, musiałoby być $b\le-1$, co przeczy założeniu. Rozważmy więc $\E(T(2))$, które na mocy punktu~(c) jest równe $1+c$, gdzie $c$ jest stałą ukrytą w~notacji~$\Theta$. Nierówność $1+c\le2a-2b$ łatwo spełnić, dobierając odpowiednio duże~$a$. Aby móc przyjąć $n=2$ na podstawę indukcji, musimy uniezależnić dalsze wyrazy rekurencji od $\E(T(1))$, które nie spełnia oszacowania. Dokonamy tego przez modyfikację wzoru~(7.6) tak, aby sumowanie przebiegało od $q=2$, podczas gdy pierwsze dwa składniki będziemy traktować jak wchłonięte przez składnik $\Theta(n)$. W~założeniu indukcyjnym także pomijamy $E(T(1))$. Dowód jest zakończony -- mamy ostatecznie, że $\E(T(n))=O(n\lg n)$.

Łącząc ten wynik z~oszacowaniem $\Omega(n\lg n)$ dla przypadku optymistycznego, które zostało wyznaczone w~\refExercise{7.4-2}, dostajemy, że oczekiwanym czasem działania algorytmu quicksort jest $\Theta(n\lg n)$.

\problem{Nieefektywne sortowanie} %7-3

\subproblem %7-3(a)
Udowodnimy poprawność algorytmu przez indukcję względem rozmiaru tablicy $n$. Łatwo sprawdzić, że algorytm działa poprawnie w~przypadku, gdy $n\le2$. Załóżmy więc, że $n>2$ i~że poprawnie sortowane są tablice o~rozmiarach mniejszych niż $n$. W~wyniku wykonania wiersza~6 na pozycjach $\lfloor n/3\rfloor+1\twodots n-\lfloor n/3\rfloor$ znajdują się elementy nie mniejsze od tych z~pozycji $1\twodots\lfloor n/3\rfloor$. A~zatem, po wykonaniu wiersza~7, $\lfloor n/3\rfloor$ największych elementów tablicy $A$ znajduje się w~obszarze $A[n-\lfloor n/3\rfloor+1\twodots n]$. Aby zakończyć sortowanie tablicy $A$, wystarczy posortować fragment $A[1\twodots n-\lfloor n/3\rfloor]$, co realizuje wiersz~8.

\subproblem %7-3(b)
Procedura jest wywoływana rekurencyjnie 3~razy, zaś każde wywołanie otrzymuje tablicę o~rozmiarze około $2/3$ rozmiaru oryginalnej tablicy. Ponadto praca poza wywołaniami rekurencyjnymi jest wykonywana w~czasie stałym. Stąd dostajemy równanie rekurencyjne
\[
	T(n) =
	\begin{cases}
		\Theta(1), & \text{jeśli $n\le2$}, \\
		3T(2n/3)+\Theta(1), & \text{jeśli $n>2$},
	\end{cases}
\]
które rozwiązujemy przy użyciu twierdzenia o~rekurencji uniwersalnej, otrzymując wynik $T(n)=\Theta(n^{\log_{3/2}3})\approx \Theta(n^{2{,}71})$.

\subproblem %7-3(c)
Pesymistyczny czas działania algorytmu \proc{Stooge-Sort} jest wyższego rzędu nie tylko od pesymistycznego czasu działania algorytmów sortowania przez scalanie, kopcowanie czy sortowania szybkiego, ale również od mniej efektywnego sortowania przez wstawianie. Metoda sortowania profesorów jest więc poprawna, ale bardzo powolna.

\problem{Głębokość stosu w~algorytmie quicksort} %7-4

\subproblem %7-4(a)
\proc{Quicksort}$'$ wykonuje te same operacje na tablicy $A$ co oryginalny algorytm quicksort. Różnica jest tylko w~przetwarzaniu podtablicy $A[q+1\twodots r]$. Zamiast drugiego wywołania rekurencyjnego procedura wykonuje przypisanie w~wierszu~5, po czym następuje kolejna iteracja pętli \kw{while}, co działa identycznie jak wywołanie $\proc{Quicksort}'(A,q+1,r)$, ale bez zwiększania stosu rekurencji. Poprawność algorytmu wynika zatem z~poprawności oryginalnego algorytmu quicksort.

\subproblem %7-4(b)
Stos rekurencji może urosnąć do rozmiaru $\Theta(n)$ w~sytuacji, gdy będzie $\Theta(n)$ wywołań rekurencyjnych \proc{Quicksort}$'$. Dzieje się tak wtedy, gdy na każdym poziomie rekursji procedura \proc{Partition} zwraca $q=r$. Do wywołania rekurencyjnego przekazywana jest wtedy podtablica o~1 mniejsza w~porównaniu z~początkową tablicą. Algorytm zachowuje się w~ten sposób, jeśli na wejście dostanie tablicę posortowaną niemalejąco.

\subproblem %7-4(c)
Wykorzystamy pomysł, aby wywoływać procedurę rekurencyjnie dla mniejszej podtablicy, natomiast większą przetwarzać w~bieżącym wywołaniu. Po wywołaniu \proc{Partition} wystarczy sprawdzać rozmiary podtablic i~mniejszą z~nich przekazywać do wywołania rekurencyjnego. Dzięki temu na kolejnym poziomie rekursji rozważany będzie problem mniejszy co najmniej o~połowę, więc w~najgorszym przypadku głębokość stosu rekurencji wyniesie $\Theta(\lg n)$. Oczekiwany czas działania algorytmu nie zmieni się -- tworzone podziały będą takie same jak przed dokonaniem usprawnienia. Zmodyfikowany kod procedury \proc{Quicksort}$'$ został przedstawiony poniżej.
\begin{codebox}
\Procname{$\proc{Quicksort}''(A,p,r)$}
\li	\While $p<r$
\li		\Do
			\Comment Dziel i~sortuj mniejszą podtablicę.
\li			$q\gets\proc{Partition}(A,p,r)$
\li			\If $q-p<r-q$
\li				\Then
					$\proc{Quicksort}''(A,p,q-1)$
\li					$p\gets q+1$
\li				\Else
					$\proc{Quicksort}''(A,q+1,r)$
\li					$r\gets q-1$
				\End
		\End
\end{codebox}

\problem{Podział względem mediany trzech wartości} %7-5

\subproblem %7-5(a)
Aby element $x$ znajdował się na pozycji $i$ w~tablicy $A'$, drugi z~wybranych elementów powinien znajdować się na lewo od $i$ w~tej tablicy, a~trzeci wybrany element -- na prawo od $i$ w~tej tablicy. Dla pierwszego mamy $i-1$ możliwości wyboru jego pozycji, a~dla drugiego liczbą możliwości jest $n-i$. Otrzymujemy zatem
\[
	p_i = \frac{(i-1)(n-i)}{\binom{n}{3}}.
\]

\subproblem %7-5(b)
W~zwykłej implementacji szanse wyboru dowolnego elementu z~tablicy $A[1\twodots n]$ na element rozdzielający są równe $1/n$ (z~części~(a) problemu~\refProblem{7-2}). Natomiast przy wyborze mediany wynoszą one
\[
	p_{\lfloor(n+1)/2\rfloor} \approx \frac{(n/2)(n/2)}{\binom{n}{3}} = \frac{3n}{2(n-1)(n-2)}.
\]
Możemy sobie pozwolić na obliczenie powyższej wartości w~przybliżeniu, gdyż niedokładność zostanie zniwelowana przez fakt, że $n\to\infty$. Stosunek tych prawdopodobieństw wynosi
\[
	\lim_{n\to\infty}\frac{p_{\lfloor(n+1)/2\rfloor}}{1/n} = \lim_{n\to\infty}\frac{3n^2}{2(n-1)(n-2)} = \frac{3}{2},
\]
czyli szanse na to, że mediana tablicy $A[1\twodots n]$ zostanie wybrana na element rozdzielający, zwiększą się o~50\% dla dostatecznie dużych $n$.

\subproblem %7-5(c)
W~tradycyjnym podejściu szansa na uzyskanie dobrego podziału wynosi około $1/3$. Obliczmy teraz szanse na dobry podział przy wyborze mediany z~trzech:
\[
	\sum_{i=n/3}^{2n/3}p_i = \sum_{i=n/3}^{2n/3}\frac{(i-1)(n-i)}{\binom{n}{3}} = \frac{6}{n(n-1)(n-2)}\sum_{i=n/3}^{2n/3}(i-1)(n-i).
\]
Ostatnią sumę można oszacować następująco:
\[
	\sum_{i=n/3}^{2n/3}(i-1)(n-i) \approx \sum_{i=n/3}^{2n/3}i(n-i) \approx 2\sum_{i=n/3}^{n/2}i(n-i),
\]
co następnie przybliżamy za pomocą całki:
\begin{align*}
	2\sum_{i=n/3}^{n/2}i(n-i) &\approx 2\int_{n/3}^{n/2}x(n-x)\,dx = 2\biggl[x^2\biggl(\frac{n}{2}-\frac{x}{3}\biggr)\biggr]\bigg|_{n/3}^{n/2} \\
	&= 2\biggl(\frac{n}{2}\biggr)^2\biggl(\frac{n}{2}-\frac{n}{6}\biggr)-2\biggl(\frac{n}{3}\biggr)^2\biggl(\frac{n}{2}-\frac{n}{9}\biggr) = \frac{13n^3}{6\cdot27}.
\end{align*}
Powracając teraz do oszacowania szans dobrego podziału, otrzymujemy
\[
	\sum_{i=n/3}^{2n/3}p_i \approx \frac{6}{n(n-1)(n-2)}\cdot\frac{13n^3}{6\cdot27} = \frac{13n^2}{27(n-1)(n-2)}.
\]

Wzrost szans na uzyskanie dobrego podziału po zastosowaniu nowej strategii wyboru elementu rozdzielającego wyznaczymy, obliczając stosunek prawdopodobieństw z~obu metod, który wynosi
\[
	\frac{\sum_{i=n/3}^{2n/3}p_i}{1/3} \approx \frac{13n^2}{9(n-1)(n-2)},
\]
co przy $n\to\infty$ jest bliskie $13/9$ -- wzrost wynosi więc około 50\%.

\subproblem %7-5(d)
Nowy sposób wyboru elementu rozdzielającego zwiększa jedynie szanse na uzyskanie podziału zrównoważonego, co z~kolei obniża prawdopodobieństwo, że algorytm quicksort będzie działał w~czasie kwadratowym. Jednakże dolne oszacowanie na czas działania algorytmu pozostaje bez zmian i~wynosi nadal $\Omega(n\lg n)$ -- można sobie wyobrazić sytuację, w~której oryginalny sposób wyboru elementu rozdzielającego wprowadza za każdym razem najbardziej zrównoważony podział, a~dolnym ograniczeniem czasu działania oryginalnego algorytmu jest właśnie $\Omega(n\lg n)$.

\problem{Rozmyte sortowanie przedziałów} %7-6

\subproblem %7-6(a)
Niech $A$ będzie tablicą wejściową algorytmu, gdzie $A[i]=[a_i,b_i]$ dla $i=1$, 2,~\dots,~$n$. Zauważmy, że jeśli $[a_i,b_i]\cap[a_j,b_j]\ne\emptyset$, czyli przedziały $A[i]$ i~$A[j]$ nachodzą na siebie, to mogą wystąpić w~tablicy wynikowej w~dowolnej kolejności. Algorytm działa podobnie jak quicksort, ale wykorzystuje tę obserwację, znajdując zbiór przedziałów nachodzących na przedział stanowiący element rozdzielający i~pomijając wywołanie rekurencyjne dla podtablicy utworzonej przez ten zbiór przedziałów.

Procedura \proc{Fuzzy-Sort} implementuje rozmyte sortowanie przedziałów; aby posortować całą tablicę $A$, należy wywołać $\proc{Fuzzy-Sort}(A,1,\id{length}[A])$.
\begin{codebox}
\Procname{$\proc{Fuzzy-Sort}(A,p,r)$}
\li	\If $p<r$
\li		\Then
			$\langle q_1,q_2\rangle\gets\proc{Fuzzy-Partition}(A,p,r)$
\li			$\proc{Fuzzy-Sort}(A,p,q_1-1)$ \label{li:fuzzy-sort-recursion1}
\li			$\proc{Fuzzy-Sort}(A,q_2+1,r)$ \label{li:fuzzy-sort-recursion2}
		\End
\end{codebox}
Pomocnicza procedura \proc{Fuzzy-Partition} dokonuje podziału tablicy $A[p\twodots r]$ na 3 podtablice: $A[q_1\twodots q_2]$, która nie musi być dalej sortowana, oraz $A[p\twodots q_1-1]$ i~$A[q_2+1\twodots r]$, które następnie sortowane są w~wywołaniach rekurencyjnych w~wierszach~\ref{li:fuzzy-sort-recursion1} i~\ref{li:fuzzy-sort-recursion2}. Pseudokod procedury pomocniczej został przedstawiony poniżej.
\begin{codebox}
\Procname{$\proc{Fuzzy-Partition}(A,p,r)$}
\li	zamień $A[r]\leftrightarrow A[\proc{Random}(p,r)]$
\li	$x\gets a_r$
\li $i\gets p-1$
\li	\For $j\gets p$ \To $r-1$
\li		\Do
			\If $a_j\le x$
\li				\Then
					$i\gets i+1$
\li					zamień $A[i]\leftrightarrow A[j]$
				\End
		\End
\li	zamień $A[i+1]\leftrightarrow A[r]$ \label{li:fuzzy-partition-swap}
\li	$q\gets i+1$ \label{li:fuzzy-partition-q-init}
\li	\For $k\gets i$ \Downto $p$
\li		\Do
			\If $b_k\ge x$
\li				\Then
					$q\gets q-1$
\li					zamień $A[q]\leftrightarrow A[k]$
				\End
		\End \label{li:fuzzy-partition-for-end}
\li	\Return $\langle q,i+1\rangle$
\end{codebox}
Po wykonaniu wiersza~\ref{li:fuzzy-partition-swap} tablica $A$ jest podzielona na dwie podtablice według lewych końców przedziałów względem lewego końca $x$ przedziału stanowiącego element rozdzielający wybrany losowo spośród wszystkich elementów $A[p\twodots r]$. Ta część jest więc analogiczna do zwykłej procedury \proc{Partition}, w~wyniku czego dostajemy dwa obszary tablicy rozdzielone elementem $x$. Następnie, w~wierszach~\ref{li:fuzzy-partition-q-init}\nobreakdash--\ref{li:fuzzy-partition-for-end}, wszystkie przedziały z~podtablicy $A[p\twodots i]$, które nachodzą na element rozdzielający znajdujący się teraz w~$A[i+1]$, zostają przeniesione na koniec tej podtablicy. W~rezultacie z~przedziałów tych utworzony zostaje trzeci obszar tablicy, niewymagający dalszego sortowania. Na końcu zwracane zostają indeksy początku i~końca tego obszaru.

\subproblem %7-6(b)
Algorytm został oparty o~randomizowaną wersję quicksorta, więc jego czas działania dla tablicy \compound{$n$}{elementowej} w~przypadku średnim wynosi $\Theta(n\lg n)$. Jeśli jednak wszystkie przedziały na siebie nachodzą, to w~każdym wywołaniu rekurencyjnym będzie sortowana tylko podtablica zawierająca elementy leżące na prawo od elementu rozdzielającego. Randomizacja zapewnia, że wartość oczekiwana pozycji elementu rozdzielającego wypada pośrodku podtablicy $A[p\twodots r]$ (patrz \refExercise{C.3-2}) i~w~kolejnych wywołaniach rekurencyjnych sortowany będzie fragment o~połowę mniejszy. Oczekiwany czas działania algorytmu w~tym przypadku jest więc opisany przez rekurencję $T(n)=T(n/2)+\Theta(n)$, której rozwiązaniem jest $\Theta(n)$.

\endinput
